{"meta":{"title":"Searene","subtitle":null,"description":null,"author":"Searene","url":"http://searene.me"},"pages":[{"title":"about me","date":"2016-05-23T18:11:42.000Z","updated":"2017-08-21T12:41:01.120Z","comments":true,"path":"about/index.html","permalink":"http://searene.me/about/index.html","excerpt":"","text":"I’m a software engineer. I like coding, music and hiking in my spare time."}],"posts":[{"title":"Went to Qiandao Lake","slug":"Went-to-Qiandao-Lake","date":"2018-04-07T02:48:09.000Z","updated":"2018-04-07T03:11:28.155Z","comments":true,"path":"2018/04/07/Went-to-Qiandao-Lake/","link":"","permalink":"http://searene.me/2018/04/07/Went-to-Qiandao-Lake/","excerpt":"","text":"Qingming Festival of 2018 falls on April 5 to April 7 in China, and I, along with two of my college classmates, planed to go to Qiandao Lake for two days. Qiandao Lake is about 150km away from my house, we started at about 10:00 AM, and arrived at around 2:30 PM. All of us were exhausted, after having our lunch at a local restaurant, we all went to sleep. In fact, we did almost nothing but driving/watching TV on the first day. When the second day came, we decided to go around by boat and have some fun. The boat was bigger than I thought, which might be able to hold around 100 people. There were even bigger ones, which looked like a building. I found that the scenery was not bad, maybe slightly better than I thought. This is small island. On our way back, we were hit by another car in the highway. This was intense. Luckily no one got hurt. We didn’t finish dealing with the accident until 8 o’clock, during which we called the police and the insurance company. Since we were the one that got hit, we didn’t need to assume any responsibility. And for the other car, all the money was covered by the insurance company, so no one needed to worry about that. Then we drove to my company and had a supper around it, it was about 9 o’clock at that time. We were all pretty tired. We went to our home respectively and the travel was over.","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[]},{"title":"Go to KTV alone","slug":"Go-to-KTV-alone","date":"2018-04-02T23:10:10.000Z","updated":"2018-04-02T23:35:32.163Z","comments":true,"path":"2018/04/03/Go-to-KTV-alone/","link":"","permalink":"http://searene.me/2018/04/03/Go-to-KTV-alone/","excerpt":"","text":"I went to KTV alone last weekend. On the one hand, going to KTV alone is somewhat embarrassing and uncomfortable, I want to train myself to be comfortable with the uncomfortable. On the other hand, I want to check if I have a talent for singing, without being affected by others. Well, I successfully paid in front of a waiter and a waitress. Although the price is slightly higher than what I found in Meituan, I didn’t care too much about it. I was also given two bottles of water and a bowl of popcorns for free. You can see that it’s obviously for lovers, yet I’m all alone, whatever. Then I started singing. After about 5 minutes, I became hoarse, and singing high notes became very difficult for me. Then I realized that I was not suitable to be a singer, God doesn’t give me a good throat. The physical conditions are extremely important. I once heard that when colleges enroll music students, they usually check their physical conditions, like your voice, how high you can reach, etc. They don’t care about your skills, whether you are able to make trills, whether your breath is correct, etc. All of them can be trained, except your physical conditions. If you don’t have a good throat, you won’t be able to be a good singer, period. Anyway, it’s just an experience. Although I’m not able to be a singer, it may not be a bad thing. I just need to know it.","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[]},{"title":"live a quite life","slug":"live-a-quite-life","date":"2018-04-01T01:50:26.000Z","updated":"2018-04-01T02:25:06.967Z","comments":true,"path":"2018/04/01/live-a-quite-life/","link":"","permalink":"http://searene.me/2018/04/01/live-a-quite-life/","excerpt":"","text":"It’s strange that quite girls seem irresistible to me. I found it about a month ago, when I met a girl during the company training. She was always working, and kept quite all the time. I found her attractive because of that. But later I found out that she was actually not quite, she would argue with others when necessary. The reason why she kept quite for the most of her time is simply because she was focusing on her work. She would do everything to accomplish her job, including keeping quite. That’s all. I’m not saying it’s wrong. Actually it couldn’t be more correct, especially when living in this world is pretty hard. But I’m not attractive to her any more, I don’t know why. Maybe that’s who I am. I found another quite girl a few days ago. She was sitting opposite me, and she was looking at her laptop quietly. She seemed beautiful back then, I don’t know why. Maybe it’s just because she’s quite. I often thought about a quite life, the best life I could imagine. A life without struggling, without fighting, and without loneliness. However, we are not designed to live in this kind of life. It’s not only because we human beings are constantly worried and trying to find something to do, but also because this kind of quite world simply does not exist. The world we are living in is so hard, so I changed my mind, I told myself that I should solve all of my problems. But it’s a pretty ambitious goal. When the night falls, when everyone returns to his/her home, I don’t know where to go. Now I understand why depressed people tend to be insomnia, it’s caused by despair. You cannot go to sleep when tomorrow also sucks.","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[]},{"title":"The meaning of life","slug":"The-meaning-of-life","date":"2018-03-05T10:53:53.000Z","updated":"2018-03-06T00:00:48.819Z","comments":true,"path":"2018/03/05/The-meaning-of-life/","link":"","permalink":"http://searene.me/2018/03/05/The-meaning-of-life/","excerpt":"","text":"I’ve been pretty busy since joining the new company, but finally I get some time to write a blog today, so I decided to discuss a question that has been baffling me for a long time, The Meaning Of Life. The question came into my head when I was studying for a master degree. I never pondered over it before, and when it hit me, the first and obvious answer I could think of, was that Life had no meaning at all. I guess I was just too lonely, and I had been quiet for a long time, which may be the reason why I started to question it. And I guess there is high likelihood that people who suffer in their lives would ask the same question, due to some obvious reasons: We are mortal, which means whatever we do, it will disappear someday, which proves the meaninglessness of our lives. Although life is meaningless, we still have to suffer in this world, because this world is cruel and we are afraid to die. I learned a word nihilism when I was learning English, the definition of this word is as follows(From Longman DOCE). the belief that nothing has any meaning or value Now that I think about it, this is exactly what I described above. And there have to be a lot of people harboring the same thoughts, because there even exists a specific word here describing it! I think the thoughts mainly exist in people who suffer, who are depressed, because life is both hard and meaningless, and that’s why some people choose to commit suicide in the end, there’s just no hope in their lives. We have the above points to describe our problem, and we even have a terminology to concentrate our problem, now the question is, should we adopt it? If we adopt it, we concede the meaninglessness of our lives, which leads to the question that whether we should commit suicide to leave this horrible world. If we refuse to adopt it, we have to give enough evidence that life does have meaning and what we do has its own purpose in its own way. So what’s the answer? This is a hard question, but in my humble option, the answer is no, we should not adopt it. The reason is that, if everybody in this world adopts this mentality, our world would absolutely gets worse, which makes our lives even more miserable. But if we don’t adopt it, and think that life has some sort of purposes in its own way, we may strive to find it, or just do whatever we do to make us thrive, so this world would get better everyday, and maybe someday in the future, we will get an answer somewhere. But maybe you have noticed, I only described the outcome of our choice, I didn’t mention the answer of our ultimate question, what’s the meaning of our lives? Before trying to get the answer, let’s just try to recall why we would think about this question in the first place. You know why? Because we are suffering. Consider a life that is so easy, and you can enjoy all kinds of pleasure you can think of, would you asking this question in that situation? No, the only thing you would question is, why you are mortal? It’s obvious that you want to live forever in this wonderful world. So you see, it’s not about the question, it’s about why we would ask this question, there maybe two reasons. This world is horrible. We are not smart/lucky enough to live a good life in this world, and we are suffering because of it. About the first one, we cannot change this world, whether it’s good, horrible, the truth is, it already exists and there’s nothing we can do to change it. So it comes to the second one, I think this is actually the answer, we are not smart/lucky enough to live a good life. That’s the truth. If you were suffering and you knew that life was meaningless, suicide would become the final resort. Because by committing suicide, both the suffering and the question would be gone, they wouldn’t exist in your head any more. But it will also lead to the great sorrow of your beloved, it could easily crush them. So your death would destroy others’ lives, which may not be so bad otherwise. Think about it, it’s not an option. So we are back to the second point again. We are suffering, is there a solution? In most cases, yes, just do everything you can to make your life better. Don’t have money? Try to get a job. Hate your job? Just try to do better in your job or get a new job if you cannot handle the pain. Cannot get a job? Learn something, so you could be utilized by some company. In fact, some people can make their lives better just by changing their mentalities, but some people cannot, because they don’t have enough resources to change their lives. Image that you are handicapped, you have a pretty low IQ, you are extremely poor… God has a thousand ways to make your life miserable and you cannot even change it, what should you do? I want to talk about a person before answering the question. I once saw Nick in a video, and I was shocked. Nick is guy with no arms or legs, yet he managed to marry a beautiful wife and have several kids. He talked about his life for many times on the Internet, about how he was depressed and decided to commit suicide when he was only 10, and how he was pondering over God’s intention over and over again. But finally, he found the purpose of his life, which is to be an inspiration, to help others live a better life, because if he can do it, it’s obvious that most people should be able to do it. So, as you can see, maybe you haven’t tried the best of you, you should try harder, so you can live a better life, so you could be happy for the most of your time. So you can start to enjoy in this world, at least you are not making your life worse, which is very important. But what if you cannot? E.g. what if you have a pretty low IQ? I guess sometimes you just need to change your mentality. God only gives us limited resources, which means no matter how hard we try, we still cannot achieve something that is beyond our capabilities. That’s exactly why you should change your goal. The reason why you are unhappy is because you cannot get what you want. Just imagine, you would feel miserable if you are surrounded by rich business men, lucky guys, lottery winners, etc. You are nothing compared to them, you don’t have anything to show for in your life. What should you do? Maybe lower your goals is one option. I went to a template several days before, and I was pretty surprised by the sentences printed on the walls of the temple because it conforms to what I learned in the past few years. It says that our life is just a dream, all the fame and fortune are just hallucinations in our lives. Be calm and quiet, listen to yourself, don’t try to pursue the useless in your life, and only then will you find your purpose. I agree with most of them, if we cannot achieve what we want, we need to listen to our heart, is this really what we want? Money? Fame? Maybe that’s not what you want. Of course, money is necessary in your life, you need it to live. But what if you have enough of it to avoid hunger? Do you really need them in that situation? Maybe, or maybe not. It depends on your mentalities. It seems that your life would get better if you had more money? But is this really true? Not necessary. Many rich people choose to commit suicide. If more money means more happiness, then why they choose death? So if pursuing those things makes your miserable, just stop, your life may get better if you have a better mentality. Still, I’m struggling to make my life better. To figure out what I want, and to strive for them as hard as I can. I get pretty upset sometimes, because life is so cruel, but we have no other options. Try everything, and see what happens. Maybe we will get the answer to the ultimate question someday.","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[{"name":"life","slug":"life","permalink":"http://searene.me/tags/life/"}]},{"title":"We are either young or old, never something in between","slug":"We-are-either-young-or-old-never-something-in-between","date":"2018-01-20T07:55:01.000Z","updated":"2018-01-20T08:42:01.727Z","comments":true,"path":"2018/01/20/We-are-either-young-or-old-never-something-in-between/","link":"","permalink":"http://searene.me/2018/01/20/We-are-either-young-or-old-never-something-in-between/","excerpt":"","text":"Today I watched ビリギャル(垫底辣妹)，it told a story of how a bad student strove for a top university and finally succeeded. While moved by the movie plot, I also realized I was not a student any more, life would never the same. I remember that my teacher often told me school might be the best place you could ever stay in your entire life, where there was no trouble , no frustration, you got a lot of classmates to study with, to play with, to strive for the same goal together with. Life would never be the same when you went to the society, where life might become so unfair and frustrating to the extent that you had never imagine. Well, this is so true, but this is not the worst part. The worst part is you will never be as young as before. You have to grow up, grow old, and grow older, until someday you start wondering what is going wrong with you. But actually nothing is going wrong, this is just life. I once heard a theory that you would only consider yourself as young, or old in the audience, never something in between. It’s true. Life flies by so fast, you may not even notice that. And here we are, 2018, I didn’t notice it either. But it came, so I became older, once again. I cannot prevent the process, and the process will be faster and faster as we grow older. I miss those days when I was still in school, when everything was new. When I still believed in love, when I had lots of friends to play with, when I still looked forward to the future. It’s not the same any more. No matter how hard I strive, I will never get younger. Not to say that my life isn’t getting better, either. Every day is an ordinary day, every day is the same. I go to work, I earn my money, then I don’t know what to do with my money, I just want to go back to the past, when I don’t have money but I’m still young, when everything is possible.","categories":[{"name":"Journey","slug":"Journey","permalink":"http://searene.me/categories/Journey/"}],"tags":[]},{"title":"Write Machine Learning Algorithms From Scratch: Random Forest","slug":"Write-Machine-Learning-Algorithms-From-Scratch-Random-Forest","date":"2017-12-23T02:14:33.000Z","updated":"2018-01-09T15:24:17.817Z","comments":true,"path":"2017/12/23/Write-Machine-Learning-Algorithms-From-Scratch-Random-Forest/","link":"","permalink":"http://searene.me/2017/12/23/Write-Machine-Learning-Algorithms-From-Scratch-Random-Forest/","excerpt":"","text":"IntroductionRandom Forest is a supervised classification algorithm, it can classify data according to various given features. Assuming that we want to determine whether a person is male or female according to his/her weight, height and 100m-race time. Training data is as follows. Person Weight(kg) Height(meter) 100m-race time(second) Gender A 50 1.62 18 Female B 70 1.81 16 Male C 60 1.72 15 Female D 70 1.71 19 Male E 52 1.69 17 Female We can load these data and train them with the random forest classification algorithm. The model obtained from training could be used for prediction. E.g., We will be able to predict this person’s gender using the trained model. Weight(kg) Height(meter) 100m-race time(second) 60 1.62 16 Notice that we will mainly focus on how to use random forest and how to write the algorithm from scratch. We won’t dive into the esoteric mathematical principles behind it. After finishing this post, you will be able to understand various parameters seen in third-party random forest implementations. All the code mentioned in the post is available for download. So please refer to the code if there’s anything unclear in the post. ExecutionLet’s first run the code that we will write, so we could know what it’s like. Install Python3 Download code 1git clone git@github.com:searene/demos.git &amp;&amp; cd demos/RandomForest Download Dependencies 1pip install numpy pandas Execution 1234567python evaluate_random_forest.pyAverage cross validation accuracy for 1 trees: 0.6887700534759359Test accuracy for 1 trees: 0.6190476190476191Average cross validation accuracy for 3 trees: 0.6898395721925135Test accuracy for 3 trees: 0.8571428571428571Average cross validation accuracy for 10 trees: 0.6983957219251338Test accuracy for 10 trees: 0.7619047619047619 So you can see that, we get the highest accuracy with 3 trees, which is about 85%. How It WorksRandom Forest is rather complex, so let’s use an example. Person Weight(kg) Height(meter) 100m-race time(second) Gender A 50 1.62 18 Female B 70 1.81 16 Male C 60 1.72 15 Female D 70 1.71 19 Male E 52 1.69 17 Female We mentioned before that we could use these data to train our random forest model, in order to predict new items. So how to train? In fact, training is equivalent to building a tree here. Steps are as follows. Based on D’s height, anyone whose height is less or equal to 1.71m belong to one group, and anyone whose height is greater than 1.71m belong to another group, then we get two groups(Don’t think too much about why to split in this way, this is just an example, we will talk about the reason in detail later). 1234 A, B, C, D, E / \\ / \\A, D, E B, C For group A, D, E, based on A’s 100m-race time, anyone whose time is less or equal to 18s belong to one group, and anyone whose time is greater than 18s belong to another group. The same goes to group B, C. Based on C’s height, anyone whose height is less than or equal to 1.72m belong to one group, and anyone whose height is greater than 1.72m belong to another group. After splitting, we get a tree like this. 1234567 A, B, C, D, E / \\ / \\ B, C A, D, E / \\ / \\ / \\ / \\C B A, E D Now only group A, E could be further split. So let’s base on A’s weight, anyone whose weight is less than or equal to 50kg belong to one group, and anyone whose weight is greater than 50kg belong to another group. After that, we mark each leaf node with their genders. 12345678910 A, B, C, D, E / \\ / \\ B, C A, D, E / \\ / \\ / \\ / \\C(F) B(M) A, E D(M) / \\ / \\ A(F) E(M) That’s it, a tree in the random forest! Now we can use this tree to predict new data. Assuming we want to predict this person’s gender: Weight(kg) Height(meter) 100m-race time(second) 60 1.62 16 Just like training, this person’s height is 1.62m, which is less than or equal to 1.71, so he/she belongs to group B, C in the second layer. Again, compare based on his/her height, which is less than or equal to 1.72m, so he/she belongs to leaf node C, which means the prediction result is Female. This is the whole process of prediction. The Principle To Split A Tree Into Two Groups In the above example, we first split the whole data into two groups according to D’s height, then continue to split them according to D’s height, A’s weight, etc. What’s going on here? It seemed that we were casually splitting the data with no principle. OK, I concede that it’s true. I just want to show you guys how to build a random forest tree. In fact, the genuine tree-building-process would split the data according to gini index. E.g., assuming we split the data according to A’s weight, we will get two groups of data: A and B, C, D, E. Let’s call them group1 and group2 respectively, then we can calculate gini index according to the following equation. $gini$ = [1 - (the number of males in group1 / the number of people in group1)$^2$ - (the number of females in group1 / the number of people in group1)$^2$] $\\times$ (the number of people in group1 / the total number of people in both groups) + [1 - (the number of males in group2 / the number of people in group2)$^2$ - (the number of females in group2 / the number of people in group2)$^2$] $\\times$ (the number of people in group2 / the total number of people in both groups) So the gini index should be calculated as follows if we split the data based on A’s weight.$$ gini = 0 + (1 - 0.25 - 0.25) \\times 0.8 = 0.4$$ We can also split the data based on A’s height, to get another gini index.$$ gini = 0 + (1 - 0.25 - 0.25) \\times 0.8 = 0.4$$We can also split based on A’s 100m-race time, B’s weight, B’s height, …, E’s 100m-race time, 3 x 5 = 15 ways in total. We calculate the gini index for each of the 15 ways, and choose the one with the smallest gini index. So we should split based on D’s weight if we got the smallest gini index based on D’s weight. Why choose the smallest one? Because the smaller gini index is, the purer each group will be. We are not going to dive into the reason in detail here because it’s more about the math rather than the implementation. The code to calculate gini index is as follows. 1234567891011def get_gini_index(left, right, categories): gini_index = 0 for group in left, right: if len(group) == 0: continue score = 0 for category in categories: p = [row[-1] for row in group].count(category) / len(group) score += p * p gini_index += (1 - score) * (len(group) / len(left + right)) return gini_index We use the above piece of code in this way: 123456789A = [50, 1.62, 18, 'Female']B = [70, 1.81, 16, 'Male']C = [60, 1.72, 15, 'Female']D = [70, 1.71, 19, 'Male']E = [52, 1.69, 17, 'Female']left = [A]right = [B, C, D, E]gini_index = get_gini_index(left, right, ['Male', 'Female'])print(gini_index) # 0.4 Use multiple trees to boost the accuracyYou may wonder why it’s called the random forest when we only used one tree? Good question! In fact, we shouldn’t only use one tree. The correct process is as follows. Choose 90% of the data randomly for training. Train those data, i.e. the process of building a tree shown above. Use this tree to predict, get the prediction x. Repeat the above three steps, build another tree, get another prediction y. Repeat the first three steps again, get another prediction z. Choose the one that appears the most in x, y, z, which should be our final prediction, return it. So you should know why it’s call random forest, right? We built 3 trees in total, and got the final result based on 3 predictions obtained from 3 trees. The number 3 can be changed, too. You can also build 5 trees, 10 trees, etc., whatever works out for you. Moreover, the sampling ratio 90% can be changed, too. 80%, 70%, whatever you like. The purpose of building multiple trees is to avoid overfitting. From Wikipedia: In statistics, overfitting is “the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably”. CodeNow that we know how it works, it’s time for us to dive into the code. Notice that some parameters in the code are not mentioned before, so let’s review them together. min_size: when the number of data in some node is less than min_size, further splitting is not allowed. I.e., the current group is taken as a leaf node, the value of the leaf node is determined by the category that appears the most in the group. max_depth: The maximum depth of a tree, further splitting is not allowed when max_depth is exceeded, the value of the node is determined by the category that appears the most in the group. n_features: The number of features chosen to build the current tree. In case if you don’t know what a feature is, weight, height, 100m-race time are both called features in the previous example. We choose n_features features for training each time we build a tree. In this way, features used in each tree is different, which means the final trees we build will be different, so overfitting could be avoid. Code to implement random forest is as follows. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124import randomclass Node: def __init__(self, data): # all the data that is held by this node self.data = data # left child node self.left = None # right child node self.right = None # category if the current node is a leaf node self.category = None # a tuple: (row, column), representing the point where we split the data # into the left/right node self.split_point = Nonedef build_model(train_data, n_trees, max_depth, min_size, n_features, n_sample_rate): trees = [] for i in range(n_trees): random.shuffle(train_data) n_samples = int(len(train_data) * n_sample_rate) tree = build_tree(train_data[: n_samples], 1, max_depth, min_size, n_features) trees.append(tree) return treesdef predict_with_single_tree(tree, row): if tree.category is not None: return tree.category x, y = tree.split_point split_value = tree.data[x][y] if row[y] &lt;= split_value: return predict_with_single_tree(tree.left, row) else: return predict_with_single_tree(tree.right, row)def predict(trees, row): prediction = [] for tree in trees: prediction.append(predict_with_single_tree(tree, row)) return max(set(prediction), key=prediction.count)def get_most_common_category(data): categories = [row[-1] for row in data] return max(set(categories), key=categories.count)def build_tree(train_data, depth, max_depth, min_size, n_features): root = Node(train_data) x, y = get_split_point(train_data, n_features) left_group, right_group = split(train_data, x, y) if len(left_group) == 0 or len(right_group) == 0 or depth &gt;= max_depth: root.category = get_most_common_category(left_group + right_group) else: root.split_point = (x, y) if len(left_group) &lt; min_size: root.left = Node(left_group) root.left.category = get_most_common_category(left_group) else: root.left = build_tree(left_group, depth + 1, max_depth, min_size, n_features) if len(right_group) &lt; min_size: root.right = Node(right_group) root.right.category = get_most_common_category(right_group) else: root.right = build_tree(right_group, depth + 1, max_depth, min_size, n_features) return rootdef get_features(n_selected_features, n_total_features): features = [i for i in range(n_total_features)] random.shuffle(features) return features[:n_selected_features]def get_categories(data): return set([row[-1] for row in data])def get_split_point(data, n_features): n_total_features = len(data[0]) - 1 features = get_features(n_features, n_total_features) categories = get_categories(data) x, y, gini_index = None, None, None for index in range(len(data)): for feature in features: left, right = split(data, index, feature) current_gini_index = get_gini_index(left, right, categories) if gini_index is None or current_gini_index &lt; gini_index: x, y, gini_index = index, feature, current_gini_index return x, ydef get_gini_index(left, right, categories): gini_index = 0 for group in left, right: if len(group) == 0: continue score = 0 for category in categories: p = [row[-1] for row in group].count(category) / len(group) score += p * p gini_index += (1 - score) * (len(group) / len(left + right)) return gini_indexdef split(data, x, y): split_value = data[x][y] left, right = [], [] for row in data: if row[y] &lt;= split_value: left.append(row) else: right.append(row) return left, right So how to use this piece of code? Let’s take Sonar, which is real-life data as an example(You can have a glimpse of its contents in here). The last column in Sonar represents category, which are two of them in total, R and M. R means rock and M means metal. The first 60 columns represents data obtained by bouncing sonar signals off a surface(R or M) at various angles and under various conditions. Let’s load these data and split them into two groups, one for training and one for testing. Training data is used to build models, and test data is used to check the accuracy of the model. The code is as follows. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576import randomimport numpy as npimport pandas as pdfrom math import sqrtfrom random_forest import build_model, predictclass CrossValidationSplitter: def __init__(self, data, k_fold): self.data = data self.k_fold = k_fold self.n_iteration = 0 def __iter__(self): return self def __next__(self): if self.n_iteration &gt;= self.k_fold: raise StopIteration self.n_iteration += 1 return self.__load_data() def __load_data(self): n_train_data = (1 / self.k_fold) * len(self.data) data_copy = self.data[:] train_data = [] while len(train_data) &lt; n_train_data: train_data.append(self.__pop_random_row(data_copy)) test_data = data_copy return train_data, test_data def __pop_random_row(self, data): random.shuffle(data) return data[0]def split_data(data, rate): random.shuffle(data) n_train_data = int(len(data) * rate) return data[: n_train_data], data[n_train_data:]def calculate_accuracy(model, validate_data): n_total = 0 n_correct = 0 predicted_categories = [predict(model, row[:-1]) for row in validate_data] correct_categories = [row[-1] for row in validate_data] for predicted_category, correct_category in zip(predicted_categories, correct_categories): n_total += 1 if predicted_category == correct_category: n_correct += 1 return n_correct / n_totaldf = pd.read_csv('resources/sonar.all-data.csv', header=None)data = df.values.tolist()train_data_all, test_data = split_data(data, 0.9)for n_tree in [1, 3, 10]: accuracies = [] cross_validation_splitter = CrossValidationSplitter(train_data_all, 5) model = None for train_data, validate_data in cross_validation_splitter: n_features = int(sqrt(len(train_data[0]) - 1)) model = build_model( train_data=train_data, n_trees=n_tree, max_depth=5, min_size=1, n_features=n_features, n_sample_rate=0.9 ) accuracies.append(calculate_accuracy(model, validate_data)) print(\"Average cross validation accuracy for &#123;&#125; trees: &#123;&#125;\".format(n_tree, np.mean(accuracies))) print(\"Test accuracy for &#123;&#125; trees: &#123;&#125;\".format(n_tree, calculate_accuracy(model, test_data))) The result is as follows. 123456Average cross validation accuracy for 1 trees: 0.6887700534759359Test accuracy for 1 trees: 0.6190476190476191Average cross validation accuracy for 3 trees: 0.6898395721925135Test accuracy for 3 trees: 0.8571428571428571Average cross validation accuracy for 10 trees: 0.6983957219251338Test accuracy for 10 trees: 0.7619047619047619 As you can see, we get the highest accuracy with 3 trees(around 85%), we have reason to believe that we could get a better result if further tunning is conducted.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"http://searene.me/tags/machine-learning/"}]},{"title":"My Last Weekend At Cisco","slug":"My-Last-Weekend-At-Cisco","date":"2017-12-17T09:05:54.000Z","updated":"2017-12-17T09:57:20.373Z","comments":true,"path":"2017/12/17/My-Last-Weekend-At-Cisco/","link":"","permalink":"http://searene.me/2017/12/17/My-Last-Weekend-At-Cisco/","excerpt":"","text":"Today is my last weekend at Cisco, and I’m about to leave the company at the next Friday. My next employer is Alibaba, which is more cruel and fierce than Cisco, I’m not sure if this is the right choice, maybe there is no right choice at all. I remember that when I arrived at Hangzhou one and a half years ago, my ID card was just expired. And since Hangzhou was holding the G20 event at that time, no hotel dared to accept me. So I wandered around the street for the whole night, and what was worse, since I was carrying my baggage, I couldn’t sleep for a single minute because I was afraid my baggage could be stolen by some random guy on the street. It was blazing hot at the time, I walked into an ATM booth and tried to sleep there because it had an air conditioner, but I was asked out after several minutes since sleeping in there was not allowed. While I was walking on the street, I thought a lot. I thought about why I would choose Hangzhou, why this world was so terrible, why everything was falling into the wrong place. Finally the sun rose and I called my friends at Hangzhou so I could have a rest at his house for a while. I rent a house that afternoon, which I’m still living in it. All right, besides those nonsense, it’s time for me to talk about Cisco. Cisco is a really good company, I mean, really good. I could never imagine a company so kind, it gives the best to the employees. It’s also a good thing for me to join such a company on graduation, so I could know that there are still good companies out there, that care about its employees, even in this more and more competitive society. I chose Alibaba so I could learn cooler stuff, and it offered a higher salary package. I couldn’t find a concrete reason to decline the offer, so I joined. No matter whether I would thrive or suffer in the new company, I have to accept. I’m about to turn 30 in the next few years, yet I’m still lonely. Maybe I’ve said too much, while staying at the office, all alone.","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[]},{"title":"Use Deep Learning to Detect Programming Languages","slug":"use-neural-networks-to-detect-programming-languages","date":"2017-11-26T07:56:45.000Z","updated":"2017-12-09T10:10:51.110Z","comments":true,"path":"2017/11/26/use-neural-networks-to-detect-programming-languages/","link":"","permalink":"http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/","excerpt":"","text":"IntroductionThis post introduces a way to use deep learning to detect programming languages. Take the following code as an example. 12def test(): print(\"something\") We will get an answer python if we use the program to be introduced in the post to detect the language of the above code, which is also the correct answer. In fact, through a preliminary test, the accuracy of the program is around 90%. We have reason to believe that we are able to get a better result if the training dataset is larger or further tuning is conducted. ExecutionFirst let’s try running the program, so we can have an intuitive perspective on what the program is about. Install third-party libraries Anaconda(Python 3.6+) Gensim 1conda install -c anaconda gensim Keras 1conda install -c conda-forge keras Tensorflow 1pip install tensorflow==1.3.0 Download the program 1git clone git@github.com:searene/demos.git &amp;&amp; cd demos/PLDetector-demo Train the model 123456789101112131415161718192021222324252627282930313233343536373839404142python -m src.neural_network_trainer Using TensorFlow backend. ..._________________________________________________________________Layer (type) Output Shape Param #=================================================================embedding_1 (Embedding) (None, 500, 100) 773100_________________________________________________________________conv1d_1 (Conv1D) (None, 496, 128) 64128 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 248, 128) 0 _________________________________________________________________ flatten_1 (Flatten) (None, 31744) 0 _________________________________________________________________ dense_1 (Dense) (None, 8) 253960 ================================================================= Total params: 1,091,188 Trainable params: 318,088Non-trainable params: 773,100_________________________________________________________________INFO:root:NoneEpoch 1/10 - 1s - loss: 0.4304 - acc: 0.8823Epoch 2/10 - 1s - loss: 0.1357 - acc: 0.9657Epoch 3/10 - 1s - loss: 0.0706 - acc: 0.9788Epoch 4/10 - 1s - loss: 0.0392 - acc: 0.9887Epoch 5/10 - 1s - loss: 0.0266 - acc: 0.9927Epoch 6/10 - 1s - loss: 0.0203 - acc: 0.9945Epoch 7/10 - 1s - loss: 0.0169 - acc: 0.9948Epoch 8/10 - 1s - loss: 0.0145 - acc: 0.9956Epoch 9/10 - 1s - loss: 0.0131 - acc: 0.9959 Epoch 10/10 - 1s - loss: 0.0120 - acc: 0.9959 INFO:root:Test Accuracy: 94.642857 We will have three important files as soon as the above step is completed. resources/models/model.h5 resources/models/model.json resources/vocab_tokenizer We will introduce the three files in detail later on. Detection 1234python -m src.detectorUsing TensorFlow backend.Python The following python code is detected by default by detector.py 12def test(): print(\"something\") Of course you can modify detector.py to detect other code. Project StructureLet’s first have a rough idea of the project structure. Don’t worry, it will only take 1 ~ 2 minutes. resources/code/train: training data. The name of each subfolder representes a programming language. There are around 10 code files in each subfolder, i.e. 10 files per programming language for training. resources/code/test: the same as resources/code/train except that it’s used for testing accuracy instead of training. models directory &amp; vocab_tokenizer: stored training result src/config.py: some constants used in the program src/neural_network_trainer.py: code used to train the model src/detector.py: code used to load the model and detect programming languages How It WorksConstruct Vocabularylet’s first get our heads around the training process, aka the contents in neural_network_trainer.py. the first step to train the neural network is to build a vocabulary. Vocabulary is actually a list of words, which consists of some common words in the training data. When we are done with building a vocabulary and start detecting the programming language, we will try splitting the code into a list of words, and remove those which are not in the vocabulary, then we put the remaining words into the neural network for detection. OK, you might want to ask, why removing words that are not in the vocabulary? Wouldn’t it work if we just put all the words into the neural network? Actually, this is impossible. Because each word in the vocabulary is mapped to a word vector, which is constructed during training. So words that are not in the vocabulary don’t have word vectors to map, which means the neural network is unable to process this word. So how do we build the vocabulary? It’s fairly easy, we just need to scan all the code in resources/code/train and extract common words in it. Those common words will make up our vocabulary. Key code is as follows. 1234567891011def build_vocab(train_data_dir): vocabulary = Counter() files = get_files(train_data_dir) for f in files: words = load_words_from_file(f) vocabulary.update(words) # remove rare words min_count = 5 vocabulary = [word for word, count in vocabulary.items() if count &gt;= min_count] return vocabulary Run build_vocab to get the vocabulary. 12vocab = build_vocab(config.train_data_dir)print(vocab) # [..., 'script', 'text', 'head', 'appendChild', 'parentNode', 'removeChild', ...] So, as you can see, the vocabulary is just a list of words, that’s it. Build vocab_tokenizerThe next step is to build vocab_tokenizer. So what is vocab_tokenzier? It’s a simple variable, you can imagine it as a dictionary, which maps each word in the vocabulary to a number. Why would we map those words to numbers? Because our neural network is only able to run with numbers, rather than strings. We use Tokenizer provided by Keras to build vocab_tokenizer. 1234def build_vocab_tokenizer_from_set(vocab): vocab_tokenizer = Tokenizer(lower=False, filters=\"\") vocab_tokenizer.fit_on_texts(vocab) return vocab_tokenizer Then we save this vocab_tokenizer as a file, to be used later. 123def save_vocab_tokenizer(vocab_tokenzier_location, vocab_tokenizer): with open(vocab_tokenzier_location, 'wb') as f: pickle.dump(vocab_tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL) Build Word VectorsBefore diving into word vectors, we first need to know what they are. To put it simply, word vectors are just vectors, and each word in the vocabulary is mapped to a word vector. You may still not get it. This may seem too simple, let’s take the following Java code as an example. 123public static void main(String[] args) &#123; System.out.println(\"something\")&#125; The word2vec variable we are building here is actually a dictionary, which is like this(word -&gt; word_vector). 1234567891011word2vec = &#123; 'public': [2, 1, 10], 'static': [2, 1, 9], 'main': [1, 10, 3], 'String': [1, 20, 3], 'args': [1, 40, 3], 'System': [20, 10, 3], 'out': [3, 10, 3], 'println': [1, 39, 3], 'something': [1, 20, 3]&#125; Here comes the question. Why would we build word vectors, instead of just using the number given by vocab_tokenizer? This is because word vectors have a very special and useful characteristic: The more close two words are, the smaller their word vectors are(Note that the calculation of the distance between vectors are of the field of math, which can be dealt with using multiple methods. It doesn’t matter if you don’t know how to calculate it, you only need to know the distance between vectors can be calculated). This characteristic will boost the accuracy of our neural network dramatically. For example, public and staic are only seen together in Java, so the distance between their word vectors should be small. However, public and System is not that close, i.e. we may only see one of them at a time, so the distance between their word vectors are larger. Now that we know why it is necessary to build word vectors, the next problem is how we build them. There are multiple ways to do it. Here we use the Word2Vec algorithm provided by gensim to achieve it. Steps are as follows. Load all the training data, extract those words which are in the vocabulary. Map each word into its respective number by using vocab_tokenizer. Put those numbers into Word2Vec library and obtain word vectors. The code is as follows. 12345678def build_word2vec(train_data_dir, vocab_tokenizer): all_words = [] files = get_files(train_data_dir) for f in files: words = load_words_from_file(f) all_words.append([word for word in words if is_in_vocab(word, vocab_tokenizer)]) model = Word2Vec(all_words, size=100, window=5, workers=8, min_count=1) return &#123;word: model[word] for word in model.wv.index2word&#125; Build the Neural NetworkEverything is ready, now it’s the time to train the neural network! First we need to know the input and output of the neural network, take the following code as an example. 12def test(): print(\"something\") Map def, test, print and something into their respective numbers, we get the input 1input = [0, 1, 2, 3] The output of the neural network is the probability of each language. 1output = [0.5, 0.1, 0.04, 0.06, 0.1, 0.1, 0.05, 0.05] The code is as follows. 1all_languages = [\"Python\", \"C\", \"Java\", \"Scala\", \"Javascript\", \"CSS\", \"C#\", \"HTML\"] So we know the above code is most likely to be written by Python, because Python has the most probability(0.5) Now that we know the input and output, let me introduce how the neural network is constructed. There are three parts in total. Embedding Layer: it’s used to map each word into its respective word vector Conv1D, MaxPooling1D: this part is a classic deep learning layer. To put it simply, what it does is extraction and transformation. Refer to corresponding tutorials of deep learning for details. Flatten, Dense: convert the multi-dimensional array into one-dimensional, and output the prediction. Key code is as follows. 1234567891011121314151617181920def build_model(train_data_dir, vocab_tokenizer, word2vec): weight_matrix = build_weight_matrix(vocab_tokenizer, word2vec) # build the embedding layer input_dim = len(vocab_tokenizer.word_index) + 1 output_dim = get_word2vec_dimension(word2vec) x_train, y_train = load_data(train_data_dir, vocab_tokenizer) embedding_layer = Embedding(input_dim, output_dim, weights=[weight_matrix], input_length=input_length, trainable=False) model = Sequential() model.add(embedding_layer) model.add(Conv1D(filters=128, kernel_size=5, activation=\"relu\")) model.add(MaxPooling1D(pool_size=2)) model.add(Flatten()) model.add(Dense(len(all_languages), activation=\"sigmoid\")) logging.info(model.summary()) model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) model.fit(x_train, y_train, epochs=10, verbose=2) return model All right, we built our neural network, not a trivial achievement! Then let’s write a function, which uses the neural network to detect test code, check out its accuracy. 1234def evaluate_model(test_data_dir, vocab_tokenizer, model): x_test, y_test = load_data(test_data_dir, vocab_tokenizer) loss, acc = model.evaluate(x_test, y_test, verbose=0) logging.info('Test Accuracy: %f' % (acc * 100)) As what we have got before, the test accuracy is around 94%~95%, which is good enough. Let’s save the neural network as files, so we can load it when detecting. 12345def save_model(model, model_file_location, weights_file_location): os.makedirs(os.path.dirname(model_file_location), exist_ok=True) with open(model_file_location, \"w\") as f: f.write(model.to_json()) model.save_weights(weights_file_location) Load the Neural Network For DetectionThis part is simple, we only need to load vocab_tokenizer and the neural network for detection. The code is as follows. 1234567891011121314vocab_tokenizer = load_vocab_tokenizer(config.vocab_tokenizer_location)model = load_model(config.model_file_location, config.weights_file_location)def to_language(binary_list): i = np.argmax(binary_list) return all_languages[i]def get_neural_network_input(code): encoded_sentence = load_encoded_sentence_from_string(code, vocab_tokenizer) return pad_sequences([encoded_sentence], maxlen=input_length)def detect(code): y_proba = model.predict(get_neural_network_input(code)) return to_language(y_proba) Use it like this. 12345code = \"\"\"def test(): print(\"something\")\"\"\"print(detect(code)) # Python SummaryAll in all, here are the steps to build the neural network. Build vocabulary. Build vocab_tokenizer using vocabulary, which is used to convert words into numbers. Load words into Word2Vec to build word vectors. Load word vectors into the neural network as part of the input layer. Load all the training data, extract words that are in the vocabulary, convert them into numbers using vocab_tokenizer, load them into the neural network for training. Three steps for detection: Extract words in the code and remove those that are not in the vocabulary. Convert those words into number through vocab_tokenizer, and load them into the neural network. Choose the language which has the most probability, which the answer we want. ExerciseYou may have already found out that, we only saved vocab_tokenizer and the neural network(which lies in the model directory), why didn’t we save word2vec and vocab? QuestionIf you have any question, please leave it in the comment below, I’ll try to answer it.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"Neural Network","slug":"Neural-Network","permalink":"http://searene.me/tags/Neural-Network/"}]},{"title":"Right associativity in Scala","slug":"Right-associativity-in-Scala","date":"2017-10-07T05:07:50.000Z","updated":"2017-10-07T05:56:44.634Z","comments":true,"path":"2017/10/07/Right-associativity-in-Scala/","link":"","permalink":"http://searene.me/2017/10/07/Right-associativity-in-Scala/","excerpt":"","text":"We define two methods here, ++ and ++: 1234567891011class Foo &#123; def ++(n: Int): Unit = println(n + 1) def ++:(n: Int): Unit = println(n + 1)&#125;object ValFunctionTest &#123; def main(args: Array[String]): Unit = &#123; val foo = new Foo foo.++(1) foo.++:(1) &#125;&#125; Nothing special, right? Yes, for now, until we try removing the parentheses in it. 1234567891011121314class Foo &#123; def ++(n: Int): Unit = println(n + 1) def ++:(n: Int): Unit = println(n + 1)&#125;object ValFunctionTest &#123; def main(args: Array[String]): Unit = &#123; val foo = new Foo foo ++ 1 1 ++: foo foo ++: 1 // error 1 ++ foo // error &#125;&#125; So the difference is, foo can only be placed on the left side when using ++, and it can only be placed on right side when using ++:. The latter is called right associativity, and methods ending with : are used in the right associativity.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"Scala","slug":"Scala","permalink":"http://searene.me/tags/Scala/"}]},{"title":"Cast away on the moon","slug":"Cast-away-on-the-moon","date":"2017-10-06T02:36:40.000Z","updated":"2017-10-06T03:25:27.836Z","comments":true,"path":"2017/10/06/Cast-away-on-the-moon/","link":"","permalink":"http://searene.me/2017/10/06/Cast-away-on-the-moon/","excerpt":"","text":"I watched a movie these days, it’s called Cast Away on the Moon(or 金氏漂流记 , 김씨 표류기). A man was saddled with debts of more than $20,000, and he couldn’t afford to pay it off. One day he jumped off a bridge to kill himself, but he didn’t die. He was cast away on an island across the city, although he could see the city from the island, there was no way for him to get out of it. To the end of his rope, he decided to live on this island. He pulled a discarded sightseeing boat and took it as his home. While day dreaming in the free time, he recalled one of his favorite food, noodles, and decided to grow corn and make a bowl of noodles as his goal. In the mean time, a girl, who seemed to be a social phobia patient, was watching him closely using her telescope. After a long time of thinking and struggling, she threw a bottle in the river, which also drifted on the island. Of course it was not only a bottle, there was a piece of paper in it, which said “Hello”. The man found this bottle and the piece of paper, then he replied to the girl “How are you?” on the beach. They kept communicating with each other in this way. Finally the man was taken away from the island by force. The girl noticed that and struggled for a long time, then she broke out of her house and ran as fast as she can to meet this man, because it might be the last chance for her to meet him. The end of the story is a lovely one, because they met in the end. I vividly remember a scene in the movie. The girl called a takeaway, which was three bowls of noodles to the man, but the man refused. He said making a bowl of noodles was his dream and he didn’t want to ruin it by accepting the girl’s takeaway. This was so true. While living in this world, we can be broken, we can be poor, but we cannot lose hope. Because with hope, we may still have a chance to get what we want, at least we can enjoy the process, no matter it’s achieved or not. But without hope, nothing is important any more, even if you seem to have everything in the eyes of others. That’s all, it’s a beautiful movie and has a beautiful girl. I hope I can meet my girl someday, but I don’t know how long it will take, or whether I can meet her at all.","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[]},{"title":"The difference between a case class and a normal class in Scala","slug":"The-difference-between-a-case-class-and-a-normal-class-in-Scala","date":"2017-10-06T01:03:48.000Z","updated":"2017-10-06T09:05:46.789Z","comments":true,"path":"2017/10/06/The-difference-between-a-case-class-and-a-normal-class-in-Scala/","link":"","permalink":"http://searene.me/2017/10/06/The-difference-between-a-case-class-and-a-normal-class-in-Scala/","excerpt":"","text":"What is a case class like12345678case class Person(name: String)object CaseClassTest &#123; def main(args: Array[String]): Unit = &#123; val person = Person(\"John\") println(person.toString) &#125;&#125; Can be Instantiated without the new keywordCase classes have prebuilt companion objects with apply() implemented, so a case class can be instantiated without using new. 12345678910case class Person(name: String)object CaseClassTest &#123; def main(args: Array[String]): Unit = &#123; // Both ways have the same effect val person1 = Person(\"John\") val person2 = new Person(\"John\") &#125;&#125; Why removing the new keyword? Because case classes are often used to implement algebraic data types, it’s more elegant to do so without the new keyword. Default equals and hashCode implementationCase classes have default equals and hashCode implementations. Let’s pick equals and talk about it in this part, because it’s easier to verify. 123456789case class Person(name: String)object CaseClassTest &#123; def main(args: Array[String]): Unit = &#123; val person1 = Person(\"John\") val person2 = Person(\"John\") println(person1 == person2) // true &#125;&#125; Because Case classes have default equals implementation, so although person1 and person2 are different objects(I’m talking about their references), they are still equal because Scala only checks field values(name in this case) for case classes. The result is different if we use a normal class, which compares equality by references. 123456789class Person(name: String)object CaseClassTest &#123; def main(args: Array[String]): Unit = &#123; val person1 = new Person(\"John\") val person2 = new Person(\"John\") println(person1 == person2) // false &#125;&#125; SerializableCase classes can be serialized. 12345678910111213141516import java.io.&#123;FileOutputStream, ObjectOutputStream&#125;case class Person(name: String)object CaseClassTest &#123; def main(args: Array[String]): Unit = &#123; // creat an instance val person = Person(\"John\") // serialize val oos = new ObjectOutputStream(new FileOutputStream(\"/tmp/person\")) oos.writeObject(person) oos.close() &#125;&#125; A normal class cannot be serialized by default. 1234567891011121314class Person(name: String)object CaseClassTest &#123; def main(args: Array[String]): Unit = &#123; // creat an instance val person = new Person(\"John\") // serialize val oos = new ObjectOutputStream(new FileOutputStream(\"/tmp/person\")) oos.writeObject(person) // Exception in thread \"main\" java.io.NotSerializableException: com.example.Person oos.close() &#125;&#125; Better toString123456789101112131415package com.examplecase class Person(name: String)class Animal(name: String)object CaseClassTest &#123; def main(args: Array[String]): Unit = &#123; val person = Person(\"John\") val animal = new Animal(\"Dog\") println(person.toString) // Person(John) println(animal.toString) // com.example.Animal@5a39699c &#125;&#125; Pattern MatchingCase classes support pattern matching. 123456789101112131415161718package com.exampleabstract class Animalcase class Dog() extends Animalcase class Cat() extends Animalobject CaseClassTest &#123; def main(args: Array[String]): Unit = &#123; val animal = Dog() printType(animal) &#125; def printType(animal: Animal): Unit = &#123; animal match &#123; case Dog() =&gt; println(\"It's a dog.\") case Cat() =&gt; println(\"It's a cat.\") &#125; &#125;&#125; Can we achieve pattern matching using a normal class? Of course, just implement the unapply method, here is an example. 1234567891011121314151617181920212223242526package com.exampleabstract class Animalclass Dog() extends Animalclass Cat() extends Animalobject Dog &#123; def apply(): Dog = new Dog() def unapply(arg: Animal): Boolean = arg.isInstanceOf[Dog]&#125;object Cat &#123; def apply(): Cat = new Cat() def unapply(arg: Animal): Boolean = arg.isInstanceOf[Cat]&#125;object CaseClassTest &#123; def main(args: Array[String]): Unit = &#123; val animal = Dog() printType(animal) &#125; def printType(animal: Animal): Unit = &#123; animal match &#123; case Dog() =&gt; println(\"It's a dog.\") case Cat() =&gt; println(\"It's a cat.\") &#125; &#125;&#125; So we can use pattern matching with normal classes, but with case classes, we don’t need to write those boilerplate code any more. Case classes extend the Product classCase classes extend the Product class, so it has some methods inherited from it, like productArity 1234567case class Person(name: String, address: String)object CaseClassTest &#123; def main(args: Array[String]): Unit = &#123; val person = Person(\"John\", \"Earth\") println(person.productArity) // 2, the size of the product, i.e. the number of arguments &#125;&#125; Other Interesting stuffCase classes also have other interesting stuff, e.g. we can copy a case class by calling copy on it. 123456789101112case class Person(name: String, address: String)object CaseClassTest &#123; def main(args: Array[String]): Unit = &#123; val person = Person(\"John\", \"Earth\") val copiedPerson = person.copy() println(copiedPerson) // Person(John,Earth) val copiedPersonWithModifiedName = person.copy(\"Johnson\") println(copiedPersonWithModifiedName) // Person(Johnson,Earth) &#125;&#125; I think I’ve covered almost all the interesting parts of case classes, you can check the official Scala docs for more details.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"Scala","slug":"Scala","permalink":"http://searene.me/tags/Scala/"}]},{"title":"Some Linux Commands","slug":"Some-Linux_Commands","date":"2017-10-05T00:37:42.000Z","updated":"2017-10-05T03:57:24.113Z","comments":true,"path":"2017/10/05/Some-Linux_Commands/","link":"","permalink":"http://searene.me/2017/10/05/Some-Linux_Commands/","excerpt":"","text":":-Take ${val1:-val2} for example, if val1 is unset or null, return val2, otherwise return val1. Example: 123456#!/bin/bashdefault=\"default\"preset=\"preset\"value=\"This is $&#123;preset:-\"$default\"&#125; value\"echo $value # This is preset value 12345#!/bin/bashdefault=\"default\"value=\"This is $&#123;preset:-\"$default\"&#125; value\"echo $value # This is default value set -aDefinition from the Bash Manual -a Each variable or function that is created or modified is given the export attribute and marked for export to the environment of subsequent commands. Honestly I haven’t fully comprehended the definition, but we can set up an example to see what it does. Create foo.sh 12345678#!/usr/bin/env bashset -a. \"./bar.sh\"set +aecho \"a=$a\"echo \"b=$b\"echo \"c=$c\" Create bar.sh 12345#!/usr/bin/env basha=1b=2c=3 Set executable permission 12chmod +x foo.shchmod +x bar.sh Source foo.sh 1. ./foo.sh Result 123a=1b=2c=3 As you can see, we can access all the variables defined in bar.sh in foo.sh, just as if they are marked as export. If we didn’t use set -a, the result would be 123a=b=c= We can access it directly in the terminal too, they are exported all the way to the top bash environment. 123456➜ /tmp echo $a1➜ /tmp echo $b2➜ /tmp echo $c3 Bash Regular ExpressionsWe can use regular expressions with the help of =~, here is an example. 123456#!/usr/bin/env bashfoo=1if [[ $foo =~ [[:digit:]]+$ ]]; then echo numberfi Output 1number Notice that you cannot use \\d or \\\\d to replace [[:digit:]], because \\d is PCRE, while it uses POSIX regex here, which doesn’t recognize \\d. If you think [[:digit:]] is too long, you can use [0-9] to replace it, which has the same effect. 123456#!/usr/bin/env bashfoo=1if [[ $foo =~ [0-9]+$ ]]; then echo numberfi Output 1number","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://searene.me/tags/linux/"}]},{"title":"newInstance in Java","slug":"newInstance-in-Java","date":"2017-10-03T09:03:53.000Z","updated":"2017-10-03T09:05:46.292Z","comments":true,"path":"2017/10/03/newInstance-in-Java/","link":"","permalink":"http://searene.me/2017/10/03/newInstance-in-Java/","excerpt":"","text":"IntroductionnewInstance is used to instantiate an instance of a class dynamically. Here is an example written in Scala. 1234567891011class Printer() &#123; def print(): Unit = &#123; println(s\"print something\") &#125;&#125;object ScalaTest &#123; def main(args: Array[String]): Unit = &#123; val testClass = Class.forName(\"Printer\").newInstance().asInstanceOf[Printer] testClass.print() &#125;&#125; Output 1print something By the way, asInstanceOf[Printer] is used for casting in Scala, it’s just like (Printer) Class.forName(&quot;Printer&quot;).newInstance() in Java. What if we want to call Printer’s constructor with arguments? We can use getDeclaredConstructor 1234567891011121314class Printer(val name: String, val description: String) &#123; def print(): Unit = &#123; println(s\"product name: $name, description: $description\") &#125;&#125;object ScalaTest &#123; def main(args: Array[String]): Unit = &#123; val testClass = Class.forName(\"Printer\") .getDeclaredConstructor(classOf[String], classOf[String]) .newInstance(\"kindle\", \"used for reading\") .asInstanceOf[Printer] testClass.print() &#125;&#125; Output 1product name: kindle, description: used for reading","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"Java, Scala","slug":"Java-Scala","permalink":"http://searene.me/tags/Java-Scala/"}]},{"title":"When and how to use InheritableThreadLocal","slug":"When-and-how-to-use-InheritableThreadLocal","date":"2017-10-02T14:02:51.000Z","updated":"2017-10-02T14:29:30.000Z","comments":true,"path":"2017/10/02/When-and-how-to-use-InheritableThreadLocal/","link":"","permalink":"http://searene.me/2017/10/02/When-and-how-to-use-InheritableThreadLocal/","excerpt":"","text":"Today I was reading Spark’s source code, and found InheritableThreadLocal in it. Little information could be found online about this class, so I decided to write a blog to illustrate how to use it, based on the experiments I did. ThreadLocalBefore diving into InheritableThreadLocal, we need to understand ThreadLocal. ThreadLocal is used to create separate variables for each thread, as follows. 1234567891011121314151617181920212223class PrintRunnable extends Runnable &#123; val number = new ThreadLocal[Double] override def run(): Unit = &#123; number.set(Math.random()) println(number.get()) &#125;&#125;object SimpleApp &#123; def main(args: Array[String]): Unit = &#123; val printRunnable = new PrintRunnable val thread1 = new Thread(printRunnable) val thread2 = new Thread(printRunnable) thread1.start() thread2.start() thread1.join() thread2.join() &#125;&#125; Output 120.51576763494930980.37557496403907353 The above code is written in Scala. As you can see, thread1 and thread2 have different values for number, because we use ThreadLocal here, so the result is different. InheritableThreadLocalNow we decided to start a child thread within thread1/thread2, obtain the value of number and print it, can we achieve it? 12345678910111213141516171819202122232425262728293031class PrintRunnable extends Runnable &#123; val number = new ThreadLocal[Double] override def run(): Unit = &#123; number.set(Math.random()) println(number.get()) val childThread = new Thread(new Runnable &#123; override def run(): Unit = &#123; println(number.get()) &#125; &#125;) childThread.start() childThread.join() &#125;&#125;object SimpleApp &#123; def main(args: Array[String]): Unit = &#123; val printRunnable = new PrintRunnable val thread1 = new Thread(printRunnable) val thread2 = new Thread(printRunnable) thread1.start() thread2.start() thread1.join() thread2.join() &#125;&#125; Output 12340.54752260994071530.8376546404552231nullnull No, we cannot, because threadLocal cannot be passed into child threads. But what if we want it to do so? Just use InheritableThreadLocal! 12345678910111213141516171819202122232425262728293031class PrintRunnable extends Runnable &#123; val number = new InheritableThreadLocal[Double] override def run(): Unit = &#123; number.set(Math.random()) println(number.get()) val childThread = new Thread(new Runnable &#123; override def run(): Unit = &#123; println(number.get()) &#125; &#125;) childThread.start() childThread.join() &#125;&#125;object SimpleApp &#123; def main(args: Array[String]): Unit = &#123; val printRunnable = new PrintRunnable val thread1 = new Thread(printRunnable) val thread2 = new Thread(printRunnable) thread1.start() thread2.start() thread1.join() thread2.join() &#125;&#125; Output 12340.0064253751348991580.0219323063100743680.0064253751348991580.021932306310074368 Notice that we cannot set the value of InheritableThreadLocal in the child thread. 123456789101112131415161718192021222324252627class PrintRunnable extends Runnable &#123; val number = new InheritableThreadLocal[Double] override def run(): Unit = &#123; number.set(Math.random()) println(number.get()) val childThread = new Thread(new Runnable &#123; override def run(): Unit = &#123; println(number.get()) number.set(0.1) &#125; &#125;) childThread.start() childThread.join() println(number.get()) &#125;&#125;object SimpleApp &#123; def main(args: Array[String]): Unit = &#123; val printRunnable = new PrintRunnable val thread1 = new Thread(printRunnable) thread1.start() thread1.join() &#125;&#125; Output 1230.74138530128499370.74138530128499370.7413853012849937 As you can see, setting the value of InheritableThreadLocal doesn’t have any effect.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"multi-thread, java, scala","slug":"multi-thread-java-scala","permalink":"http://searene.me/tags/multi-thread-java-scala/"}]},{"title":"The difference between wait and sleep","slug":"The-difference-between-wait-and-sleep","date":"2017-09-09T08:29:09.000Z","updated":"2017-09-09T09:01:04.210Z","comments":true,"path":"2017/09/09/The-difference-between-wait-and-sleep/","link":"","permalink":"http://searene.me/2017/09/09/The-difference-between-wait-and-sleep/","excerpt":"","text":"wait and sleep can both be used to put a thread into sleep and wait for a while. So what’s the difference? To find it out, we need to figure out how to use them first. WaitTo use wait, you have to put mon.wait() and mon.notify() inside the synchronized block, where mon is the monitor object. mon is used such that only one thread can enter the synchronized block. It’s easier to see it with the code. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.example;public class WaitTest &#123; private static final Object mon = new Object(); private static volatile boolean stopWaiting = false; public static void main(String[] args) throws InterruptedException &#123; final Thread boyThread = new Thread(new Runnable() &#123; public void run() &#123; synchronized (mon) &#123; System.out.println(\"I'm waiting for the girl to show up\"); try &#123; while(!stopWaiting) mon.wait(); System.out.println(\"The girl showed up, I can stop waiting now.\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;); Thread girlThread = new Thread(new Runnable() &#123; public void run() &#123; try &#123; System.out.println(\"I'm wearing make-ups, the boy need to wait for me for 5 seconds.\"); Thread.sleep(5 * 1000); System.out.println(\"Make-up is completed, I'm going to see the boy and stop him from waiting\"); stopWaiting = true; synchronized (mon) &#123; mon.notify(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); boyThread.start(); girlThread.start(); boyThread.join(); girlThread.join(); System.out.println(\"The test is completed.\"); &#125;&#125; Output: 12345I'm waiting for the girl to show upI'm wearing make-ups, the boy need to wait for me for 5 seconds.Make-up is completed, I'm going to see the boy and stop him from waitingThe girl showed up, I can stop waiting now.The test is completed. Here the girl needs to wear the make-up before going out to see the boy. When she finishes, mon.notify() is called and the boy stops waiting, and they meet in the end. Sleepsleep can also be used to put a thread into sleep for a while, and you can use thread.interrupt() to cancel the sleep and put the thread into running. Let’s see an example. 1234567891011121314151617181920212223242526272829303132333435363738package com.example;public class SleepTest &#123; public static void main(String[] args) throws InterruptedException &#123; final Thread boyThread = new Thread(new Runnable() &#123; public void run() &#123; try &#123; System.out.println(\"I'm going to sleep for 5 seconds. If the girl wouldn't show up after 5 second, I'll stop waiting.\"); Thread.sleep(5 * 1000); System.out.println(\"The girl didn't show up, bummer.\"); &#125; catch (InterruptedException e) &#123; System.out.println(\"The girl showed up, great!\"); &#125; &#125; &#125;); Thread girlThread = new Thread(new Runnable() &#123; public void run() &#123; System.out.println(\"I'm going to wear make-ups, which will take 3 seconds\"); try &#123; Thread.sleep(3 * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"I'm done, going to see my boy and stop him from waiting\"); boyThread.interrupt(); &#125; &#125;); boyThread.start(); girlThread.start(); boyThread.join(); girlThread.join(); System.out.println(\"The test is completed.\"); &#125;&#125; Output: 12345I'm going to sleep for 5 seconds. If the girl wouldn't show up after 5 second, I'll stop waiting.I'm going to wear make-ups, which will take 3 secondsI'm done, going to see my boy and stop him from waitingThe girl showed up, great!The test is completed. The girl takes 3 seconds to wear her make-up, and when it’s done, she tells the boy to stop sleeping by calling boyThread.interrupt(), the boy stops sleeping and they meet in the end. DifferenceSo what’s the difference? wait should be used in a synchronized block, while sleep doesn’t need to. wait belongs to java.lang.Object and is an instance method, while sleep belongs to java.lang.Thread and is a static method. wait can be woken by notify, notifyAll and interrupt, while sleep can only be woken by interrupt. wait and notify release the lock, which means you can enter the synchronized block for multiple times as long as those threads call wait, while sleep doesn’t release the lock. Use Casessleep is a normal way to put the thread into sleep for a pre-defined time, and interrupt is only a way to cancel the sleep. wait is a normal way for inter-thread communication, and usually you can build a publish-subscribe system by it. notify =&gt; publish, wait =&gt; subscribe. When you call notify, it means some messages are available, and one thread will be woken to consume those messages.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"java","slug":"java","permalink":"http://searene.me/tags/java/"}]},{"title":"Leetcode: Combination Sum II","slug":"Leetcode-Combination-Sum-II","date":"2017-07-15T00:33:03.000Z","updated":"2017-07-15T00:44:59.809Z","comments":true,"path":"2017/07/15/Leetcode-Combination-Sum-II/","link":"","permalink":"http://searene.me/2017/07/15/Leetcode-Combination-Sum-II/","excerpt":"","text":"ProblemGiven a collection of candidate numbers (C) and a target number (T), find all unique combinations in C where the candidate numbers sums to T. Each number in C may only be used once in the combination. Note: All numbers (including target) will be positive integers. The solution set must not contain duplicate combinations. For example, given candidate set [10, 1, 2, 7, 6, 1, 5] and target 8,A solution set is: 123456[ [1, 7], [1, 2, 5], [2, 6], [1, 1, 6]] Leetcode Linkhttps://leetcode.com/problems/combination-sum-ii/#/description SolutionThis problem can be solved using DFS: Get the result starting with the first number Get the result starting with the second number … Get the result starting with the last number But we need to sort the array first in order to remove duplicate records. 12345678910111213141516171819202122232425262728public class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; combinationSum2(int[] candidates, int target) &#123; if(candidates == null || candidates.length == 0) &#123; return new ArrayList&lt;&gt;(); &#125; Arrays.sort(candidates); return combinationSum2(candidates, target, new ArrayList&lt;&gt;(), 0); &#125; private List&lt;List&lt;Integer&gt;&gt; combinationSum2(int[] candidates, int target, List&lt;Integer&gt; prefix, int startPos) &#123; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); if(target == 0) &#123; result.add(new ArrayList&lt;&gt;(prefix)); &#125; else if(target &gt; 0)&#123; for (int i = startPos; i &lt; candidates.length; i++) &#123; if(i &gt; startPos &amp;&amp; candidates[i] == candidates[i - 1]) &#123; continue; &#125; prefix.add(candidates[i]); List&lt;List&lt;Integer&gt;&gt; subResult = combinationSum2(candidates, target - candidates[i], prefix, i + 1); prefix.remove(prefix.size() - 1); result.addAll(subResult); &#125; &#125; return result; &#125;&#125;","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://searene.me/tags/leetcode/"},{"name":"algorithm","slug":"algorithm","permalink":"http://searene.me/tags/algorithm/"}]},{"title":"Why is Kafka so fast","slug":"Why-is-Kafka-so-fast","date":"2017-07-09T00:45:39.000Z","updated":"2018-08-05T03:38:26.070Z","comments":true,"path":"2017/07/09/Why-is-Kafka-so-fast/","link":"","permalink":"http://searene.me/2017/07/09/Why-is-Kafka-so-fast/","excerpt":"","text":"As we all know that Kafka is very fast, much faster than most of its competitors. So what’s the reason here? Avoid Random Disk AccessKafka writes everything onto the disk in order and consumers fetch data in order too. So disk access always works sequentially instead of randomly. For traditional hard disks(HDD), sequential access is much faster than random access. Here is a comparison: hardware sequential writes random writes 6 * 7200rpm SATA RAID-5 300MB/s 50KB/s Kafka Writes Everything Onto The Disk Instead of MemoryYes, you read that right. Kafka writes everything onto the disk instead of memory. But wait a moment, isn’t memory supposed to be faster than disks? Typically it’s the case, for Random Disk Access. But for sequential access, the difference is much smaller. Here is a comparison taken from https://queue.acm.org/detail.cfm?id=1563874 As you can see, it’s not that different. But still, sequential memory access is faster than Sequential Disk Access, why not choose memory? Because Kafka runs on top of JVM, which gives us two disadvantages. The memory overhead of objects is very high, often doubling the size of the data stored(or even higher). Garbage Collection happens every now and then, so creating objects in memory is very expensive as in-heap data increases because we will need more time to collect unused data(which is garbage). So writing to file systems may be better than writing to memory. Even better, we can utilize MMAP(memory mapped files) to make it faster. Memory Mapped Files(MMAP)Basically, MMAP(Memory Mapped Files) can map the file contents from the disk into memory. And when we write something into the mapped memory, the OS will flush the change onto the disk sometime later. So everything is faster because we are using memory actually, but in an indirect way. So here comes the question. Why would we use MMAP to write data onto disks, which later will be mapped into memory? It seems to be a roundabout route. Why not just write data into memory directly? As we have learned previously, Kafka runs on top of JVM, if we wrote data into memory directly, the memory overhead would be high and GC would happen frequently. So we use MMAP here to avoid the issue. Zero CopySuppose that we are fetching data from the memory and sending them to the Internet. What is happening in the process is usually twofold. To fetch data from the memory, we need to copy those data from the Kernel Context into the Application Context. To send those data to the Internet, we need to copy the data from the Application Context into the Kernel Context. As you can see, it’s redundant to copy data between the Kernel Context and the Application Context. Can we avoid it? Yes, using Zero Copy we can copy data directly from the Kernel Context to the Kernel Context. Batch DataKafka only sends data when batch.size is reached instead of one by one. Assuming the bandwidth is 10MB/s, sending 10MB data in one go is much faster than sending 10000 messages one by one(assuming each message takes 100 bytes). Reference https://www.slideshare.net/baniuyao/kafka-24299168 https://toutiao.io/posts/508935/app_preview","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"Big Data","slug":"Big-Data","permalink":"http://searene.me/tags/Big-Data/"},{"name":"Kafka","slug":"Kafka","permalink":"http://searene.me/tags/Kafka/"}]},{"title":"kafka in a nutshell","slug":"kafka-in-a-nutshell","date":"2017-05-18T13:51:28.000Z","updated":"2017-05-21T09:58:15.327Z","comments":true,"path":"2017/05/18/kafka-in-a-nutshell/","link":"","permalink":"http://searene.me/2017/05/18/kafka-in-a-nutshell/","excerpt":"","text":"IntroductionKafka is a distributed publish-subscribe messaging system that is designed to be fast, scalable and reliable. It can be used in data analysis, stream processing and other similar tasks. This article gives a brief introduction on its components and how these components work together to make Kafka an amazing program. Basic ModelBasically you have to provide two things in order to use Kafka: producer and consumer. Producer is used to generate data constantly and write those data to Kafka servers, then consumer reads data from kafka servers and dispatch those data to downstream systems for further processing. Notice that you can provide multiple producers and multiple consumers to ensure fast data delivery. Usually there are also multiple kafka servers. In this case, same data will be replicated across multiple servers so that Kafka would still work even if one of those servers goes offline. There are some keywords you need to about first before getting into some details of Kafka. Topic: When you are sending data to Kafka using producers, you have to tell producers, “Hey, could you please send these data to that place in the Kafka server?” Here that place should be replaced with topic. Topics are just like directories in your computer, different directories store different files. The same goes to Kafka. You may have three different Kafka topics, game, website and log, they are used to stream gaming, website and log data respectively. Typically different producers write data to different topics, but notice that one topic can be fed by multiple producers at the same time. Partition: A topic is divided into multiple partitions, so that if you have multiple producers for a topic, they can write to different partitions concurrently, likewise, consumers can also read from different partitions at the same time, which makes the whole streaming process much faster. Offset: Each message sent by producer will be stored by Kafka servers, and marked with a unique number for each partition, this number is called offset. Just as the name implies, offset starts from 0 and increases by one each time a message is received from producers. Broker: Each server in Kafka is called a broker. Leader &amp; Follower: The data stored in a topic will be replicated across multiple servers. Since a topic is made up of partitions, it’s safe to say that the same partition is replicated across multiple servers. One of those partitions is called leader, and others are called follower. Suppose we have three brokers, and we mark leader partitions in red, follower partitions in blue, the whole picture is like this: ProducerWhen producers write data to Kafka, they first write to the leader partition, then the data is replicated into the first follower, then the second follower…until all followers have the same data as the leader. Each broker has its own commit log. When data is successfully stored in its respective partition in one broker, a new record will be written into the broker’s commit log. When a message is replicated across all leader and followers for that partition, i.e. we have committed the message in all brokers, we take it that the message has been committed in its respective partition. So when should the producer consider the message has been written into Kafka successfully? After the message is committed in leader, or in all brokers? In fact, producers have three choices. Producer returns immediately right after the message is written into the leader, don’t wait for commit. Producer waits for confirm from the leader, which means the message has been committed in the leader partitionbs.reload. Producer waits for confirm from all brokers, which means the message has been committed in both leader and follower partitions. ConsumerConsumers in Kafka use the poll() function to fetch data from Kafka servers. Every once in a while, consumers need to commit messages which they receive. The commit log is stored in a special Kafka topic. So how do consumers commit and when? Basically there are three modes for consumers to choose from. Commit At Most Once You have to set the following properties to use this mode: 12enable.auto.commit = trueauto.commit.interval.ms = 15 The value of auto.commit.interval.ms could be any number. Now let’s talk about what these properties mean and how the mode works. The following steps will be proceeded if this mode is turned on: Consumer fetches some data from Kafka. Consumer checks whether auto.commit.interval.ms is up. If so, it commits offset fetched between the last commit time and now. The commit is done automatically by Kafka, this is also what enable.auto.commit means. Consumer processes the fetched data. Repeat above steps. Let’s use a picture to illustrate the process. Regarding the above diagram, what will happen if error occurs while processing data? Well, as you see, data from offset 10 ~ 14 will be lost because these unsuccessfully-processed data has been committed, when the consumer recovers from the crash, it will continue to fetch and process data from offset 15, which is the next number from the last commit offset. Commit At Least Once You have to set the following properties to turn on this mode. 1enable.auto.commit = false As you can see, enable.auto.commit is set false, which means that you have to manually commit offsets. There are the steps to be proceeded if the mode is turned on. Consumer fetches some data from Kafka. Consumer processes those data. Consumer commit offsets regarding those data manually. Repeat above steps. Here is a picture to illustrate the process. What if an exception occurs while we are processing data, just like the last mode mentioned before? Well, as you can see, nothing is lost here because we haven’t committed those data at the time of processing. The worst thing for us is that some duplicated data will be appeared in the downstream system. That’s totally fine as long as we have a proper filter system to filter out those duplicated data. Since this mode is safer than the last one, we often choose to use receive at least once in Kafka to fetch data. There’s also another mode called commit exactly once, where the committed messages and offsets will get through a transaction system. It’s even safer than receive at least once but costs much more resources. Most of the time the second mode would be fine, we will not talk about it in detail for now. When Brokers Are DownLet’s say we have three brokers, one is Leader, the other two are followers. Now one of the follower is down. What will happen? Nothing. We just lost one replica, it’s not that a big deal. OK, the second follower is down. How about that? Never mind! The leader is still up and running, this is enough. Now the Leader is down… All right, we have no brokers any more. Producers and consumers will both stop. What will happen next is determined by the type of broker brought back online first. If the Leader is brought back online first, nothing will be lost because producers and consumers stop while the leader is offline. If one of the follower is brought back online first, it will become Leader, and some data fetched between the time the follower is down and the time the leader is up may be lost. When the leader is up, it will become a follower, and it will find out that some data have been committed in itself which don’t belong to other brokers, those data will be discarded. Now let’s say the three brokers are up and running, and the leader is down. What will happen then? One of the followers will be elected as the leader. Nothing will be lost. This may take a few seconds and result in LeaderNotAvailable error from the client, but it doesn’t matter because a new leader will be elected soon.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://searene.me/tags/kafka/"}]},{"title":"what does \"this\" refer to in javascript?","slug":"what-does-this-refer-to-in-javascript","date":"2017-05-15T15:30:32.000Z","updated":"2017-05-17T12:32:52.670Z","comments":true,"path":"2017/05/15/what-does-this-refer-to-in-javascript/","link":"","permalink":"http://searene.me/2017/05/15/what-does-this-refer-to-in-javascript/","excerpt":"","text":"Introductionthis in javascript is always a mysterious thing. Some programmers who have written a lot of javascript code still cannot tell the value of this every now and then. So today, I decided to write an article about it to solve the problem once and for all. I think you would be able to fully understand what this refers to in almost all situations after you read this article. Rule 1: Basic RuleRule 1: When this is used in a normal function(i.e. not an arrow function), this refers to the object that calls the function. This is the most important rule, let’s use several examples to illustrate what it means. when the function is called by an object.123456var obj = &#123; foo: function() &#123; console.log(this); // this? &#125;&#125;;obj.foo(); this is in a normal function foo, and foo is called by obj. So this refers to obj here. answer: obj when the function is called all by itself.12345function foo() &#123; console.log(this); // this?&#125;foo(); This is different, nothing calls foo(), right? Well, not exactly. In fact, foo() is the same as window.foo(), so this refers to window here, which is the global object in javascript. answer: window when the function is assigned to another function1234567var obj = &#123; foo: function() &#123; console.log(this); // this? &#125;&#125;;var bar = obj.foo;bar(); This time the function that gets executed is not obj.foo, it’s bar, because obj.foo is assigned to bar. this refers to object that calls bar instead of obj.foo in this case, because obj.foo has been assigned to bar. Who calls bar? window. So this refers to window here. answer: window A Gotcha Moment: this is only injected into context when the function which contains this is called. We cannot determine the value of this only by its definition. We have to see who calls this to determine its value. You can find it in the above code that the value of this may be different when it’s called in different ways. Rule 2: EvalRule 2: this remains unchanged when evaluated using eval directly, and is equal to window when evaluated using eval indirectly. Using eval directly means something like: eval(&#39;this&#39;).Using eval indirectly means something like (1, eval)(&#39;this&#39;). Let’s look at the code first. 123456var obj = &#123; foo: function() &#123; console.log(eval('this')); // this? &#125;&#125;;obj.foo(); To solve the problem, let’s first insert another line in the above code. 1234567var obj = &#123; foo: function() &#123; console.log(this) // &lt;-- insert this line console.log(eval('this')); // this? &#125;&#125;;obj.foo(); Do you know what this in the inserted line refers to? Of course it’s obj, we have talked about it a while before. So what’s the value of eval(&#39;this&#39;)? It’s exactly the same, obj! It doesn’t change. answer: obj What if we use eval indirectly? 123456var obj = &#123; foo: function() &#123; console.log((1, eval)('this')); // this? &#125;&#125;;obj.foo(); When eval is used indirectly, this in it refers to window, simple rule. answer: window Rule 3: Arrow FunctionsRule 3: this in arrow functions is the same as this in the outer context. Still, code first. 123456789function bar() &#123; var obj = &#123; foo: () =&gt; &#123; console.log(this); // this? &#125; &#125;; obj.foo();&#125;bar(); OK, this time, this is used in an arrow function. According to Rule 3, we have to find out what this is in the outer context with respect to the arrow function obj.foo. Some people don’t know what outer context is. Actually, the outer context can be seen as the context where obj.foo gets executed. Let’s insert another line in the above code. 12345678910function bar() &#123; var obj = &#123; foo: () =&gt; &#123; console.log(this); // this? &#125; &#125;; console.log(this); // &lt;-- insert this line obj.foo();&#125;bar(); Do you know what this refers to in the inserted line? Of course, it refers to window, because it’s window that calls bar. So what this refers to in the original code(the 4th line)? It’s the same! Because the outer context of obj.foo is exactly the context where the inserted line is in. answer: window Rule 4: Event handlerRule 4: this refers to window when used an inline event handler, and refers to the attached DOM element when used in a separate event hanlder. inline event handler1234567891011&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt; &lt;button id=\"button\" onclick=\"foo()\"&gt;Click me!&lt;/button&gt; &lt;script type=\"text/javascript\"&gt; function foo() &#123; alert(this); &#125; &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; this is used in an inline event handler foo here, so this refers to window. answer: window separate event handler123456789101112&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt; &lt;button id=\"button\"&gt;Click me!&lt;/button&gt; &lt;script type=\"text/javascript\"&gt; var button = document.getElementById(\"button\"); button.onclick = function foo() &#123; alert(this); &#125; &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; this is used in a separate event handler foo here. So it refers to the DOM element button according to Rule 4. In fact, we can also use Rule 1 to get the same answer. Because each time the button is clicked, button.onclicked is executed. Who calls the onclick function? button. So the answer is button. answer: button(DOM element) Rule 5: JQueryRule 5: this in most JQuery callbacks refers to the attached JQuery element 123456789101112131415&lt;html&gt;&lt;head&gt; &lt;script src=\"/jquery-2.2.4.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;button id=\"button\"&gt;Click me!&lt;/button&gt; &lt;script type=\"text/javascript\"&gt; $(\"button\").click(function() &#123; alert(this); &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; According to Rule 5, this refers to $(&quot;button&quot;) here. You may wonder why it is the case. In fact, JQuery calls the callback using something like this: 123function click(callback) &#123; callback.call($(\"button\"))&#125; callback.call($(&quot;button&quot;)) is the same as callback(), except that it sets the this in callback as $(&quot;button&quot;), so you can happily use this as the JQuery element inside the callback function. answer: button(JQuery object)","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://searene.me/tags/javascript/"}]},{"title":"re-embrace hexo and hueman","slug":"re-embrace-hexo-and-hueman","date":"2017-05-15T13:24:18.000Z","updated":"2017-05-15T13:54:21.867Z","comments":true,"path":"2017/05/15/re-embrace-hexo-and-hueman/","link":"","permalink":"http://searene.me/2017/05/15/re-embrace-hexo-and-hueman/","excerpt":"","text":"About a month ago, I started writing blogs in Chinese using WordPress. I stuck to the plan for about several days then decided to use English instead. The reason is unbelievably simple: typing English characters is a lot easier than typing Chinese characters. Now today, which is about a month later, I decided to abandon WordPress altogether. WordPress is an excellent blogging platform, I have to admit it. But I cannot find a reliable way to use markdown in WordPress, and I also noticed some odd behaviors of the visual editor used in WordPress. Nothing is more convenient and portable than writing my blogs in vim using markdown. So finally I decided to abandon it and embrace hexo and hueman again. I will consider moving some of the blogs written in WordPress back in here.","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://searene.me/tags/hexo/"},{"name":"hueman","slug":"hueman","permalink":"http://searene.me/tags/hueman/"}]},{"title":"An Illustration of Various Encoding Schemes","slug":"An-Illustration-of-Various-Encoding-Schemes","date":"2017-05-13T14:04:58.000Z","updated":"2017-05-26T14:12:08.310Z","comments":true,"path":"2017/05/13/An-Illustration-of-Various-Encoding-Schemes/","link":"","permalink":"http://searene.me/2017/05/13/An-Illustration-of-Various-Encoding-Schemes/","excerpt":"","text":"What are encoding schemes?Encoding schemes are ways to store and retrieve characters in computers. For example, in ISO-8859-1(which is one of various encoding schemes), we use 01100001 to denote a, and 00111111 to denote ?. Because computers only know how to store and fetch 0 and 1, we must have a way to store other characters like alphabets, or even Chinese characters. Some of the frequently used encoding schemesISO-8859-1 ISO-8859-1 is also called LATIN-1, which is a deprecated encoding scheme. It can only store the 256 characters in the ASCII table. For example, let’s write a text file with the following contents: 1&amp;1231208ABCabc中文 Let’s see how the computer stores it. Type the command xxd -b resources/test/ASCII.txt to display the real contents the computer stores. 12300000000: 00100110 00110001 00110010 00110011 00110001 00110010 &amp;1231200000006: 00110000 00111000 01000001 01000010 01000011 01100001 08ABCa0000000c: 01100010 01100011 00111111 00111111 bc?? We can see that &amp; was stored as 00100110, and 1 was stored as 00110001. This is exactly how ISO-8859-1 processes characters. It maps each character to a unique byte. Refer to the code page displayed in Wikipedia to see the map. Because ISO-8859-1 doesn’t have a way to store Chinese characters, we can see that 中文 are mapped to Because ISO-8859-1 doesn’t have a way to store Chinese characters, we can see that 中文 are mapped to 00111111 00111111, which are just two question marks in ISO-8859-1. Unicode You may notice that ISO-8859-1 can only store 256 characters, this is not enough. How can we store Chinese characters, which include way more characters than 256? Here comes Unicode.Unicode is a computing industry standard that is able to store millions of characters in computers. Basically it’s just a huge map, which maps every character in this world to a number, which takes 1 ~ 4 bytes depending on what the character is. For example, A is mapped to 0x41, w is mapped to ox77, 中 is mapped to 0x4E2D. Each character in this world has its number mapped. You can find the whole mapping table in here. UTF-8 Unicode may have solved the problem, right? Why would we need UTF-8, and what is UTF-8? To find out the reason, first we need to find out if Unicode could solve our problem directly. Say I want to store AA on my disk. In Unicode, A is mapped to 0x41, so what I need to do is just store 0x4141 in my computer, right? No, it’s not going to work. How can we know what 0x4141 is if we try to decode it? Is it AA, or just a character whose mapping number is exactly 0x4141? Because a Unicode character takes 1 ~ 4 bytes, you will never know the boundary of each character if you store it directly on the disk. How can we solve the problem? The simplest method is to store each character in 4 bytes, if a character’s mapping number is less than 4 bytes, left padding it with zeros, so A would become 0x00000041 instead of just 0x41, that’s a way, it would work, but since most characters take less than 4 bytes in Unicode, it would waste a lot of space if we use this method. So here comes UTF-8. In UTF-8, the first 128 characters in the ASCII table take only 1 byte each.For those characters, the first bit in each byte is 0. When we need to denote a character that is not one of those characters, like 中, which takes 2 bytes in Unicode, we set the first bit of its first byte to 1, and set the rest bits according to the Unicode Standard. More detailed can be seen from here. So we can say that Unicode is just a standard, UTF-8 is a way to implement the standard, which specifies in detail how to store the Unicode number onto disk.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"encoding","slug":"encoding","permalink":"http://searene.me/tags/encoding/"}]},{"title":"Serialization and Deserialization in Java","slug":"Serialization-and-Deserialization-in-Java","date":"2017-05-10T02:01:24.000Z","updated":"2017-05-28T02:19:26.413Z","comments":true,"path":"2017/05/10/Serialization-and-Deserialization-in-Java/","link":"","permalink":"http://searene.me/2017/05/10/Serialization-and-Deserialization-in-Java/","excerpt":"","text":"IntroductionSerialization: a process which converts a Java instance into a bunch of bytes, so it can be stored in disk/database or transferred through network. Deserialization: the opposite of Serialization, in which a Java instance is extracted and recovered from disk/database/network. How to serialize and deserialize?To make the Serialization and Deserialization work for a Java class, you only need to implement Serializable in most cases. In the following example, we will create a class called Address, serialize it using WriteObject and deserialize it using ReadObject. 123456789101112131415161718192021222324252627282930313233package com.example;import java.io.Serializable;public class Address implements Serializable &#123; private String street; private String country; public void setStreet(String street) &#123; this.street = street; &#125; public void setCountry(String country) &#123; this.country = country; &#125; public String getStreet() &#123; return this.street; &#125; public String getCountry() &#123; return this.country; &#125; @Override public String toString() &#123; return \" Street : \" + this.street + \" Country : \" + this.country; &#125;&#125; 1234567891011121314151617181920212223242526package com.example;import java.io.FileOutputStream;import java.io.ObjectOutputStream;public class WriteObject&#123; public static void main (String args[]) &#123; Address address = new Address(); address.setStreet(\"wall street\"); address.setCountry(\"united states\"); try&#123; FileOutputStream fout = new FileOutputStream(\"c:\\\\address.ser\"); ObjectOutputStream oos = new ObjectOutputStream(fout); oos.writeObject(address); oos.close(); System.out.println(\"Done\"); &#125;catch(Exception ex)&#123; ex.printStackTrace(); &#125; &#125;&#125; 12345678910111213141516171819202122232425package com.example;import java.io.FileInputStream;import java.io.ObjectInputStream;public class ReadObject&#123; public static void main (String args[]) &#123; Address address; try&#123; FileInputStream fin = new FileInputStream(\"c:\\\\address.ser\"); ObjectInputStream ois = new ObjectInputStream(fin); address = (Address) ois.readObject(); ois.close(); System.out.println(address); &#125;catch(Exception ex)&#123; ex.printStackTrace(); &#125; &#125;&#125; First, run WriteObject to Serialize Address into C:\\address.ser, you can change it to another path if you use Linux or Mac**OS. Then run readObject to Deserialize Address from C:\\address.ser. And you can see from the console that we have obtained the serialized data in C:\\address.ser. 1Street : wall street Country : united states The whole process is illustrated as follows. Serialization Deserialization What happened in the background was that Java serialized each field in address(aka. street and country) into disk and read it when the deserialization was done. But does Java know how to serialize/deserialize street and country? Yes, because they are of type String, which also implements Serializable, and Java has its own rules to convert a String instance into a stream of bytes, so they can be written into disk. Everything seems to be working fine, right? No, because you forgot to add serialVersionUID in Address. The correct version is this. 123456789101112131415161718192021222324252627282930313233343536package com.example;import java.io.Serializable;public class Address implements Serializable&#123; // NOTICE HERE! private static final long serialVersionUID = 1L; private String street; private String country; public void setStreet(String street)&#123; this.street = street; &#125; public void setCountry(String country)&#123; this.country = country; &#125; public String getStreet()&#123; return this.street; &#125; public String getCountry()&#123; return this.country; &#125; @Override public String toString() &#123; return \" Street : \" + this.street + \" Country : \" + this.country; &#125;&#125; What is serialVersionUID? and why should I add it? Basically serialVersionUID is simply a number that is written into disk along with the serialized instance. And in the process of deserialization, Java checks whether the serialized serialVersionUID is the same as the one declared in class. If not, an exception will be thrown and deserialization will fail. It is used to make sure the serialized instance is compatible with the current class. Where Can I Get serialVersionUID?serialVersionUID can be set manually by the programmer with any number, or you can generate one using serialver provided by Oracle. What Will Happen If I Don’t Set serialVersionUID?Java will generate one for you based on class name, implemented interfaces, etc. But this is highly discouraged. Quote from Oracle doc: It is strongly recommended that all serializable classes explicitly declare serialVersionUID values, since the default serialVersionUID computation is highly sensitive to class details that may vary depending on compiler implementations, and can thus result in unexpected serialVersionUID conflicts during deserialization, causing deserialization to fail. For example, if you don’t set serialVersionUID manually, Java may generate a serialVersionUID = 12345 for you in the process of serialization. However, the deserializing program may use a different JVM and the serialVersionUID it gets may be 123456, which is different because of different calculation algorithms. Then the program finds that the two serialVersionUIDs don’t match and throws an exception to tell the user that the deserialization fails. When should I update the serialVersionUID value?You should update serialVersionUID when some incompatible fields are added to the class and it’s no longer possible to be support the old version. That’s it. Below are some links that I found helpful when I was writing the article. https://www.mkyong.com/java-best-practices/understand-the-serialversionuid/ http://stackoverflow.com/questions/285793/what-is-a-serialversionuid-and-why-should-i-use-it","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://searene.me/tags/Java/"}]},{"title":"the machanism of garbage collectors in Java","slug":"the-machanism-of-garbage-collectors-in-Java","date":"2017-05-07T14:01:33.000Z","updated":"2017-05-20T17:02:58.303Z","comments":true,"path":"2017/05/07/the-machanism-of-garbage-collectors-in-Java/","link":"","permalink":"http://searene.me/2017/05/07/the-machanism-of-garbage-collectors-in-Java/","excerpt":"","text":"There are several garbage collectors in Java, each has its specific usage scenario. To understand garbage collection, we first have to understand how heaps are divided in Java. Heaps are divided into two parts in Java, one is called the Young Generation, and the other one is called the Old Generation. You may have seen something called the Permanent Generation in other tutorials/documentations. It exists in Java 7 and before, Oracle removed it in Java 8. The Young Generation is also divided into three parts: Eden Area Survivor Space 1 Survivor Space 2 The whole picture in Heap is as follows. Basically, there are two types of garbage collections for most collectors: Young Generation Collection Old Generation Collection Young Generation Collection is meant to be time-efficient and frequent, this is different from the Old Generation Collection, which could take a long time, and it’s done less frequently. The Old Generation usually has larger heap space. Serial CollectorYoung Generation Collection Using the Serial Collector When you new an object in the Java code, the space for that object will be allocated in the Eden Area. After a while, the Eden Area may be filled up, so live objects in it will be copied into one of the Survivor Space, let’s say it’s Survivor Space 1. Some large objects that won’t be fit in the Survivor Space will be copies into the Old Generation. After a while, some live objects in Survivor Space 1 become dead, i.e., they are not referenced by any other objects anymore, and some more space is allocated in the Eden Area for newly initiated objects. Now you can see, objects exist in Eden and Survivor Space 1, and Survivor Space 2 is empty. This is where the interesting thing begins. Because from now on, what the Young Generation does is to repeat the following process. When the Eden Area is filled up again. live objects in it will be copied into Survivor Space 2(Some large objects that are too large to fit in Survivor Space will be copied into the Old Generation). The live objects that are relatively young are copied into the Survivor Space 2, live objects that are relatively old(i.e., they survived through several Young Generation Collections) are copied into the Old Generation. Then all dead objects in the Eden and Survivor Space 1 will be garbage collected, the two survivor spaces swap roles, the Survivor Space 1 is empty while the Survivor Space 2 is not, and the above process will be repeated. Old Generation Collection Using the Serial Collector Old Generation Collection is divided into three steps, mark-sweep-compact. In the mark phase, the collector identifies live objects, the sweep phase sweeps over the generation and frees space taken by dead objects. Then the collector moves all live objects to the beginning of the old generation, which is called compaction. The compaction is for quick space allocation in the old generation later on. When to Use the Serial Collector The Serial Collector is done in a single-threaded way, so it’s meant to be run on client-style machines that do not require low pause times. And since it only takes a small amount of memory, the serial collector can perform very well with only 64MB heaps in most cases. Parallel CollectorYoung Generation Collection Using the Parallel Collector Young Generation collection in the parallel collector is the same as the Serial Collector, except that it’s done in parallel. The Parallel Collector fully utilizes the power of multiple threads and make the process of Young Generation Collection faster. Although the Young Generation Collection is still a stop-the-world action, the process would take less time and make less impact to the running program. Old Generation Collection Using the Parallel Collector Old Generation Collection using the Parallel Collector is the same as the Serial Collector. When to Use the Parallel Collector You can use the Parallel Collector when you have multiple CPU cores, whose power could be unleashed and utilized by it. But also notice that the Parallel Collector wouldn’t help you a lot if you need a much shorter pause time in GC, because it still takes a long time to finish the Old Generation Collection, which is done in a single-threaded way in the Parallel Collector. Parallel Compacting CollectorYoung Generation Collection Using the Parallel Collector Young Generation Collection using the Parallel Compacting Collector is the same as the Parallel Collector. Old Generation Collection Using the Parallel Collector Old Generation Collection in the Parallel Compacting Collector is done in a multi-threaded way, this is different from the Parallel Collector, whose uses only a single thread to complete Old Generation Collection. There are in total three phases regarding Old Generation Collection. 1. Mark(multi-thread) First of all, the old generation is divided into several regions of the same fixed sizes. Then live objects that are directly reachable from the code are divided equally among multiple threads. Those threads work concurrently to mark all live objects in the old generation, storing the size and location of each live object. 2. Summary(single-thread) Due to previous compactions, some portions on the left side of the old generation are typically denser than those on the right side of it. So the collector will search from the left side, calculate the density of live objects in each region until it reaches a point where the density is small enough to be considered eligible for garbage collection. All the regions to the left of the point are not worth garbage collecting, and they will not be moved, those regions are called dense prefix. All the regions to the right of the point will be garbage collected. After collection, the collector will store the location of the first live object in each region, which would be helpful in the compaction phase. 3. Compaction(multi-thread) Live objects on the right side will be moved to the left side of the old generation, leaving a huge chunk of contiguous free memory on the right side. This process is called compaction. When to Use the Parallel Compacting Collector You can use the Parallel Compacting Collector if you have multiple CPU cores that could be utilized. The collector will take advantage of those CPU cores and make the total pause time shorter. Concurrent Mark-Sweep(CMS) CollectorYoung Generation Collection Using the CMS Collector Young Generation Collection using the CMS Collector is the same as the Parallel Collector. Old Generation Collection Using the CMS Collector There are four phases in total in the Old Generation Collection using the CMS Collector. 1. Initial Mark(single thread) All live objects that are directly reachable from the code are marked as alive. It takes a short pause to do it. 2. Concurrent Mark(multi-thread) While the application is running, the collector marks live objects that are transitively reachable from the above set obtained from the Initial Mark. 3. Remark(multi-thread) Because the Concurrent Mark is conducted while the application is still running, some live objects cannot be detected in the second phase. So the application stops for a while, and the collector checks all objects that are modified during the Concurrent Mark phase, and mark all objects that turned garbage during the previous phase. After the Remark phase, all live objects are marked. 4. Sweep(multi-thread) The collector conducts a Sweep operation to eliminate all garbage in the Old Generation. Disadvantages of the CMS Collector The CMS Collector is the only collector that has no compact phase, which means it cannot use the bump-the-pointer strategy(see reference below) to find free space. bump-the-pointer strategy: This is a strategy used to allocate new space in the Old Generation. With this strategy, you only need to store the position of the last live object after each Old Generation Collection. When you need to allocate a space to store a new object, what you need to do is just to allocate the space right after the position and update the position to the new one. There are no live objects after that position because the Old Generation has been compacted before. The strategy is used in all above collectors except the CMS Collector because the CMS Collector doesn’t compact the Old Generation. So how does the CMS Collector find new space to allocate? Basically, it maintains a linked list internally, which connects all free space together. When an allocation is needed, the collector will traverse through the list and find the appropriate region to allocate the space. Another disadvantage of the CMS Collector is that it needs a bigger heap size because the Concurrent Mark phase proceeds while the application is still running, which means more space needs to be allocated when some garbage cannot be collected in time. So enough heap size must be prepared to store both uncollected garbage and newly allocated space. When to Use the CMS Collector The CMS Collector is typically used in the server side application, where large heap size and multiple CPU cores could be utilized. Those applications usually require a smaller pause time, which is exactly what the CMS Collector is good at. G1(Garbage First) CollectorG1 Collector is different from previous collectors. All the previous collectors have a young generation and an old generation of fixed-size. This is the not the case for the G1 Collector. For the G1 Collector, the entire heap is divided into approximately 2000 areas, the size of each area is around 1MB ~ 32MB. The type of these areas may be different, it may be eden, survivor area, or the old generation. The whole picture is as follows. Although the size of each region is the same in the above picture, in reality, this may not be the case. The size of each region usually depends on how the collector optimizes the collection algorithm, and they are changing constantly. Notice that Humongous Region is used to store objects that are larger than 50% of the normal region size. Currently, no optimization is applied to this type of region, so avoid using objects that are too large. Young Generation Collection Using the G1 Collector Live objects in eden areas are copied into survivor areas. Some live objects that are out of the time threshold are copied into old generations. “Accounting” process is performed, which determines how much time is needed for the next Young GC based on the current stats and the predefined pause time. Resize eden/survivor regions based on the information obtained above. Old Generation Collection Using the G1 Collector Initial Mark: mark all survivor regions which may have references to objects in old generations. This step is done concurrently with Young GC. So although it’s still a stop-the-world operation(because the entire Young GC is a stop-the-world operation), it doesn’t take extra time to complete. Root region Scan: scan survivor regions for references into the old generation. It happens when the application is still running. Concurrent Mark: mark all live objects across the entire heap, this is done while the application is still running. Remark: stop the world and complete the marking process. Cleanup: Perform accounting on live objects and completely free regions.(stop-the-world) Scrubs Remembered Sets.(stop-the-world) Reset empty regions and return them to the free list.(concurrent) Copy: copy live objects from to new regions. This is a stop-the-world step. It can be seen as a kind of compaction. Reference http://www.oracle.com/technetwork/java/javase/memorymanagement-whitepaper-150215.pdf http://www.oracle.com/technetwork/tutorials/tutorials-1876574.html http://stackoverflow.com/a/19303535/1031769","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"java","slug":"java","permalink":"http://searene.me/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"http://searene.me/tags/jvm/"}]},{"title":"Inheritance in Javascript","slug":"Inheritance-in-Javascript","date":"2017-04-23T13:54:39.000Z","updated":"2017-05-20T16:10:38.400Z","comments":true,"path":"2017/04/23/Inheritance-in-Javascript/","link":"","permalink":"http://searene.me/2017/04/23/Inheritance-in-Javascript/","excerpt":"","text":"Javascript uses prototype chains to make inheritance work, that’s a little odd given that other OOP languages usually use class and extend. So to fully understand inheritance in javascript, we first have to understand what prototype chain is. Let’s say we have a function. 12345function Animal() &#123; this.category = 'organism'; this.food = 'generic food';&#125;console.log(Animal.prototype.constructor); // [Function: Animal] As shown in the above code, when we define a function, javascript also adds a special property called prototype on that function at the same time. And you can see that another special property constructor is automatically created on function.prototype, which is Animal.prototype.constructor in the above code. You can take the property as the function itself, when we create an instance using something like var animal = new Animal(), javascript will create the instance using the constructor specified by Animal.prototype.constructor. 1let animal = new Animal(); What happens under the hood when the above line gets executed is that: A new object is created, which is called animal. A property called animal.__proto__ is created, and animal.__proto__ === Animal.prototype. It calls Animal() in the context of animal, which means following lines get executed. 12animal.category = 'organism';animal.food = 'generic food'; So let’s sum up what happens here with a diagram. animal.__proto__ is the same as Animal.prototype. animal.category is organism. animal.food is generic food. Nothing is wrong here, we get all of animal’s custom properties(category and food) with or without __proto__, so what is it used for? Let’s add a line here. 12Animal.prototype.walk = 'animals can walk';console.log(animal.walk); // animals can walk. This is where the interesting part comes in. We know that animal doesn’t have a property called walk. So to find it, javascript resort to animal.__proto__, aka Animal.prototype to see if Animal.prototype has a property called walk. You know what? We just defined it! So javascript fetches the value of walk and returns it. So it looks like animal has a walk property itself! In this way, we can define another object called Cat, which inherits from Animal. 1234567891011function Cat() &#123; this.food = 'fish';&#125;Cat.prototype = animal; // all instances created by Cat inherit from Animallet cat = new Cat();console.log(cat.category); // organismconsole.log(cat.food); // fishconsole.log(cat.walk); // animals can walkconsole.log(cat.constructor); // [Function: Animal] You see, cat has all properties that we defined in Animal, including category, walk, and our cat even overrides Animal‘s food, because we all know, cat likes to eat fish. Something familiar? Yes, this is called inheritance! We just implemented inheritance in javascript! But do you know how cat.walk === &#39;aniamls can walk&#39; works? It follows several steps. Check if cat has a property called walk, obviously it doesn’t have that. Check if cat.__proto__, which is Cat.prototype, which is also animal has that property, obviously animal also doesn’t have it. Check if cat.__proto__.__proto__ has the walk property, OK, this time cat.__proto__.__proto__ aka Animal.prototype has that walk property, return its value, the job is done here. So you can see, __proto__ is just like a chain, to check if an instance cat has a property walk, we need to check: cat.walk cat.__proto__.walk cat.__proto__.__proto__.walk cat.__proto__.__proto__.__proto__.walk … And because cat.__proto__ is the same thing as Cat.prototype, to inherit cat from Animal, what we need to do is just point Cat.prototype to animal, so cat could have all properties animal has in this way. One thing is left here. We find out that cat.constructor equals [Function: Animal], this may not be what we want. cat is created by Cat instead of Animal, so we need to add another line here. 1Cat.prototype.constructor = Cat; This is the complete code. 12345678910111213141516171819202122\"use strict\";function Animal() &#123; this.category = 'organism'; this.food = 'generic food';&#125;Animal.prototype.walk = 'animals can walk';function Cat() &#123; this.food = 'fish';&#125;Cat.prototype = new Animal(); // all instances created by Cat inherit from AnimalCat.prototype.constructor = Cat; // change the constructor backlet cat = new Cat();console.log(cat.category); // organismconsole.log(cat.food); // fishconsole.log(cat.walk); // animals can walkconsole.log(cat.constructor); // [Function: Cat] Let’s make it more concise. 123456789\"use strict\";function Animal() &#123;&#125;function Cat() &#123;&#125;Cat.prototype = new Animal(); // all instances created by Cat inherit from AnimalCat.prototype.constructor = Cat; // change the constructor backvar cat = new Cat(); This can also be written as 12345678910\"use strict\";function Animal() &#123;&#125;function Cat() &#123; Animal.call(this)&#125;Object.setPrototypeOf(Cat.prototype, Animal.prototype); // set Cat.prototype as Animal.prototype, notice that this line won't change Cat.prototype.constructor, so it will remain as Catvar cat = new Cat(); In fact, we also need to do anther things like changing the super class of Cat, so a function called Object.inheritance was created to do this sort of work, which would modify the super class of the child class and set the child class’ prototype as the parent’s. 12345678910111213141516171819\"use strict\";var util = require(\"util\");function Animal() &#123;&#125;function Cat() &#123; Animal.call(this)&#125;util.inherits(Cat, Animal);// If you want to add some properties to Cat.prototype, make sure they are added after util.inherits, or these properties will not work because util.inherits will overwrite those propertiesCat.prototype.eat = function() &#123; console.log(\"Cat is eating\");&#125;var cat = new Cat(); That’s it, the above code is one of the most common ways to achieve inheritance.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://searene.me/tags/javascript/"}]},{"title":"Where to go","slug":"Where-to-go","date":"2017-03-29T14:49:23.000Z","updated":"2017-05-15T14:59:10.631Z","comments":true,"path":"2017/03/29/Where-to-go/","link":"","permalink":"http://searene.me/2017/03/29/Where-to-go/","excerpt":"","text":"I haven’t written my blog for a long time, partly it’s due to my sheer laziness, partly because I gathered nobody would even find it, let alone read it. But anyway, I decided to write something tonight. I’m almost 27, I told my self. And it is 2017, 17 years after 2000, I could never figure out where those years went. So many years, I’m getting older every day. Does the performance in the work really matter? Not sure, maybe not that important. So what really matters? I know it, I always know it, but I’m always afraid to face it. I started trying to solve problems on leetcode, that was for my career. Sometimes I thought maybe I just needed to choose a life and went with it, but I really hoped the life I chose would be perfect, or at least full of happiness and fulfillment, but actually it was not. I often think of the Sergeant in Forrest Gump, he lost his legs during the war, he didn’t know what to do. He cursed his life, joked about God, but when he finally got a normal life, he didn’t say anything. He never mentioned whether God existed or not, maybe he still didn’t know. I often pondered over the same question, but I had no answer to it. Why wouldn’t God give me a better life? Maybe he has his reason, I just need to go with it. It’s already late, I have to go to bed and sleep. I wrote some nonsense here, whatever.","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[]},{"title":"Hadoop Internals -- Configuration","slug":"Hadoop-Internals-Configuration","date":"2017-03-09T13:49:00.000Z","updated":"2017-05-15T15:10:56.737Z","comments":true,"path":"2017/03/09/Hadoop-Internals-Configuration/","link":"","permalink":"http://searene.me/2017/03/09/Hadoop-Internals-Configuration/","excerpt":"","text":"IntroductionAs what is called, Configuration is used to store all kinds of configurations in the hadoop platform, either they are from files(like core-default.xml) or from users(set via conf.setInt(&quot;dfs.replication&quot;, 1)). It would also warn you if you use a deprecated key. So how does it work? I will try to explain it in the source code level. Serialization and DeserializationConfiguration can be serialized in the file system and deserialized again into an instance. It implements the Writable interface to achieve this. There are only two methods in the Writable interface, write and readFields, just as follows. 1234567891011121314151617181920public interface Writable &#123; /** * Serialize the fields of this object to &lt;code&gt;out&lt;/code&gt;. * * @param out &lt;code&gt;DataOuput&lt;/code&gt; to serialize this object into. * @throws IOException */ void write(DataOutput out) throws IOException; /** * Deserialize the fields of this object from &lt;code&gt;in&lt;/code&gt;. * * &lt;p&gt;For efficiency, implementations should attempt to re-use storage in the * existing object where possible.&lt;/p&gt; * * @param in &lt;code&gt;DataInput&lt;/code&gt; to deseriablize this object from. * @throws IOException */ void readFields(DataInput in) throws IOException;&#125; As you can see, we call write when we need to serialize a Configuration instance into file, and we call readFields when we need to deserialize it from file. In fact, I wrote several lines to show how to serialize and deserialize a Configuration instance. 123456789101112131415161718192021222324252627282930package com.example;import org.apache.hadoop.conf.Configuration;import java.io.*;/** * Created by searene on 3/7/17. */public class ConfigurationInternal &#123; public static void main(String[] args) throws IOException &#123; String serializationFileName = \"conf.ser\"; String key = \"dfs.replication\"; Configuration conf = new Configuration(); conf.setInt(key, 1); // serialize the configuration instance into file DataOutput dataOutput = new DataOutputStream(new FileOutputStream(serializationFileName)); conf.write(dataOutput); // read from the serialized file into a new configuration instance DataInput dataInput = new DataInputStream(new FileInputStream(serializationFileName)); Configuration confObtained = new Configuration(); confObtained.readFields(dataInput); System.out.println(confObtained.getInt(key, 0)); &#125;&#125; To run it, you have to create a maven project and add hadoop-common as a dependency. 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt; &lt;version&gt;2.7.3&lt;/version&gt;&lt;/dependency&gt; Run it, and you will notice that a file confi.ser is created out of it, it stores the instance of Configuration, then we load it(aka deserialize it) from the file and get the instance. We can look through the source code of write and readFields implemented in Configuration to know more about it. 12345678910111213141516171819202122232425262728293031public class Configuration implements Iterable&lt;Map.Entry&lt;String,String&gt;&gt;, Writable &#123; .... @Override public void write(DataOutput out) throws IOException &#123; Properties props = getProps(); WritableUtils.writeVInt(out, props.size()); for(Map.Entry&lt;Object, Object&gt; item: props.entrySet()) &#123; org.apache.hadoop.io.Text.writeString(out, (String) item.getKey()); org.apache.hadoop.io.Text.writeString(out, (String) item.getValue()); WritableUtils.writeCompressedStringArray(out, updatingResource.get(item.getKey())); &#125; &#125; .... @Override public void readFields(DataInput in) throws IOException &#123; clear(); int size = WritableUtils.readVInt(in); for(int i=0; i &lt; size; ++i) &#123; String key = org.apache.hadoop.io.Text.readString(in); String value = org.apache.hadoop.io.Text.readString(in); set(key, value); String sources[] = WritableUtils.readCompressedStringArray(in); if(sources != null) &#123; updatingResource.put(key, sources); &#125; &#125; &#125; ...&#125; As you can see, the fields that serialization and deserialization apply to are this.properties and this.updateResource, the former stores all the configurations, which is the most important field in Configuration, and the latter stores the mapping of key to the resource which modifies or loads the key most recently. For example, if Configuration loads a file configuration.xml, which modifies the configuration dfs.replication, a new item will be added to this.updateResource: 1this.updateResource.put(\"dfs.replication\", new String[]&#123;\"configuartion.xml\"&#125;); Detect Deprecated KeysWhen Configuartion is loaded, a default list of deprecated keys will be loaded into defaultDeprecations too. 123456789101112131415161718192021private static DeprecationDelta[] defaultDeprecations = new DeprecationDelta[] &#123; new DeprecationDelta(\"topology.script.file.name\", CommonConfigurationKeys.NET_TOPOLOGY_SCRIPT_FILE_NAME_KEY), new DeprecationDelta(\"topology.script.number.args\", CommonConfigurationKeys.NET_TOPOLOGY_SCRIPT_NUMBER_ARGS_KEY), new DeprecationDelta(\"hadoop.configured.node.mapping\", CommonConfigurationKeys.NET_TOPOLOGY_CONFIGURED_NODE_MAPPING_KEY), new DeprecationDelta(\"topology.node.switch.mapping.impl\", CommonConfigurationKeys.NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY), new DeprecationDelta(\"dfs.df.interval\", CommonConfigurationKeys.FS_DF_INTERVAL_KEY), new DeprecationDelta(\"hadoop.native.lib\", CommonConfigurationKeys.IO_NATIVE_LIB_AVAILABLE_KEY), new DeprecationDelta(\"fs.default.name\", CommonConfigurationKeys.FS_DEFAULT_NAME_KEY), new DeprecationDelta(\"dfs.umaskmode\", CommonConfigurationKeys.FS_PERMISSIONS_UMASK_KEY), new DeprecationDelta(\"dfs.nfs.exports.allowed.hosts\", CommonConfigurationKeys.NFS_EXPORTS_ALLOWED_HOSTS_KEY) &#125;; When you try to set a configuration via something like configuration.set(&quot;name&quot;, &quot;value&quot;), it will first check if the key provided is deprecated, and if it is, it will store both deprecated and new keys in itself with the given value, and warn once to the user that the key should not be used. 123456789101112131415161718192021222324252627282930313233343536373839public void set(String name, String value, String source) &#123; Preconditions.checkArgument( name != null, \"Property name must not be null\"); Preconditions.checkArgument( value != null, \"The value of property \" + name + \" must not be null\"); name = name.trim(); DeprecationContext deprecations = deprecationContext.get(); if (deprecations.getDeprecatedKeyMap().isEmpty()) &#123; getProps(); &#125; getOverlay().setProperty(name, value); getProps().setProperty(name, value); String newSource = (source == null ? \"programatically\" : source); if (!isDeprecated(name)) &#123; updatingResource.put(name, new String[] &#123;newSource&#125;); String[] altNames = getAlternativeNames(name); if(altNames != null) &#123; for(String n: altNames) &#123; if(!n.equals(name)) &#123; getOverlay().setProperty(n, value); getProps().setProperty(n, value); updatingResource.put(n, new String[] &#123;newSource&#125;); &#125; &#125; &#125; &#125; else &#123; String[] names = handleDeprecation(deprecationContext.get(), name); String altSource = \"because \" + name + \" is deprecated\"; for(String n : names) &#123; getOverlay().setProperty(n, value); getProps().setProperty(n, value); updatingResource.put(n, new String[] &#123;altSource&#125;); &#125; &#125;&#125; Load Default Configuration filesWhen Configuration is loaded, it will try to find two files in the classpath: core-default.xml and core-site.xml, then load them if they are found. 1234567891011121314151617181920212223242526272829static&#123; //print deprecation warning if hadoop-site.xml is found in classpath ClassLoader cL = Thread.currentThread().getContextClassLoader(); if (cL == null) &#123; cL = Configuration.class.getClassLoader(); &#125; if(cL.getResource(\"hadoop-site.xml\")!=null) &#123; LOG.warn(\"DEPRECATED: hadoop-site.xml found in the classpath. \" + \"Usage of hadoop-site.xml is deprecated. Instead use core-site.xml, \" + \"mapred-site.xml and hdfs-site.xml to override properties of \" + \"core-default.xml, mapred-default.xml and hdfs-default.xml \" + \"respectively\"); &#125; addDefaultResource(\"core-default.xml\"); addDefaultResource(\"core-site.xml\");&#125; ... public static synchronized void addDefaultResource(String name) &#123; if(!defaultResources.contains(name)) &#123; defaultResources.add(name); for(Configuration conf : REGISTRY.keySet()) &#123; if(conf.loadDefaults) &#123; conf.reloadConfiguration(); &#125; &#125; &#125;&#125;","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"java","slug":"java","permalink":"http://searene.me/tags/java/"},{"name":"hadoop","slug":"hadoop","permalink":"http://searene.me/tags/hadoop/"}]},{"title":"I arrived in Hangzhou yesterday","slug":"I-arrived-in-Hangzhou-yesterday","date":"2017-02-12T23:35:34.000Z","updated":"2017-10-05T08:10:12.327Z","comments":true,"path":"2017/02/13/I-arrived-in-Hangzhou-yesterday/","link":"","permalink":"http://searene.me/2017/02/13/I-arrived-in-Hangzhou-yesterday/","excerpt":"","text":"I arrived in Hangzhou yesterday, and I could feel that the amounts of dopamine released in my brain fluctuated from time to time. At first I felt really happy, I was not sure why. Then I felt sort of upset when I got off the plane and headed towards my company. Maybe it was because I had to work again in my company, which was so boring and annoying. I think some people tend to release dopamine a lot, and they may never know what depression is like. I downloaded the movie Passenger from the Internet and watched it last night. To my suprise, although there were lots of negative comments on douban, I found the movie pretty interesting and compelling. Maybe it was due to the unbeatable charm of Jennifer Lawrence, she was so beautiful. That being said, the plot was not bad, and the film’s special effects were amazing! I really loved it. I even loved it to the extent that I couldn’t decide whether Arrival or Passenger was better, even though the former got a much higher mark on douban and IMDB. Another thing. I decided to use Wechat as few as possible. I watched a Ted talk yesterday and the speaker said that falling into social media was really a bad thing for us. It might cause more anxiety and depression and made us even more lonely, no matter how many friends we had ONLINE. I think that is absolutely correct. I felt more lonely when I talked in social media, our brain wasn’t designed to talk like this. We have to communicate face to face, use our gestures and expressions to create a better conversation and relax ourselves. Really, few people care about what I post on moments, what is the purpose of that!","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[]},{"title":"change openwrt source to UTSC","slug":"change-openwrt-source-to-UTSC","date":"2016-12-18T07:08:29.000Z","updated":"2017-02-11T01:24:24.637Z","comments":true,"path":"2016/12/18/change-openwrt-source-to-UTSC/","link":"","permalink":"http://searene.me/2016/12/18/change-openwrt-source-to-UTSC/","excerpt":"","text":"The following steps only apply to Netgear 4300 and openwrt 15.05.1. Modify /etc/opkg.conf to the following lines. 1234567891011dest root /dest ram /tmplists_dir ext /var/opkg-listsoption overlay_root /overlayoption check_signature 1src/gz chaos_calmer_base http://openwrt.proxy.ustclug.org/chaos_calmer/15.05.1/ar71xx/nand/packages/basesrc/gz chaos_calmer_luci http://openwrt.proxy.ustclug.org/chaos_calmer/15.05.1/ar71xx/nand/packages/lucisrc/gz chaos_calmer_management http://openwrt.proxy.ustclug.org/chaos_calmer/15.05.1/ar71xx/nand/packages/managementsrc/gz chaos_calmer_packages http://openwrt.proxy.ustclug.org/chaos_calmer/15.05.1/ar71xx/nand/packages/packagessrc/gz chaos_calmer_routing http://openwrt.proxy.ustclug.org/chaos_calmer/15.05.1/ar71xx/nand/packages/routingsrc/gz chaos_calmer_telephony http://openwrt.proxy.ustclug.org/chaos_calmer/15.05.1/ar71xx/nand/packages/telephony","categories":[],"tags":[]},{"title":"Install fcitx on ubuntu 16.10","slug":"Install-fcitx-on-ubuntu-16-10","date":"2016-12-06T14:13:57.000Z","updated":"2016-12-06T14:30:23.054Z","comments":true,"path":"2016/12/06/Install-fcitx-on-ubuntu-16-10/","link":"","permalink":"http://searene.me/2016/12/06/Install-fcitx-on-ubuntu-16-10/","excerpt":"","text":"Run the following command. 1sudo apt-get install fcitx fcitx-table fcitx-googlepinyin fcitx-module-cloudpinyin Search for language support, and check Keyboard input method system is fcitx Reboot. Go to the configuration of fcitx –&gt; Addon –&gt; Cloud Pinyin –&gt; Configure –&gt; Cloud Pinyin Source –&gt; Change from google to baidu.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"http://searene.me/tags/ubuntu/"},{"name":"linux","slug":"linux","permalink":"http://searene.me/tags/linux/"},{"name":"fcitx","slug":"fcitx","permalink":"http://searene.me/tags/fcitx/"}]},{"title":"Auto Adjust Brightness On Ubuntu 16.10 Using Systemd","slug":"Auto-Adjust-Brightness-On-Ubuntu-16-10-Using-Systemd","date":"2016-12-06T14:05:27.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/12/06/Auto-Adjust-Brightness-On-Ubuntu-16-10-Using-Systemd/","link":"","permalink":"http://searene.me/2016/12/06/Auto-Adjust-Brightness-On-Ubuntu-16-10-Using-Systemd/","excerpt":"","text":"This works on ubuntu 16.10 Create a file brightness.service in /lib/systemd/system with the following contents(Change 100 to whatever brightness you want, roughly it’s between 0 ~ 1000). 12345678[Unit]Description=Lower default brightness[Service]ExecStart=/usr/bin/zsh -c &quot;echo 100 &gt; /sys/class/backlight/intel_backlight/brightness&quot;[Install]WantedBy=multi-user.target Enable it. 1sudo systemctl enable brightness. Restart. It will work.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"http://searene.me/tags/ubuntu/"},{"name":"linux","slug":"linux","permalink":"http://searene.me/tags/linux/"}]},{"title":"Super CapsLock On Ubuntu 16.10","slug":"Super-CapsLock-On-Ubuntu-16-10","date":"2016-12-06T14:02:35.000Z","updated":"2016-12-10T04:59:41.797Z","comments":true,"path":"2016/12/06/Super-CapsLock-On-Ubuntu-16-10/","link":"","permalink":"http://searene.me/2016/12/06/Super-CapsLock-On-Ubuntu-16-10/","excerpt":"","text":"On ubuntu 16.10, make CapsLock act as Esc when it is hit, and as Ctrl when it is held. To make it work, modify /etc/default/keyboard, change 1XKBOPTIONS=&quot;&quot; to 1XKBOPTIONS=&quot;caps:ctrl_modifier&quot; Then add the following line in ~/.xsessionrc 123#!/usr/bin/env zsh/usr/bin/xcape -e 'Caps_Lock=Escape' Reboot.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"http://searene.me/tags/ubuntu/"},{"name":"linux","slug":"linux","permalink":"http://searene.me/tags/linux/"}]},{"title":"beautify i3wm","slug":"beautify-i3wm","date":"2016-10-07T00:28:38.000Z","updated":"2018-05-05T08:22:47.523Z","comments":true,"path":"2016/10/07/beautify-i3wm/","link":"","permalink":"http://searene.me/2016/10/07/beautify-i3wm/","excerpt":"","text":"MotivationI enjoy using i3wm, big time. You can switch to different windows/apps conveniently with it. The only problem to me is that it’s not beautiful enough, and it’s ridiculously small in my high-resolution screen. So I decided to change it a little bit. EffectHere is what you would get after applying the method. MethodTo change the appearance, you only need to modify the config file, usually it’s ~/.config/i3/config. Add the following lines. 1234567891011121314151617font pango:nimbus sans 18bar &#123; status_command conky -c $HOME/.i3/conky/conkyrc mode dock position top strip_workspace_numbers yes colors &#123; background #F1F2F6 statusline #788491 separator #51c4d4 focused_workspace #F1F2F6 #F1F2F6 #4FC0E8 active_workspace #F1F2F6 #F1F2F6 #4FC0E8 inactive_workspace #F1F2F6 #F1F2F6 #C1D1E0 urgent_workspace #F1F2F6 #F1F2F6 #C1D1E0 &#125;&#125; Remove those lines. 1234font pango:DejaVu Sans Mono 10 (Or whatever the font is)bar &#123; status_command i3status&#125; Then install conky and font-awesome, create a new file ~/.i3/conky/conkyrc, put the following lines in it. 1234567891011121314151617181920### lovelybacon.deviantart.com ####background noout_to_x noout_to_console yesupdate_interval 1total_run_times 0use_spacer noneTEXT$&#123;exec acpi -b | awk &quot;&#123;print $1&#125;&quot; | sed &apos;s/\\([^:]*\\): \\([^,]*\\), \\([0-9]*\\)%.*/\\3/&apos;&#125;% \\$&#123;exec acpi -b | awk &quot;&#123;print $1&#125;&quot; | sed &apos;s/\\([^:]*\\): \\([^,]*\\), \\([0-9]*\\)%.*/\\2/&apos;&#125; \\$&#123;if_mpd_playing&#125;$&#123;mpd_artist&#125;$&#123;mpd_title&#125;$&#123;endif&#125; \\ $&#123;downspeedf wlp3s0&#125; | $&#123;upspeedf wlp3s0&#125; \\ $&#123;wireless_link_qual_perc wlp3s0&#125; $&#123;wireless_essid wlp3s0&#125; \\ $&#123;hwmon 2 temp 1&#125; | $&#123;hwmon 2 temp 3&#125; \\ $&#123;exec amixer get Master -c 0 -M | grep -oE &quot;[[:digit:]]*%&quot;&#125; \\ $&#123;time %a %b %d&#125; \\ $&#123;time %H:%M&#125; Restart i3, the shortcut of mine is Shift+$mod+r, $mod could either be Alt or Super key. Note that if spaces are not recognized, install awesome-terminal-fonts and restart. 1pacaur -S awesome-terminal-fonts CreditThe above contents are from lovelybacon.deviantart.com, thanks for your amazing work. I only did a few modifications.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://searene.me/tags/linux/"},{"name":"i3","slug":"i3","permalink":"http://searene.me/tags/i3/"}]},{"title":"The empty set is the subset of any set","slug":"The-empty-set-is-the-subset-of-any-set","date":"2016-10-06T01:44:52.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/10/06/The-empty-set-is-the-subset-of-any-set/","link":"","permalink":"http://searene.me/2016/10/06/The-empty-set-is-the-subset-of-any-set/","excerpt":"","text":"The empty set is the subset of any set. This is true. Some people take it as a convention, but in fact, it can be explained. According to the definition of $\\subset$, $\\varnothing\\subset A\\Leftrightarrow$ $\\forall x$, if $x\\in\\varnothing$, then $x\\in A$. This is a vacuous truth, because the antecedent ($x\\in\\varnothing$) could never be true, so the conclusion always holds ($x\\in A$). So $\\varnothing\\subset A$ holds. Maybe you are thinking, OK, this is a vacuous truth, so maybe I can change it so that the following expression is also true. $\\forall x$, if $x\\in\\varnothing$, then $x\\not\\in A$. Then you could say, $\\varnothing\\subset A$ is false. This is what I asked on math.stackexchange.com the other day, and I read through all the answers and comments in it. Then I realized the above expression doesn’t mean $\\varnothing\\not\\subset A$, it just means $\\varnothing\\subset A^c$. I think what $\\varnothing\\not\\subset A$ means is $\\exists x, x\\in\\varnothing$ and $x\\not\\in A$ Since you can never find $x$ such that $x\\in\\varnothing$, so the condition could never be correct, so we don’t have enough evidence to make the conclusion($\\varnothing\\not\\subset A$). Notice the whole expression itself(If there exists $x\\in\\varnothing$ such that $x\\not\\in A$, then we say $\\varnothing\\not\\subset A$) is correct since it’s a vacuous truth(the condition could never be true). In fact $\\exists x, x\\in\\varnothing$ and $x\\not\\in A\\Leftrightarrow$ $\\varnothing\\not\\subset A$ Because $\\exists x, x\\in\\varnothing$ and $x\\not\\in A$ is false, so $\\varnothing\\not\\subset A$ is false, which makes $\\varnothing\\subset A$ true.","categories":[{"name":"Math","slug":"Math","permalink":"http://searene.me/categories/Math/"}],"tags":[{"name":"set-thoery","slug":"set-thoery","permalink":"http://searene.me/tags/set-thoery/"}]},{"title":"Understand poisson distribution","slug":"Understanding-poisson-distribution","date":"2016-10-01T15:34:25.000Z","updated":"2017-05-18T16:42:28.526Z","comments":true,"path":"2016/10/01/Understanding-poisson-distribution/","link":"","permalink":"http://searene.me/2016/10/01/Understanding-poisson-distribution/","excerpt":"","text":"IntroductionPoisson distribution can be derived from Binomial distribution when $\\lim\\limits_{n\\to\\infty}np = \\lambda(\\lambda\\in\\mathbb R)$, in which $n$ is the number of trials, $p$ is the probability of success in each trial. But how is the formula of poisson distribution obtained? Why is $p$ getting smaller when $n$ approaches infinity? I will try to answer these questions in this post. QuestionImagine there’s a call center in your local city, it receives a certain amount of calls per day. Let’s say the expected value of the number of the received calls is $\\lambda$. Now we need to calculate the probability of the number of received calls equaling $x$. How can we do it? ModelLet’s split one day into $n$ periods. So there could exist the two following cases for each period of time. There are calls received, either only one call or multiple calls There are no call received Whether there being calls received in each period of time is independent. Let’s define the following symbols: $P(X=x)$: the probability of the number of periods during which one or more calls received being $x$, $p_n$: the probability of there existing one or more calls during one period of time. ${p_n}’$: the probability of there existing only one call during one period of time It can be easily found out that $P(X=x)$ follows Binomial distribution, so $$P(X=x) = \\binom n x {p_n}^x(1-p_n)^{(n - x)}\\tag1$$ The expected value of $X$ is $$E(X) = np_n$$ Notice that we have another information: the average number of received calls per day is $\\lambda$, which means the expected value of the number of received calls per day is $\\lambda$. It’s going to come in handy later on. Increase $n$, we will notice that the amount of time each period contains decreases, so some periods in which there exist two or more calls before only exist one or even zero call now. So the expected value of $X$ increases(because some periods in which two or more calls exists is split into multiple periods in which only one call exists), which means $np_n$ increases as $n$ increases. When $n$ is large enough, so that each period of time is so short that no more than one call can exist in one period of time, the following equation would hold in this case. $$p_n = {p_n}’$$ So that $$E(X) = np_n = n{p_n}’ = \\lambda\\tag2$$ Let’s define another variable Y $Y$: the total number of calls received per day. $\\delta t$: the amount of time each period contains When $n$ is large enough, no more than one call exists in one period of time, so the number of periods of time in which one or more calls received($X$) equals the number of total calls received per day($Y$). So $$P(Y=x) = P(X=x) = \\binom n x {p_n}^x(1-p_n)^{(n-x)}\\tag3$$ How large should $n$ be to hold the above equation? 100, 10000, 10000000000? The larger, the better, so we set $n \\to\\infty$, so $\\delta t \\to 0$. In this case, no more than one call exists in one period of time. Let’s prove that no more than one call exists in $\\delta t$ when $\\delta t \\to 0$. Assuming more than one call exist in $\\delta t$, because $\\delta t \\to 0$, so $\\delta t$ should be smaller than $\\forall \\varepsilon&gt;0$. So we can futher split $\\delta t$ into several parts so each part only contains one call or no call, so no more than one call could exist in $\\delta t$ when $\\delta t \\to\\infty$. But is there a possibility that one call exists in $\\delta t$? Yes. Notice that $\\delta t\\to 0$ doesn’t mean $\\delta t = 0$. It just means $\\delta t$ is smaller than any positive real number. Just like the figure of $y=\\frac 1 x$ below. While $y\\to0$ when $x\\to \\infty$, but $y$ could be smaller than any positive real number, but $y$ can never be 0. So $p_n$ becomes the possibility of there existing only one call in each period of time, so $np_n$ becomes the total number of calls per day, i.e. $$\\lim\\limits_{n\\to\\infty}np_n = \\lambda$$ To make it work, the following equation must hold. $$\\lim\\limits_{n\\to\\infty}p_n = 0$$ So the possibility of there existing only one call in $\\delta t$ is 0. Does it mean there exists no call in any period of time? Of course not. The probability being 0 doesn’t mean it’s not possible. There will always be some calls falling into some periods of time, $p_n\\to 0$ only means $p_n$ could be smaller than any positive real number. In the real world, you cannot actually make $n = \\infty$, so you cannot actually make $p_n = 0$. To better illustrate what I mean, let’s define the two following events. event1: Only one call is received in some periods of time event2: Two or more calls are received in some periods of time. The number of event1 can never be 0 as long as we receive at least one call in a day. But when $n$ gets larger and larger, event2 will finally be 0. This is different although the possibility of both events is 0 when $n\\to\\infty$. Let’s add $n\\to\\infty$, so $(3)$ becomes $$P(Y=x) = P(X=x) = \\lim\\limits_{n\\to\\infty}\\binom n x {p_n}^x(1-p_n)^{(n-x)}\\tag4$$ Let $$\\lambda_n = np_n$$ According to $(2)$ $$\\lim\\limits_{n\\to\\infty}np_n = \\lambda$$ So $$\\lim\\limits_{n\\to\\infty}\\lambda_n = \\lambda$$ Put $p_n = \\frac{\\lambda_n} n$ into $(4)$, we get $$\\begin{equation}\\begin{split} &amp;P(Y=x) \\\\&amp;= \\lim\\limits_{n\\to\\infty}\\binom n x(\\frac{\\lambda_n} n)^x(1-\\frac{\\lambda_n}n)^{(n-x)}\\\\&amp;=\\lim\\limits_{n\\to\\infty}\\frac{n(n-1)\\cdots(n-x+1)}{x!\\cdot n^x}\\cdot{\\lambda_n}^x\\cdot(1-\\frac{\\lambda_n} n)^n\\cdot(1-\\frac{\\lambda_n} n)^{-x}\\\\&amp;=\\lim\\limits_{n\\to\\infty}\\frac 1 {x!} \\cdot 1 \\cdot \\underbrace{(1-\\frac 1 n)\\cdot(1-\\frac 2 n)\\cdots(1-\\frac{x-1} n)}_1\\cdot\\underbrace{ {\\lambda_n}^x}_{\\lambda}\\cdot\\underbrace{(1-\\frac{\\lambda_n} n)^n}_{e^{-\\lambda}}\\cdot\\underbrace{(1-\\frac{\\lambda_n} n)^{-x}}_1\\\\&amp;=\\frac{e^{-\\lambda}{\\lambda}^x}{x!}\\end{split}\\end{equation}$$ You can find out why $\\lim\\limits_{n\\to\\infty}(1-\\frac{\\lambda_n} n)^n = e^{-\\lambda}$ in this post FAQQ: If I was given $n$ and $p_n$, and I got $\\lambda$ using $\\lambda = np_n$, then I calculate the probability of there exising $x$ events in the total amount of time using the following equation. $$P(X=x) = \\frac{e^{-\\lambda}{\\lambda}^x}{x!}$$ Is it the exact value I want or just an approximation? A: This is just an approximation. The value you get is the number of pieces where events exist. There could be one event in a piece, there could be two or more events in a piece. So $P(X=x)$ not only includes the some of the cases where we want, but also the case where we don’t want, e.g. it also includes the case where $x+1$ events occur, but it doesn’t include the case where $x$ events fall into $x-1$ or less pieces. Q: If I was given the expected value $\\lambda$, and I calculate the probability using the following equation, then I calculate the probability of there exising $x$ events in the total amount of time using the following equation. $$P(X=x) = \\frac{e^{-\\lambda}{\\lambda}^x}{x!}$$ Is it the exact value I want or just an approximation? A: It’s the value you want. When $n$ is not large, the reason why there is a difference between $\\binom n x{p_n}^x(1-p_n)^{(n-x)}$ and $\\frac{e^{-\\lambda}{\\lambda}^x}{x!}$ is that $p_n$ is not exactly the value we want. That is, when $n$ is not large and we calculate the probability using $(1)$, the answer we get is $$P(X=x) = P_1 + P_2$$ $X$: the number of pieces where one or more events exist $P_1$ refers to the case where $x$ events fall into $x$ pieces $P_2$ refers to the case where $x+1$ or more events fall into $x$ pieces The value we want would be $$P(Y = x) = P_1 + P_3$$ $P_3$ refers to the case where $x$ events fall into $x-1$ or less pieces. Y: the total number of events occurring. As $n\\to\\infty$, $P_2\\to 0$, $P_3\\to 0$, so $P(X=x) \\to P(Y=x)$ So $$\\lim\\limits_{n\\to\\infty}P(X=x) = \\lim\\limits_{n\\to\\infty}P(Y=x) = P_1$$ Because $$P(X=x) = \\binom n x {p_n}^x(1-p_n)^{(n-x)}$$ So $$\\lim\\limits_{n\\to\\infty}P(Y=x) = \\frac{e^{-\\lambda}{\\lambda}^x}{x!}$$ Because P(Y=x) has nothing to do with what $n$ is, so $\\lim\\limits_{n\\to\\infty}P(Y=x) = P(Y=x)$ So $$P(Y=x) = \\frac{e^{-\\lambda}{\\lambda}^x}{x!}$$ That is, the number of total events is $\\frac{e^{-\\lambda}{\\lambda}^x}{x!}$.","categories":[{"name":"Math","slug":"Math","permalink":"http://searene.me/categories/Math/"}],"tags":[{"name":"math","slug":"math","permalink":"http://searene.me/tags/math/"},{"name":"poisson","slug":"poisson","permalink":"http://searene.me/tags/poisson/"},{"name":"probability","slug":"probability","permalink":"http://searene.me/tags/probability/"}]},{"title":"Proof of $$\\lim_{x\\rightarrow \\infty} f(x)^{g(x)} = c^d$$","slug":"Proof-of-limit-f-x-g-x-c-d","date":"2016-10-01T11:29:59.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/10/01/Proof-of-limit-f-x-g-x-c-d/","link":"","permalink":"http://searene.me/2016/10/01/Proof-of-limit-f-x-g-x-c-d/","excerpt":"","text":"Theorem: $$c, d\\in {\\bf R}, \\lim_{x\\rightarrow \\infty} f(x)=c&gt;0, \\lim_{x\\rightarrow \\infty} g(x) =d&gt;0$$ then $$\\lim_{x\\rightarrow \\infty} f(x)^{g(x)} = c^d$$ Proof: Because $y(x)=ln(x)$ is continuous at $x = c &gt; 0$ $\\lim\\limits_{x\\to \\infty}f(x) = c$ according to the composition law, we have $$\\lim\\limits_{x \\to \\infty}lnf(x) = ln\\lim\\limits_{x \\to \\infty}f(x) = lnc$$ Because $\\lim\\limits_{x \\to \\infty}g(x) = d$, we have $$\\lim\\limits_{x\\to \\infty}g(x)lnf(x) = \\lim\\limits_{x\\to \\infty}g(x)\\cdot\\lim\\limits_{x \\to \\infty}lnf(x) = dlnc$$ Apply composition law again, we get $$\\lim\\limits_{x\\to \\infty}f(x)^{g(x)} = \\lim\\limits_{x\\to \\infty}e^{g(x)lnf(x)} = e^{\\lim\\limits_{x\\to \\infty}g(x)lnf(x)} = e^{dlnc} = c^d$$","categories":[{"name":"Math","slug":"Math","permalink":"http://searene.me/categories/Math/"}],"tags":[{"name":"math","slug":"math","permalink":"http://searene.me/tags/math/"},{"name":"limit","slug":"limit","permalink":"http://searene.me/tags/limit/"}]},{"title":"Let hexo support mathjax","slug":"Let-hexo-support-mathjax","date":"2016-10-01T07:12:19.000Z","updated":"2017-05-20T01:48:14.613Z","comments":true,"path":"2016/10/01/Let-hexo-support-mathjax/","link":"","permalink":"http://searene.me/2016/10/01/Let-hexo-support-mathjax/","excerpt":"","text":"UpdateThe original answer fails on some mathjax expressions. So don’t use it. Currently changing marked.js works for me. Just use the method below. It works for me. First introduce mathjax into our blog. Create a new file called mathjax.ejs in themes/hueman/layout/plugin, and add the following contents in it. 123456789101112131415161718192021222324252627282930&lt;!-- mathjax config similar to math.stackexchange --&gt;&lt;script type=\"text/x-mathjax-config\"&gt; MathJax.Hub.Config(&#123; tex2jax: &#123; inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ], processEscapes: true &#125; &#125;);&lt;/script&gt;&lt;script type=\"text/x-mathjax-config\"&gt; MathJax.Hub.Config(&#123; tex2jax: &#123; skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'] &#125; &#125;);&lt;/script&gt;&lt;script type=\"text/x-mathjax-config\"&gt; MathJax.Hub.Queue(function() &#123; var all = MathJax.Hub.getAllJax(), i; for(i=0; i &lt; all.length; i += 1) &#123; all[i].SourceElement().parentNode.className += ' has-jax'; &#125; &#125;);&lt;/script&gt;&lt;script type=\"text/javascript\" src=\"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\"&gt;&lt;/script&gt; Then add the following line before the end of the last div tag in themes/hueman/layout/layout.ejs 1&lt;%- partial('plugin/mathjax') %&gt; The whole layout.ejs file looks like this: 1234567891011121314151617181920212223&lt;%- partial('common/head') %&gt;&lt;body&gt; &lt;div id=\"wrap\"&gt; &lt;%- partial('common/header', null, &#123;cache: !config.relative_link&#125;) %&gt; &lt;div class=\"container\"&gt; &lt;div class=\"main-body container-inner\"&gt; &lt;div class=\"main-body-inner\"&gt; &lt;section id=\"main\"&gt; &lt;%- partial('common/content-title') %&gt; &lt;div class=\"main-body-content\"&gt; &lt;%- body %&gt; &lt;/div&gt; &lt;/section&gt; &lt;%- partial('common/sidebar') %&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;%- partial('common/footer', null, &#123;cache: !config.relative_link&#125;) %&gt; &lt;%- partial('common/scripts') %&gt; &lt;%- partial('plugin/mathjax') %&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; Open ./node_modules/marked/lib/marked.js in your blog’s root directory Replace 1escape: /^\\\\([\\\\`*&#123;&#125;\\[\\]()# +\\-.!_&gt;])/, with 1escape: /^\\\\([`*\\[\\]()# +\\-.!_&gt;])/, The above step is used to avoid the escaping of \\\\, \\{, \\}. Then replace 1em: /^\\b_((?:[^_]|__)+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, with 1em: /^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, to remove the conversion of _ Then run the following command to deploy your blog 1hexo clean &amp;&amp; hexo g -d It should work now. But today I found a new problem. You cannot write two successive curly braces. I guess it’s because hexo tries to takes curly braces as part of a tag. I don’t have enough time to figure out how to let hexo accept it as a math expression rather than a tag. Currently I will just add a space between two curly braces. Just like { {. It works great. If you have better idea how to deal with it, you can leave it in the comment below. Original answerHexo doesn’t support mathjax by default. To make it work, we need to introduce mathjax to our theme. Take my current theme hueman as an example. Create a new file called mathjax.ejs in themes/hueman/layout/plugin, and add the following contents in it. 123456789101112131415161718192021222324252627282930&lt;!-- mathjax config similar to math.stackexchange --&gt;&lt;script type=\"text/x-mathjax-config\"&gt; MathJax.Hub.Config(&#123; tex2jax: &#123; inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ], processEscapes: true &#125; &#125;);&lt;/script&gt;&lt;script type=\"text/x-mathjax-config\"&gt; MathJax.Hub.Config(&#123; tex2jax: &#123; skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'] &#125; &#125;);&lt;/script&gt;&lt;script type=\"text/x-mathjax-config\"&gt; MathJax.Hub.Queue(function() &#123; var all = MathJax.Hub.getAllJax(), i; for(i=0; i &lt; all.length; i += 1) &#123; all[i].SourceElement().parentNode.className += ' has-jax'; &#125; &#125;);&lt;/script&gt;&lt;script type=\"text/javascript\" src=\"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\"&gt;&lt;/script&gt; Then add the following line before the end of the last div tag in themes/hueman/layout/layout.ejs 1&lt;%- partial('plugin/mathjax') %&gt; The whole layout.ejs file looks like this: 1234567891011121314151617181920212223&lt;%- partial('common/head') %&gt;&lt;body&gt; &lt;div id=\"wrap\"&gt; &lt;%- partial('common/header', null, &#123;cache: !config.relative_link&#125;) %&gt; &lt;div class=\"container\"&gt; &lt;div class=\"main-body container-inner\"&gt; &lt;div class=\"main-body-inner\"&gt; &lt;section id=\"main\"&gt; &lt;%- partial('common/content-title') %&gt; &lt;div class=\"main-body-content\"&gt; &lt;%- body %&gt; &lt;/div&gt; &lt;/section&gt; &lt;%- partial('common/sidebar') %&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;%- partial('common/footer', null, &#123;cache: !config.relative_link&#125;) %&gt; &lt;%- partial('common/scripts') %&gt; &lt;%- partial('plugin/mathjax') %&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; Then mathjax would be introduced into our blog. Our work should be done. But unfortunately this is not the case, because the default markdown rendering engine would accidently render some of our mathjax code, which would of course disturb the rendering of mathjax later on. To solve this problem, we need to replace hexo’s rendering engine as pandoc. First install pandoc on your system. I’m using arch, so the command is 1sudo pacman -S pandoc Then install hexo-render-pandoc. Run the following command in your blog’s root directory. 1npm install hexo-renderer-pandoc --save OK, everything is done. Write a blog containing any mathjax formula and run the following command to deploy it to your server. 1hexo clean &amp;&amp; hexo g -d Reference 搭建一个支持LaTEX的hexo博客","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://searene.me/tags/hexo/"},{"name":"mathjax","slug":"mathjax","permalink":"http://searene.me/tags/mathjax/"}]},{"title":"Proof of the limit's composition law when x approaches infinity","slug":"Proof-of-the-limit-s-composition-law-when-x-approaches-infinity","date":"2016-10-01T05:20:32.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/10/01/Proof-of-the-limit-s-composition-law-when-x-approaches-infinity/","link":"","permalink":"http://searene.me/2016/10/01/Proof-of-the-limit-s-composition-law-when-x-approaches-infinity/","excerpt":"","text":"Theorem: If $f(x)$ is continous at $b$ and $\\lim\\limits_{x \\to\\infty}g(x) = b$, then $$\\lim\\limits_{x \\to \\infty}f(g(x)) = f(b) = f(\\lim\\limits_{x\\to \\infty}g(x))\\tag1$$ Proof: Because $f(x)$ is continous at $b$, so $$\\lim\\limits_{x\\to b}f(x) = f(b)\\tag2$$ Because $$\\lim\\limits_{x\\to\\infty}g(x) = b \\tag3$$ Combine $(1)$ and $(2)$, we get $$\\lim\\limits_{x\\to\\infty}f(g(x)) = f(b)$$ Thus we proved the right side of equation $(1)$ Now we need to prove $$\\lim\\limits_{x \\to \\infty}f(g(x)) = f(b)\\tag 4$$ Because $$\\lim\\limits_{x\\to b}f(x) = f(b)$$ according to the definition of limit, $\\forall \\varepsilon &gt; 0$, there exists a $\\delta’$ such that for all $|x-b|&lt;\\delta’$, we have $$|f(x) - f(b)| &lt; \\varepsilon\\tag5$$ Replace $x$ with $g(x)$ in the above conclusion, we get $\\forall \\varepsilon’ &gt; 0$, there exists a $\\delta’$ such that for all $|g(x)-b|&lt;\\delta’$, we have $$|f(g(x)) - f(b)| &lt; \\varepsilon’\\tag6$$ Note that although $f(x)$ needs to be defined and has a limited value (6) around $b$, $g(x)$ doesn’t need to be so. For example, $g(x)$ may never be larger than $b$. But every time we get a $g(x)$ that meets the condition $|g(x) - b| &lt; \\delta’$, $|f(g(x)) - f(b)| &lt; \\varepsilon$ is guaranteed. Because $$\\lim\\limits_{x \\to \\infty}g(x) = b$$ according to the definition of limit, $\\forall \\varepsilon &gt; 0$, there exists a $\\delta$ such that for all $x &gt; \\delta$ we have $|g(x) -b| &lt; \\varepsilon$ Let $\\varepsilon = \\delta’$, so $\\forall x&gt;\\delta$, we have $$|g(x) - b| &lt; \\delta’$$ Combine this with $(6)$, $\\forall \\varepsilon’ &gt; 0$, there exists $\\delta$, whenever $x &gt; \\delta$, we have $$|f(g(x)) - f(b)| &lt; \\varepsilon’$$ Which is exactly the definition of the limit $$\\lim\\limits_{x \\to \\infty}f(g(x)) = f(b)$$ So we proved the left side of $(1)$ equation. So equation $$\\lim\\limits_{x \\to \\infty}f(g(x)) = f(b) = f(\\lim\\limits_{x\\to \\infty}g(x))$$ holds.","categories":[{"name":"Math","slug":"Math","permalink":"http://searene.me/categories/Math/"}],"tags":[{"name":"limit","slug":"limit","permalink":"http://searene.me/tags/limit/"},{"name":"composition","slug":"composition","permalink":"http://searene.me/tags/composition/"},{"name":"proof","slug":"proof","permalink":"http://searene.me/tags/proof/"}]},{"title":"Calculate $$\\lim\\limits_{n\\to\\infty}(1-\\frac{\\lambda_n}n)^n$$","slug":"Calculate-1-lambda-n-n","date":"2016-09-30T13:49:00.000Z","updated":"2017-05-18T16:44:46.983Z","comments":true,"path":"2016/09/30/Calculate-1-lambda-n-n/","link":"","permalink":"http://searene.me/2016/09/30/Calculate-1-lambda-n-n/","excerpt":"","text":"I came upon the calculation of $\\lim\\limits_{n\\to\\infty}(1-\\frac{\\lambda_n}n)^n$ when I was reviewing Poisson distribution. Notice that $\\lambda_n = np_n(n\\in\\mathbb{Z}_{\\geq 0}, 0\\leq p \\leq 1)$ and $\\lim\\limits_{n\\to\\infty}\\lambda_n = \\lambda(\\lambda\\in\\mathbb{R})$. So how to calculate it? The first thought that came to my mind was that $$\\lim\\limits_{n\\to\\infty}(1 + \\frac1 n)^n = e \\tag 1$$ So replace $n$ with $-n$, I got $$\\lim\\limits_{n\\to\\infty}(1 - \\frac1 n)^n = \\frac1 e \\tag 2$$ Then I have no clue about what to do next, I’m not even sure whether (2) is right or not. So I started digging from the calculation of $\\lim\\limits_{n\\to\\infty}(1 + \\frac1 n)^n$. Here is how I solve the problem. Let $t$ be any number in the interval $[1-\\frac{\\lambda_n}n, 1]$, then we get $$1-\\frac{\\lambda_n} n\\leq t\\leq1$$ Therefore $$\\frac 1{1-\\frac{\\lambda_n} n} \\leq \\frac 1 t \\leq 1$$ Therefore $$\\int_{1-\\frac{\\lambda_n}n}^1\\frac 1{1-\\frac{\\lambda_n} n}dt \\leq \\int_{1-\\frac{\\lambda_n}n}^1\\frac 1 t dt\\leq \\int_{1-\\frac{\\lambda_n}n}^1 1dt$$ The first integral equals $\\frac{\\lambda_n}n$, the second integral equals $ln(1-\\frac{\\lambda_n} n)^{-1}$, the third integral equals $\\frac{\\lambda_n}{n-\\lambda_n}$, so we get $$\\frac{\\lambda_n}n\\leq ln(1-\\frac{\\lambda_n} n)^{-1} \\leq \\frac{\\lambda_n}{n-\\lambda_n}$$ Exponentiating, we find that $$e^{\\frac{\\lambda_n} n}\\leq(1-\\frac{\\lambda_n}n)^{-1}\\leq e^{\\frac{\\lambda_n}{n-\\lambda_n}}$$ Taking the $(-n)^{st}$ power of the left inequality gives us $$e^{-{\\lambda_n}}\\geq (1-\\frac{\\lambda_n} n)^n\\tag{3}$$ Taking the $(\\lambda_n - n)^{th}$ power of the right inequality gives us $$(1-\\frac{\\lambda_n} n)^{(n-\\lambda_n)}\\geq e^{-\\lambda_n}$$ Why was $\\geq$ replaced with $\\leq$? Because $\\lambda_n = np_n, n\\geq 0, 0\\leq p_n\\leq 1$($p_n$ denotes the probability), so $\\lambda_n-n = np_n - n = n(p_n - 1)\\leq 0$, the power is less or equal to 0, so we need change the direction of the sign. Multiply each side of the inequality by $(1-\\frac{\\lambda_n} n)^{\\lambda_n}$, we get $$(1-\\frac{\\lambda_n} n)^n\\geq {e^{-\\lambda_n}} {(1-\\frac{\\lambda_n} n)^{\\lambda_n}}\\tag 4$$ Combine (3) and (4), we get $$e^{-\\lambda_n}(1-\\frac{\\lambda_n} n)^{\\lambda_n}\\leq (1-\\frac{\\lambda_n} n)^n \\leq e^{-\\lambda_n}$$ According to this theorem, because $1 - \\frac{\\lambda_n} n &gt; 0, \\lambda_n &gt; 0, \\lim\\limits_{n\\to\\infty}\\lambda_n = \\lambda$, we have $\\lim\\limits_{n \\to \\infty}(1-\\frac{\\lambda_n} n)^{\\lambda_n} = [\\lim\\limits_{n \\to \\infty}(1-\\frac{\\lambda_n} n)]^{\\lim\\limits_{n\\to\\infty}\\lambda_n}$ $ = \\lim\\limits_{n\\to\\infty}(1-\\lambda_n\\cdot\\frac 1 n)^\\lambda$ $ = (\\lim\\limits_{n\\to\\infty}1 - \\lim\\limits_{n\\to\\infty}\\lambda_n\\cdot\\lim\\limits_{n\\to\\infty}\\frac 1 n)^\\lambda$ $ = (1 -\\lambda\\cdot0)^\\lambda = 1$ So $$\\lim\\limits_{n\\to\\infty}e^{-\\lambda_n}(1-\\frac{\\lambda_n} n)^{\\lambda_n} = e^{-\\lambda}$$ $$\\lim\\limits_{n\\to\\infty}e^{-\\lambda_n} = e^{-\\lambda}$$ According to squeeze theorem, we get $$\\lim\\limits_{n\\to\\infty}(1-\\frac{\\lambda_n} n)^n = e^{-\\lambda}$$ Which is the answer. Reference $e$ as the limit of $(1+\\frac 1 n)^n$","categories":[{"name":"Math","slug":"Math","permalink":"http://searene.me/categories/Math/"}],"tags":[{"name":"math","slug":"math","permalink":"http://searene.me/tags/math/"}]},{"title":"Hexo Source Code Demystified","slug":"Hexo-Source-Code-Demystified","date":"2016-07-16T23:52:23.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/07/17/Hexo-Source-Code-Demystified/","link":"","permalink":"http://searene.me/2016/07/17/Hexo-Source-Code-Demystified/","excerpt":"","text":"PrefaceHexo is an excellent static blog generator, I read its source code recently, and I think it’s worth sharing the inner mechanism of its source code. GeneratorWhen you run the command hexo generate, hexo will generate all the static files for you. This is the part we are going to start with. The directory where hexo generate is executed is /home/searene/Development/hexo-twenty-sixteen in this tutorial. First, we can find the location of the tool hexo with the command which. 1which hexo My output is 1/home/searene/.nvm/versions/node/v5.0.0/bin/hexo This is a soft link, we get the location of the original file with ll 123ll ~/.nvm/versions/node/v5.0.0/bin/hexo lrwxrwxrwx 1 searene searene 37 May 24 01:15 /home/searene/.nvm/versions/node/v5.0.0/bin/hexo -&gt; ../lib/node_modules/hexo-cli/bin/hexo The contents of hexo are as follows. 123#!/usr/bin/env node'use strict';require('../lib/hexo')(); It requires a js file called hexo, which is located in /home/searene/.nvm/versions/node/v5.0.0/lib/node_modules/hexo-cli/lib/hexo.js in my case. The beginning part of the file is as follows. 1234567891011'use strict';var chalk = require('chalk');var tildify = require('tildify');var pathFn = require('path');var Promise = require('bluebird');var Context = require('./context');var findPkg = require('./find_pkg');var goodbye = require('./goodbye');var minimist = require('minimist');var camelCaseKeys = require('hexo-util/lib/camel_case_keys'); It requires several packages. chalk is used for colorful outputs,. tildify is used to convert an absolute path to a tilde path:, like /Users/sindresorhus/dev → ~/dev. context is used to //TODO find_pkg is used to find the local hexo directory that contains node_modules goodbye is used to generate a random goodbye sentence. minimist is used to parse argument options. camelCaseKeys is used to convert keys in parameters to the camelCased ones Let’s continue to read the file. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101function entry(cwd, args) &#123; // cwd is the directory where you invoked the node command cwd = cwd || process.cwd(); // the keys in args is camelCased args = camelCaseKeys(args || minimist(process.argv.slice(2))); var hexo = new Context(cwd, args); var log = hexo.log; // Change the title in console process.title = 'hexo'; function handleError(err) &#123; log.fatal(err); process.exit(2); &#125; /* findPkg searched upwards from the working directory(cwd) to find a directory containing package.json where the key hexo lies, a promise is returned by the function. */ return findPkg(cwd, args).then(function(path) &#123; if (!path) return; /* hexo.base_dir is set as the found directory, which is /home/searene/Development/hexo-twenty-sixteen */ hexo.base_dir = path; /* loadModule loads the hexo package located in the working directory(/home/searene/Development/hexo-twenty-sixteen) and returns a promise, the resolve function will carry a newly-constructed Hexo(return new Hexo(path, args)) object afterwards. From now on, local hexo will be used instead of the global one. */ return loadModule(path, args).catch(function() &#123; log.error('Local hexo not found in %s', chalk.magenta(tildify(path))); log.error('Try running: \\'npm install hexo --save\\''); process.exit(2); &#125;); &#125;).then(function(mod) &#123; if (mod) hexo = mod; log = hexo.log; require('./console')(hexo); return hexo.init(); &#125;).then(function() &#123; var cmd = ''; if (!args.h &amp;&amp; !args.help) &#123; cmd = args._.shift(); if (cmd) &#123; var c = hexo.extend.console.get(cmd); if (!c) cmd = 'help'; &#125; else &#123; cmd = 'help'; &#125; &#125; else &#123; cmd = 'help'; &#125; watchSignal(hexo); return hexo.call(cmd, args).then(function() &#123; return hexo.exit(); &#125;).catch(function(err) &#123; return hexo.exit(err).then(function() &#123; handleError(err); &#125;); &#125;); &#125;).catch(handleError);&#125;entry.console = &#123; init: require('./console/init'), help: require('./console/help'), version: require('./console/version')&#125;;entry.version = require('../package.json').version;function loadModule(path, args) &#123; return Promise.try(function() &#123; var modulePath = pathFn.join(path, 'node_modules', 'hexo'); var Hexo = require(modulePath); return new Hexo(path, args); &#125;);&#125;function watchSignal(hexo) &#123; process.on('SIGINT', function() &#123; hexo.log.info(goodbye()); hexo.unwatch(); hexo.exit().then(function() &#123; process.exit(); &#125;); &#125;);&#125;module.exports = entry; Notice the last part 1module.exports = entry; Remember the contents of hexo.js? 1require('../lib/hexo')(); So what hexo.js does is calling the entry function. Here comes the question, what does entry do? It searched upwards from the working directory looking for package.json containing the key hexo. 123456789101112131415161718192021222324252627function findPkg(cwd, args) &#123; args = args || &#123;&#125;; if (args.cwd) &#123; cwd = pathFn.resolve(cwd, args.cwd); &#125; return checkPkg(cwd);&#125;function checkPkg(path) &#123; var pkgPath = pathFn.join(path, 'package.json'); return fs.readFile(pkgPath).then(function(content) &#123; var json = JSON.parse(content); if (typeof json.hexo === 'object') return path; &#125;).catch(function(err) &#123; if (err &amp;&amp; err.cause.code === 'ENOENT') &#123; var parent = pathFn.dirname(path); if (parent === path) return; return checkPkg(parent); &#125; throw err; &#125;);&#125; Then it loads the local hexo package. 12345678function loadModule(path, args) &#123; return Promise.try(function() &#123; var modulePath = pathFn.join(path, 'node_modules', 'hexo'); var Hexo = require(modulePath); return new Hexo(path, args); &#125;);&#125; new a Hexo object. The souce code of Hexo is as follows: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768function Hexo(base, args) &#123; base = base || process.cwd(); args = args || &#123;&#125;; EventEmitter.call(this); this.base_dir = base + sep; this.public_dir = pathFn.join(base, 'public') + sep; this.source_dir = pathFn.join(base, 'source') + sep; this.plugin_dir = pathFn.join(base, 'node_modules') + sep; this.script_dir = pathFn.join(base, 'scripts') + sep; this.scaffold_dir = pathFn.join(base, 'scaffolds') + sep; this.theme_dir = pathFn.join(base, 'themes', defaultConfig.theme) + sep; this.theme_script_dir = pathFn.join(this.theme_dir, 'scripts') + sep; this.env = &#123; args: args, debug: Boolean(args.debug), safe: Boolean(args.safe), silent: Boolean(args.silent), env: process.env.NODE_ENV || 'development', version: pkg.version, init: false &#125;; this.config_path = args.config ? pathFn.resolve(base, args.config) : pathFn.join(base, '_config.yml'); this.extend = &#123; console: new extend.Console(), deployer: new extend.Deployer(), filter: new extend.Filter(), generator: new extend.Generator(), helper: new extend.Helper(), migrator: new extend.Migrator(), processor: new extend.Processor(), renderer: new extend.Renderer(), tag: new extend.Tag() &#125;; this.config = _.cloneDeep(defaultConfig); this.log = logger(this.env); this.render = new Render(this); this.route = new Router(); this.post = new Post(this); this.scaffold = new Scaffold(this); this._dbLoaded = false; this._isGenerating = false; this.database = new Database(&#123; version: dbVersion, path: pathFn.join(base, 'db.json') &#125;); registerModels(this); this.source = new Source(this); this.theme = new Theme(this); this.locals = new Locals(this); this._bindLocals();&#125; Hexo gets several directories such as public_dir, source_dir, etc. Then it defines the this.extend object, which contains console, deployer, etc. The format of each instance in the this.extend object is as follows: 1234567891011121314151617181920212223242526272829303132333435363738394041function Console() &#123; this.store = &#123;&#125;; this.alias = &#123;&#125;;&#125;//-------------------------function Deployer() &#123; this.store = &#123;&#125;;&#125;//-------------------------function Filter() &#123; this.store = &#123;&#125;;&#125;//-------------------------function Generator() &#123; this.id = 0; this.store = &#123;&#125;;&#125;//-------------------------function Helper() &#123; this.store = &#123;&#125;;&#125;//-------------------------function Migrator() &#123; this.store = &#123;&#125;;&#125;//-------------------------function Processor() &#123; this.store = [];&#125;//-------------------------function Renderer() &#123; this.store = &#123;&#125;; this.storeSync = &#123;&#125;;&#125;//-------------------------function Tag() &#123; this.env = new nunjucks.Environment(null, &#123; autoescape: false &#125;);&#125;//------------------------- All of them contain the same object this.store, which is used to map the name to the corresponding function. For example, this.store in Console is as follows: Each key in the object such as clean, config is of type string. What they are mapped to are functions that implement them. Then it creates several instances, logger, Render, Router, Post, Scaffold, database etc. logger is used to log information on the console and the file, Render is used to render files(e.g. render markdownf files to html), Router is used to save all paths used in the site, Post is used to //TODO, Scaffold is used to //TODO, database is a JSON-based database. It then registered following schemas using registerModels(this). 12345678910exports.Asset = require('./asset');exports.Cache = require('./cache');exports.Category = require('./category');exports.Data = require('./data');exports.Page = require('./page');exports.Post = require('./post');exports.PostAsset = require('./post_asset');exports.PostCategory = require('./post_category');exports.PostTag = require('./post_tag');exports.Tag = require('./tag'); Afterwards, two instances are initiated, Source, Theme,which represents source and theme folders respectively. They are both being processed by Box. First, let’s look at source.js. 1234567891011121314'use strict';var Box = require('../box');var util = require('util');function Source(ctx) &#123; Box.call(this, ctx, ctx.source_dir); this.processors = ctx.extend.processor.list();&#125;util.inherits(Source, Box);module.exports = Source; ctx refers to Hexo, Source function calls Box and gets the processor list, then it inherits Box. Box is used to read and render files in source or theme folder. To find out what’s going on, we need to look into the source code of Box. 123456789101112131415161718192021function Box(ctx, base, options) &#123; EventEmitter.call(this); this.options = _.assign(&#123; persistent: true &#125;, options); // if the last character of the working directory // is not /, add it to the end of base if (base.substring(base.length - 1) !== sep) &#123; base += sep; &#125; this.context = ctx; this.base = base; this.processors = []; this._processingFiles = &#123;&#125;; this.watcher = null; this.Cache = ctx.model('Cache'); this.File = this._createFileClass();&#125; It sets several variables, then it gets the Cache model. The source code of ctx.model function is as follows. 123 Hexo.prototype.model = function(name, schema) &#123; return this.database.model(name, schema);&#125;; If the model was created before, this.database.model will just return the model, or it will create the model with the specified name and schema. 12345678Database.prototype.model = function(name, schema) &#123; if (this._models[name]) &#123; return this._models[name]; &#125; var model = this._models[name] = new this.Model(name, schema); return model;&#125;; Note that We have created the model in the register_model function, which is located in the Hexo function. When the code new Hexo is run, all the models are registered. 123456789101112131415'use strict';var models = require('../models');module.exports = function(ctx) &#123; var db = ctx.database; var keys = Object.keys(models); var key = ''; for (var i = 0, len = keys.length; i &lt; len; i++) &#123; key = keys[i]; db.model(key, models[key](ctx)); &#125;&#125;; The models created here were as follows. 123456789101112'use strict';exports.Asset = require('./asset');exports.Cache = require('./cache');exports.Category = require('./category');exports.Data = require('./data');exports.Page = require('./page');exports.Post = require('./post');exports.PostAsset = require('./post_asset');exports.PostCategory = require('./post_category');exports.PostTag = require('./post_tag');exports.Tag = require('./tag'); Which includes cache. So we can get the created cache model with this.Cache = ctx.model(&#39;Cache&#39;);. This model is used to cache generated posts and stuff, and store a hashed value for all of them. If the hash value is identical, hexo will not generate the post again, which reduces the generation time to a degree. Now we only have a line left in the box function. 1this.File = this._createFileClass(); this.File is used to read file contents and render it. The source code of _createFileClass() function is as follows. 12345678910111213141516171819202122232425262728293031Box.prototype._createFileClass = function() &#123; //ctx is Hexo var ctx = this.context; var _File = function(data) &#123; File.call(this, data); &#125;; require('util').inherits(_File, File); _File.prototype.box = this; _File.prototype.render = function(options, callback) &#123; if (!callback &amp;&amp; typeof options === 'function') &#123; callback = options; options = &#123;&#125;; &#125; return ctx.render.render(&#123; path: this.source &#125;, options).asCallback(callback); &#125;; _File.prototype.renderSync = function(options) &#123; return ctx.render.renderSync(&#123; path: this.source &#125;, options); &#125;; return _File;&#125;; File.call(this, data) sets _File‘s source, path, params and type as the same as ones in data. You can see it in the source of the File constructor. 123456function File(data) &#123; this.source = data.source; this.path = data.path; this.params = data.params; this.type = data.type;&#125; _File inherits File afterwards. Then it sets render and renderSync function of _File and returns it. As you can tell from their names, they are used to render files or strings, like this: 123hexo.render.render(&#123;text: 'example', engine: 'swig'&#125;).then(function(result)&#123; // ...&#125;); 123hexo.render.render(&#123;path: 'path/to/file.swig'&#125;).then(function(result)&#123; // ...&#125;); RenderLet’s look into the Render object. 1234function Render(ctx) &#123; this.context = ctx; this.renderer = ctx.extend.renderer;&#125; Still remember renderer? It’s used to store all the information about rendering. 1234function Renderer() &#123; this.store = &#123;&#125;; this.storeSync = &#123;&#125;;&#125; The most important function in render.js is Render.prototype.render, the function is used to render text or files, the source code of it is as follows. 1234567891011121314151617181920212223242526272829303132333435363738Render.prototype.render = function(data, options, callback) &#123; if (!callback &amp;&amp; typeof options === 'function') &#123; callback = options; options = &#123;&#125;; &#125; var ctx = this.context; var self = this; var ext = ''; return new Promise(function(resolve, reject) &#123; if (!data) return reject(new TypeError('No input file or string!')); if (data.text != null) return resolve(data.text); if (!data.path) return reject(new TypeError('No input file or string!')); fs.readFile(data.path).then(resolve, reject); &#125;).then(function(text) &#123; data.text = text; ext = data.engine || getExtname(data.path); if (!ext || !self.isRenderable(ext)) return text; var renderer = self.getRenderer(ext); return renderer.call(ctx, data, options); &#125;).then(function(result) &#123; result = toString(result, data); if (data.onRenderEnd) &#123; return data.onRenderEnd(result); &#125; return result; &#125;).then(function(result) &#123; var output = self.getOutput(ext) || ext; return ctx.execFilter('after_render:' + output, result, &#123; context: ctx, args: [data] &#125;); &#125;).asCallback(callback);&#125;; First, it checks if data exists or not, data contains text(data.text) or file(data.path) that is going to be rendered, it throws an error if it doesn’t exist. 1if (!data) return reject(new TypeError('No input file or string!')); Then if data.text exists, it will try to render the text first. 1if (data.text != null) return resolve(data.text); If data.path exists, it will try to analyze the file specified by data.path. 12if (!data.path) return reject(new TypeError('No input file or string!'));fs.readFile(data.path).then(resolve, reject); It tries to find out if the rendering engine exists in renderer.store, which maps the rendering engine’s name to the corresponding rendering function. If the engine exists, it will call the corresponding function to render it, return the original text if the engine doesn’t exist. 12345678&#125;).then(function(text) &#123;data.text = text;ext = data.engine || getExtname(data.path);if (!ext || !self.isRenderable(ext)) return text;// get the function used to rendervar renderer = self.getRenderer(ext);return renderer.call(ctx, data, options); renderer refers to the function that is used to render text or files. What renderer.call() returns is usually of JSON format. For example, if the file to be rendered is like this: 12archive_dir: archivesauthor: John Doe The rendered result will be an object like this: 1&#123;archive_dir: \"archives\", author: \"John Doe\"&#125; Some files are not rendered in this way, e.g. md. The rendering results of markdown files are of type string. Hexo creates a toString function to make the conversion happen. 1result = toString(result, data); The source code of toString function is as follows. 12345678910111213function toString(result, options) &#123; if (!options.hasOwnProperty('toString') || typeof result === 'string') return result; if (typeof options.toString === 'function') &#123; return options.toString(result); &#125; else if (typeof result === 'object') &#123; return JSON.stringify(result); &#125; else if (result.toString) &#123; return result.toString(); &#125; return result;&#125; Because md files’s rendering results are of type string. so toString returns the original result directly in this case. Sometimes it needs to be further processed. Afterwards, onRenderEnd is followed in order to modify some contents of result after rendering. 123if (data.onRenderEnd) &#123; return data.onRenderEnd(result);&#125; Then the result is transferred to the next then function, and the after_render filter is executed. 12345678910&#125;).then(function(result) &#123; // output is the file's final type, e.g. html, css // the result of self.getOutput('md') would be 'html', // because the rendering result of a markdown file is of type html var output = self.getOutput(ext) || ext; return ctx.execFilter('after_render:' + output, result, &#123; context: ctx, args: [data] &#125;);&#125;).asCallback(callback); To make it even clearer about how to use execFilter, Here I give an example from the official Hexo website, the following code is used to uglify js files. 123456var UglifyJS = require('uglify-js');hexo.extend.filter.register('after_render:js', function(str, data)&#123; var result = UglifyJS.minify(str); return result.code;&#125;); This is the source code of register function. 1234567891011121314151617181920212223Filter.prototype.register = function(type, fn, priority) &#123; if (!priority) &#123; if (typeof type === 'function') &#123; priority = fn; fn = type; type = 'after_post_render'; &#125; &#125; if (typeof fn !== 'function') throw new TypeError('fn must be a function'); type = typeAlias[type] || type; priority = priority == null ? 10 : priority; var store = this.store[type] = this.store[type] || []; fn.priority = priority; store.push(fn); store.sort(function(a, b) &#123; return a.priority - b.priority; &#125;);&#125;; As you can see, it stores type(e.g. after_post_render:js) and the corresponding processing function in the this.store object. After the registration is over, Filter.prototype.exec executes the specified filter (after_post_render:js in this case). 12345678910111213141516171819202122232425Filter.prototype.exec = function(type, data, options) &#123; options = options || &#123;&#125;; // filters are the functions that are registered before. // this.list(type) gets these functions from this.store var filters = this.list(type); var ctx = options.context; var args = options.args || []; args.unshift(data); return Promise.each(filters, function(filter) &#123; return Promise.method(filter).apply(ctx, args).then(function(result) &#123; /* when the processing is over, the processing function returns the processed result, if the result equals null, it will return the original one without processed by the filter(data), if the result is not null, it will return the result processed by the filter */ args[0] = result == null ? data : result; return args[0]; &#125;); &#125;).then(function() &#123; return args[0]; &#125;);&#125;; OK, this part is over, let’s look into the theme/index.js file next. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647'use strict';var pathFn = require('path');var util = require('util');var Box = require('../box');var View = require('./view');var I18n = require('hexo-i18n');var _ = require('lodash');function Theme(ctx) &#123; Box.call(this, ctx, ctx.theme_dir); this.config = &#123;&#125;; this.views = &#123;&#125;; this.processors = [ require('./processors/config'), require('./processors/i18n'), require('./processors/source'), require('./processors/view') ]; var languages = ctx.config.language; if (!Array.isArray(languages)) &#123; languages = [languages]; &#125; languages.push('default'); this.i18n = new I18n(&#123; languages: _(languages).compact().uniq().value() &#125;); var _View = this.View = function(path, data) &#123; View.call(this, path, data); &#125;; util.inherits(_View, View); _View.prototype._theme = this; _View.prototype._render = ctx.render; _View.prototype._helper = ctx.extend.helper;&#125;util.inherits(Theme, Box); The function Theme also calls Box(), then it adds several processors and sets languages and views. Then it bind locals. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 Hexo.prototype._bindLocals = function() &#123; var db = this.database; var locals = this.locals; var self = this; locals.set('posts', function() &#123; var query = &#123;&#125;; if (!self.config.future) &#123; query.date = &#123;$lte: Date.now()&#125;; &#125; if (!self._showDrafts()) &#123; query.published = true; &#125; return db.model('Post').find(query); &#125;); locals.set('pages', function() &#123; var query = &#123;&#125;; if (!self.config.future) &#123; query.date = &#123;$lte: Date.now()&#125;; &#125; return db.model('Page').find(query); &#125;); locals.set('categories', function() &#123; return db.model('Category'); &#125;); locals.set('tags', function() &#123; return db.model('Tag'); &#125;); locals.set('data', function() &#123; var obj = &#123;&#125;; db.model('Data').forEach(function(data) &#123; obj[data._id] = data.data; &#125;); return obj; &#125;);&#125;; After loading module is over, it calls console to execute the provided command 123456789101112return loadModule(path, args).catch(function() &#123; log.error('Local hexo not found in %s', chalk.magenta(tildify(path))); log.error('Try running: \\'npm install hexo --save\\''); process.exit(2); &#125;);&#125;).then(function(mod) &#123; if (mod) hexo = mod; log = hexo.log; require('./console')(hexo); return hexo.init(); Let’s look through the source code of ./console. 1234567891011121314151617181920212223'use strict';module.exports = function(ctx) &#123; var console = ctx.extend.console; console.register('help', 'Get help on a command.', &#123; &#125;, require('./help')); console.register('init', 'Create a new Hexo folder.', &#123; desc: 'Create a new Hexo folder at the specified path or the current directory.', usage: '[destination]', arguments: [ &#123;name: 'destination', desc: 'Folder path. Initialize in current folder if not specified'&#125; ], options: [ &#123;name: '--no-clone', desc: 'Copy files instead of cloning from GitHub'&#125;, &#123;name: '--no-install', desc: 'Skip npm install'&#125; ] &#125;, require('./init')); console.register('version', 'Display version information.', &#123; &#125;, require('./version'));&#125;; It registers several commands using console.register, let’s look through its source code. 1234567891011121314151617181920212223242526272829303132333435363738394041Console.prototype.register = function(name, desc, options, fn) &#123; if (!name) throw new TypeError('name is required'); if (!fn) &#123; if (options) &#123; if (typeof options === 'function') &#123; fn = options; if (typeof desc === 'object') &#123; // name, options, fn options = desc; desc = ''; &#125; else &#123; // name, desc, fn options = &#123;&#125;; &#125; &#125; else &#123; throw new TypeError('fn must be a function'); &#125; &#125; else &#123; // name, fn if (typeof desc === 'function') &#123; fn = desc; options = &#123;&#125;; desc = ''; &#125; else &#123; throw new TypeError('fn must be a function'); &#125; &#125; &#125; if (fn.length &gt; 1) &#123; fn = Promise.promisify(fn); &#125; else &#123; fn = Promise.method(fn); &#125; var c = this.store[name.toLowerCase()] = fn; c.options = options; c.desc = desc; this.alias = abbrev(Object.keys(this.store));&#125;;","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[]},{"title":"The fee paid to freelancer is not refundable","slug":"The-fee-paid-to-freelancer-is-not-refundable","date":"2016-07-03T16:00:00.000Z","updated":"2017-05-15T15:06:55.321Z","comments":true,"path":"2016/07/04/The-fee-paid-to-freelancer-is-not-refundable/","link":"","permalink":"http://searene.me/2016/07/04/The-fee-paid-to-freelancer-is-not-refundable/","excerpt":"","text":"About two days ago, I got a message from my phone that I was charged for ￥110.72. The money was taken directly from my debit card. At first, I thought the money was stolen using some high-end technology, but I was wrong. After having a conversation with the customer service of UnionPay, I got a keyword, freelancer. Freelancer charged me via Paypal because to try the free trial, I had to verify my Paypal account in the freelancer website. After the free-trial period was over, it automatically charged me for £12.45 GBP to continue the current plan. I remember that the plan chosen for me at first was much more expensive, and I changed the plan to the lowest one in order to prevent any unnecessary payments as much as possible. I thought UnionPay couldn’t be used to pay in GBP, but clearly I was wrong. I issued a ticket to freelancer to try to get a refund, but I failed. It replied that this charge was not refundable. This is really bad. But luckily, there is not too much money. If I didn’t change the plan at first, I would be charged for a fat stack! I don’t want to continue to ask my money back right now, I’m way too lazy. Maybe I will deal with it sometime in the future.","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[]},{"title":"I finished reading \"The catcher in the rhy\"","slug":"I-finished-reading-The-catcher-in-the-rhy","date":"2016-06-14T23:16:44.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/06/15/I-finished-reading-The-catcher-in-the-rhy/","link":"","permalink":"http://searene.me/2016/06/15/I-finished-reading-The-catcher-in-the-rhy/","excerpt":"","text":"I finished reading “The catcher in the rhy” yesterday. I don’t think this is an excellent book. The main character in this book just hates everything. I have no idea why he thinks in this way, though he is only 12 years old. Anyway, he is more mature than me when I was 12 years old, absolutely. I used to read English books in order to improve my English and enlarge my vocabulary. But I think that’s not important now. I mean, learning English is not that important. So why am I still reading these books? Maybe reading books in Chinese will be faster. Honestly I don’t know. I still hope reading in English constantly will help me in the future sometime.","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[{"name":"book","slug":"book","permalink":"http://searene.me/tags/book/"}]},{"title":"install flash plugin in firefox on arch linux","slug":"install-flash-plugin-in-firefox-on-arch-linux","date":"2016-06-14T23:06:33.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/06/15/install-flash-plugin-in-firefox-on-arch-linux/","link":"","permalink":"http://searene.me/2016/06/15/install-flash-plugin-in-firefox-on-arch-linux/","excerpt":"","text":"First, install flashplugin. 1sudo pacman -S flashplugin Then if you launch firefox, you will find out that there’s no sound when playing flash in it. Launch it from the terminal, you will find out the reason. 1Failed to open VDPAU backend libvdpau_va_gl.so: cannot open shared object file: No such file or directory So you need to install libvdpau-va-gl 1sudo pacman -S libvdpau-va-gl Launch again, everything is fine now.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://searene.me/tags/linux/"},{"name":"firefox","slug":"firefox","permalink":"http://searene.me/tags/firefox/"}]},{"title":"connect to wifi via commandline on arch","slug":"connect-to-wifi-via-commandline-on-arch","date":"2016-06-08T12:16:30.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/06/08/connect-to-wifi-via-commandline-on-arch/","link":"","permalink":"http://searene.me/2016/06/08/connect-to-wifi-via-commandline-on-arch/","excerpt":"","text":"I just spent hours connecting to the wireless network on archlinux today. Finally I resorted to various tools in commandline. Here’s how I do it. Make sure you run the following commands as root to avoid some permission errors. Find out SSID of the target wifi1iw dev &quot;your_interface&quot; scan | less Replace your_interface with your own one, usually it’s wlp3s0 or wlan0. You can run ifconfig to find out the name of your interface You will get something like 1234567891011BSS fc:d7:33:59:74:74(on wlp3s0) -- associated TSF: 85505115422 usec (0d, 23:45:05) freq: 2412 beacon interval: 100 TUs capability: ESS Privacy ShortPreamble ShortSlotTime (0x0431) signal: -54.00 dBm last seen: 136 ms ago Information elements from Probe Response frame: SSID: TP-LINK_7474 Supported rates: 1.0* 2.0* 5.5* 11.0* 6.0 9.0 12.0 18.0 ... The SSID is something after SSID. It’s TP-LINK_7474 in my case. AssociationAfter finding out your SSID, you would need to connect to it. There are two cases here, one is when there’s no encryption and one is when WPA/WPA2 is enabled. Find the case that suits you most. No EncryptionThis is pretty easy, you only need one line here. 1iw dev wlan0 connect &quot;your_essid&quot; your_essid is the name of the network you found out before, such as TP-LINK_7474 Then you will need to Get an IP address WPA/WPA2You have a lot of work to be done here. First create a new file /etc/wpa_supplicant/wpa_supplicant.conf. Type in the following contents and save it. 12ctrl_interface=/var/run/wpa_supplicantupdate_config=1 Generate passphrase and save it to the above file. Replace your_SSID and your_key with your own ones. 1wpa_passphrase &quot;your_SSID&quot; &quot;your_key&quot; &gt;&gt; /etc/wpa_supplicant/wpa_supplicant.conf Check if wpa_supplicant is running. 1ps -aux|grep wpa_supplicant If it’s running, just as follows 1root 21108 0.0 0.0 43488 3260 ? Ss 20:01 0:00 wpa_supplicant -i wlp3s0 -B -c /etc/wpa_supplicant/wpa_supplicant.conf Kill the process, and remove /var/run/wpa_supplicant/ if it exists 12kill 21108rm /var/run/wpa_supplicant -rf If it’s not running or you’ve killed the running one, run the following command to start wpa_supplicant. 1wpa_supplicant -B -i &quot;your_interface&quot; -c /etc/wpa_supplicant/wpa_supplicant.conf Get IP AddressAfter connect to the network, you need to get an IP using dhcpcd 1dhcpcd wlp3s0 Wait for several seconds. If everything went smoothly, you would be connected to the network successfully.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://searene.me/tags/linux/"},{"name":"network","slug":"network","permalink":"http://searene.me/tags/network/"}]},{"title":"It's pretty hard to concentrate these days","slug":"It-s-pretty-hard-to-concentrate-these-days","date":"2016-05-28T00:55:25.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/05/28/It-s-pretty-hard-to-concentrate-these-days/","link":"","permalink":"http://searene.me/2016/05/28/It-s-pretty-hard-to-concentrate-these-days/","excerpt":"","text":"Honestly I feel awful these days, it goes the same for yesterday. I created a task that I needed to code for at least three hours for my project every day, but while I was anxious, it was really hard to concentrate. I have no clue about my future, which makes me nervous and kind of hopeless. I heard that you couldn’t test whether a man was strong enough or not when everything went well for him, the qualify was always shown when he was going through some tough time. I agree with it. But I’ve got to say, if everything could be fine, nobody wants to go through any tough time. Though somebody claims he/she wants it, I strongly doubt it. You said that because your life was still fine. You can never expect yourself to be depressed, hopeless and broken. If you have no hope in your life, life means nothing to you. I hope I could go through it. I already learned a lot from the tough time, I wish I could go back to the right track. I still finished my tasks yesterday, I have to go on and work harder. There are a lot to be done for my project, I do hope somebody could help me or work with me. It’s really hard to finish it all by myself.","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[]},{"title":"shorten a string without cutting words","slug":"shorten-a-string-without-cutting-words","date":"2016-05-26T00:24:01.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/05/26/shorten-a-string-without-cutting-words/","link":"","permalink":"http://searene.me/2016/05/26/shorten-a-string-without-cutting-words/","excerpt":"","text":"QuestionHow to shortening a string without cutting words? For example, I have a string called Hello World, whose length is 11. I want to shorten its length to less than 6, which would be Hello W, but W is not a full word, we need to remove it. So the result is ony a word Hello. The following code is to solve the problem, written in python. Code1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#!/usr/bin/env python# -*- coding: utf-8 -*-import unittestdef break_word(src, length): if length &lt;= 0: return '' elif length &gt;= len(src): return src.rstrip() for i in range(length, -1, -1): if src[i] == ' ': return src[:i].rstrip() return ''class TestBreakWord(unittest.TestCase): def test_breakword(self): # zero length self.assertEqual(break_word('Hello World', 0), '') # no word is hit self.assertEqual(break_word('Hello World', 2), '') # exactly a word self.assertEqual(break_word('Hello World', 5), 'Hello') # exactly a word plus a space self.assertEqual(break_word('Hello World', 6), 'Hello') # the second word isn't hit self.assertEqual(break_word('Hello World', 7), 'Hello') # exactly two words self.assertEqual(break_word('Hello World', 11), 'Hello World') # two spaces self.assertEqual(break_word('Hello World', 5), 'Hello') self.assertEqual(break_word('Hello World', 6), 'Hello') self.assertEqual(break_word('Hello World', 7), 'Hello') self.assertEqual(break_word('Hello World', 8), 'Hello') # space in the end self.assertEqual(break_word('Hello World ', 11), 'Hello World') self.assertEqual(break_word('Hello World ', 12), 'Hello World') # two spaces in the end self.assertEqual(break_word('Hello World ', 11), 'Hello World') self.assertEqual(break_word('Hello World ', 12), 'Hello World') self.assertEqual(break_word('Hello World ', 13), 'Hello World')if __name__ == '__main__': unittest.main() Result123456789./words.py.----------------------------------------------------------------------Ran 1 test in 0.000sOKProcess finished with exit code 0","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[]},{"title":"my new goals and my new life","slug":"my-new-goals-and-my-new-life","date":"2016-05-25T04:29:00.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/05/25/my-new-goals-and-my-new-life/","link":"","permalink":"http://searene.me/2016/05/25/my-new-goals-and-my-new-life/","excerpt":"","text":"I feel pretty bad recently, and it occurred to me that what made me feel bad was not the world, it was me, myself. I have to do something to fill my brain with energy, so I add a new task today, to program for my own project for at least 3 hours, apart from other coding and stuff. Though I program almost every day, I never set a goal for myself. This is really a problem, sometimes I’m just being lazy, which puts my project off again and again. So I decided to put an end to this bad behavior. There’s one thing that could achieve it, which is set a goal, a task, forcing myself to finish it every day. I reduced my running distance from 4km to 2km, because I figured that 4km is too much for me. I didn’t run in a very long time, I have to do it, it’s a very efficient way to keep me being energetic. This is my everyday task list 123456789ID Age Recur Due Description Urg 8 2min P1D 10h run for 2km 8.611 24s P1D 10h review the words in anki 8.612 24s P1D 10h add 20 new words to anki 8.6 5 2min P1D 11h play the guitar for at least 30 minutes 8.58 6 2min P1D 11h read 5% of the book in my kindle 8.5814 - P1D 11h program for my project 8.586 tasks It would take about 20 + 15 + 30 + 30 + 30 + 180 = 305min ≈ 5 hours, A lot to be done every day, I will see if I can finish all of them. Then I thought about another thing. Though I created a task to program for at least 3 hours every day, I should have a goal for each hour. I made a list of what I should do about the project right now. Once I finish one of them, I check it. Rename deck Delete deck Add word The click event of show answer button in review page The whole front-end of the review page Time schedule for Again, Hard, Good, Easy There are only these goals for now, I will add a new list if I finish all of them on the above list. What I want ultimately is the sense of felicity, from the bottom of my heart.","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[]},{"title":"I struggled to finish my tasks today","slug":"I-struggled-to-finish-my-tasks-today","date":"2016-05-24T14:55:00.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/05/24/I-struggled-to-finish-my-tasks-today/","link":"","permalink":"http://searene.me/2016/05/24/I-struggled-to-finish-my-tasks-today/","excerpt":"","text":"Today I was in a pretty bad mood, but I still finished my tasks. Because I know, whether I’m in a good or bad mood, I have to live any way. And if I do nothing, things would become worse. In fact, if I immersed myself in doing anything at all, I would probably focuse in that stuff, and forget about other things, including my trouble. So concentrating is pretty good for me. I need to learn to concentrate in any circumstances.","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[]},{"title":"I still didn't go jogging today","slug":"I-still-didn-t-go-jogging-today","date":"2016-05-23T16:31:32.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/05/24/I-still-didn-t-go-jogging-today/","link":"","permalink":"http://searene.me/2016/05/24/I-still-didn-t-go-jogging-today/","excerpt":"","text":"OK, I still didn’t go jogging today, I just don’t feel like it, but I finished other tasks, reading the book, adding new words etc. Though I know jogging is good for my health, both mentally and physically, but I’m just lazy. Today I changed the basic framework of Lantastic, I took away the database part from dsl, and create a new class Dict to include different kinds of formats, so it wouldn’t be a pain to add a new format in the future in this way. I also played the game for a while, well, a little bit long technically, I guess it’s just much easier than programming. But playing games are totally useless to me, I need to be focused on the programming, on my app. Now it’s 00:40, but I still want to finish the app. Though I changed the framework, it wasn’t working completely. I’m afraid it would take a lot of time to fix it tomorrow, I hope I can finish it tonight. I know the chances are not good. UpdateNow it’s 2:16, I think I have made the new framework work. It’s time to get on bed.","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[]},{"title":"I started programming and running today","slug":"I-started-programming-and-running-today","date":"2016-05-22T13:59:59.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/05/22/I-started-programming-and-running-today/","link":"","permalink":"http://searene.me/2016/05/22/I-started-programming-and-running-today/","excerpt":"","text":"I watched alien 3 today, It was not as bad as I thought. Though it cannot beat alien 2, I still consider it a good film. Somehow I got bored with adding new words to anki, which prevented me from enjoying the film in a way. But I consider it a task to add new words to anki, and I’m still finished with it, although some of them were omitted. It was also worth mentioning that I started programming again. I mean, the lantastic project. There are still a lot to be done. To develop a great app, you have to consider a lot of things, and you can never fix all the bugs, I mean it. All I can do is to make a better app, instead of the best, because the latter never happens. To keep me energetic, I started running tonight. It was a little late when I went out, which is almost 22:00. And I saw a car running towards me slowly, it scared me a little bit. Because it occurred to me that a girl was nearly caught by some strangers, the car in that story was also running slowly. I saw that story on zhihu, so I was a little nervous. I gradually sped up my pace and finished the jogging with only about 300 meters. I think I need to go jogging earlier in the future. Though I’m a man, I’m still nervous when I’m all alone in the middle of the night.","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[]},{"title":"bittorrent sync","slug":"bittorrent-sync","date":"2016-05-21T15:07:27.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/05/21/bittorrent-sync/","link":"","permalink":"http://searene.me/2016/05/21/bittorrent-sync/","excerpt":"","text":"I installed bittorrent sync tonight, one on my PC and one on my digitalocean VPS. If it’s working correctly, the previous backup script would be useless. One of the possible issues might be the storage limitation of my VPS, which is only 20GB by now. I haven’t checked how much storage the synced files take, but I guess it’s not a lot by now, though it will grow. Another problem is the huge amount of git files to sync. These files are of little use on account of the archive feature of bittorrent sync. But anyway, I will see if it’s working correctly and smoothly without doing any changes to it.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[]},{"title":"watched alien 2 today","slug":"watched-alien-2-today","date":"2016-05-21T10:08:03.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/05/21/watched-alien-2-today/","link":"","permalink":"http://searene.me/2016/05/21/watched-alien-2-today/","excerpt":"","text":"I watched Alien 2 today, this is an excellent film, and I think it’s better than Alien 1. So I was even a little surprised when I noticed the score of Alien 2 was less than that of Alien 1 on douban and imdb. But anyway, tastes vary from people to people, and what’s more, it’s only a small gap. There were a lot of words that I didn’t know in this movie. So I kept searching and adding those words to anki. It was getting sort of irksome afterwards. Though I omitted some, it was still a lot of words. More than 50 words were added from the film, suppose it took me about 1 minute to add a word, those words could take about 1 hour to be added. Babe, that’s a lot of time! But I knew I had also learned a lot from this film, so I was also satisfied.","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[]},{"title":"Midnight","slug":"Midnight","date":"2016-05-20T18:08:53.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/05/21/Midnight/","link":"","permalink":"http://searene.me/2016/05/21/Midnight/","excerpt":"","text":"It’s already late, more than 2:00, and I haven’t gotten on bed. I changed my blog theme to hueman, which was more friendly to English text. I also installed wordpress, which seemed useless. Before that, I purchased a VPS and a domain, which was not that useful, either. I think I shouldn’t blabber any more, it’s time to get on bed and have a good night.","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[]},{"title":"new task","slug":"new-task","date":"2016-05-20T07:07:35.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/05/20/new-task/","link":"","permalink":"http://searene.me/2016/05/20/new-task/","excerpt":"","text":"Today I added a new daily-recursive task to my taskwarrior list: Read 5% of the book in my kindle So right now I’ve four tasks I need to finish every day. Read 5% of the book in my kindle Run for at least 4 kilometers Play the guitar for at least 30 minutes Add 20 new cards to anki I also need to review cards in anki every day. So there are a lot to be done here, but I need to finish all of them, I need my life to be fulfilling. Let’s get back to the beginning. I said I needed to read a book every day, the book is called “The catcher in the rye”. It is in English, that’s why I’m reading it so slowly. A pretty famous book, I’ve already finished more than 20% of it, but I still have no clue why this book is so wide-spreading. It’s about a young man’s life, something would probably happen in one’s adolescence. Maybe this is way too far from me, after all I’m no longer a child any more. But I’m still determined to finish the book, because I dropped a lot of plans in the past, on account of the so-called meaninglessness of it. So I could barely finish anything in the past. I won’t do it again. A promise is a promise. Once I start a plan, I should never drop it unless I think it’s totally useless.","categories":[{"name":"Journal","slug":"Journal","permalink":"http://searene.me/categories/Journal/"}],"tags":[]},{"title":"WriteToDisk -- An Anki Addon to avoid losing data","slug":"WriteToDisk","date":"2016-04-13T01:21:40.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/04/13/WriteToDisk/","link":"","permalink":"http://searene.me/2016/04/13/WriteToDisk/","excerpt":"","text":"Anki wouldn’t save the cards you added or reviewed if anki or system crashes while anki is running. The addon solves the problem. After installing the addon, when you add or review a card, the data is immediately written to disk, so you wouldn’t lose it no matter what happens. It does have a side-effect, undo card deletion doesn’t work because the deletion works immediately. Try it if you want to avoid losing data. github: https://github.com/searene/Anki-Addonsankiweb: https://ankiweb.net/shared/info/657538072","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"python","slug":"python","permalink":"http://searene.me/tags/python/"},{"name":"anki","slug":"anki","permalink":"http://searene.me/tags/anki/"}]},{"title":"learn redirection the hard way","slug":"learn-redirection-the-hard-way","date":"2016-03-26T13:44:20.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/03/26/learn-redirection-the-hard-way/","link":"","permalink":"http://searene.me/2016/03/26/learn-redirection-the-hard-way/","excerpt":"","text":"It’s been a long time since the last time I wrote the blog, because I’m not a fan of writing blogs. But today I solved a problem with hours’ digging and trying, so I think it might be a good idea to share it. The main idea was that I wanted to run a script at boot, which contained the following line, 1/path/to/node_modules/.bin/gulp 2&gt;&amp;1 &gt; /tmp/gulp.log This line just wouldn’t run, and I didn’t know why. What’s more, the output file /tmp/gulp.log was totally empty. Just when I thought I could do nothing about it and I was just going to give up, I found a possible solution online, which was to put 2&gt;&amp;1 immediately before &amp;, as follows, 1/path/to/node_modules/.bin/gulp &gt; /tmp/gulp.log 2&gt;&amp;1 &amp; It worked! Then I got the error, gulp couldn’t find node. I didn’t know why, I guessed the script didn’t source ~/.zshrc file before running the script. So I added the following line in the script. 1source ~/.zshrc It worked. The original script was executed as perfectly as one could expect. A good lesson. There’s no problem that is unsolvable, the only problem is whether you have enough time and whether you want to find it.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://searene.me/tags/linux/"},{"name":"zsh","slug":"zsh","permalink":"http://searene.me/tags/zsh/"},{"name":"shell","slug":"shell","permalink":"http://searene.me/tags/shell/"}]},{"title":"make fcitx work in sublime-text-3","slug":"make-fcitx-work-in-sublime-text-3","date":"2016-02-16T14:43:42.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/02/16/make-fcitx-work-in-sublime-text-3/","link":"","permalink":"http://searene.me/2016/02/16/make-fcitx-work-in-sublime-text-3/","excerpt":"","text":"PrefaceRecently I began to use sublime and I found that fcitx couldn’t work in sublime. This is quite weird. After searching online for a while, I found a solution which could solve the problem in a “dirty” way. SolutionFirst, thanks to cjacker, save the following script as sublime-imfix.c 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263/*sublime-imfix.cUse LD_PRELOAD to interpose some function to fix sublime input method support for linux.By Cjacker Huang &lt;jianzhong.huang at i-soft.com.cn&gt;By whitequark@whitequark.org How to compile:gcc -shared -o libsublime-imfix.so sublime_imfix.c `pkg-config --libs --cflags gtk+-2.0` -fPICHow to use:LD_PRELOAD=./libsublime-imfix.so sublime_text Changes:2014 06-091, Fix cursor position update for sublime text 3.2, Combine the codes from whitequark(fix for xim immodule) and add cursor update support for XIM immodule.*/ /*for RTLD_NEXT*/#define _GNU_SOURCE #include &lt;gtk/gtk.h&gt;#include &lt;gdk/gdkx.h&gt;#include &lt;assert.h&gt;#include &lt;dlfcn.h&gt;#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;gtk/gtk.h&gt;#include &lt;X11/Xlib.h&gt;#include &lt;X11/Xutil.h&gt; #ifdef VERBOSE#define DEBUG(fmt, ...) do &#123; \\ FILE* err = fopen(\"/tmp/libsublime-immethod-fix.log\", \"a\"); \\ if (err) &#123; \\ fprintf(err, fmt, __VA_ARGS__); \\ fclose(err); \\ &#125; \\ &#125; while(0)#else#define DEBUG(fmt, ...)#endif typedef GdkSegment GdkRegionBox; struct _GdkRegion&#123; long size; long numRects; GdkRegionBox *rects; GdkRegionBox extents;&#125;; GtkIMContext *local_context; //this func is interposed to support cursor position update.voidgdk_region_get_clipbox (const GdkRegion *region, GdkRectangle *rectangle)&#123; g_return_if_fail (region != NULL); g_return_if_fail (rectangle != NULL); rectangle-&gt;x = region-&gt;extents.x1; rectangle-&gt;y = region-&gt;extents.y1; rectangle-&gt;width = region-&gt;extents.x2 - region-&gt;extents.x1; rectangle-&gt;height = region-&gt;extents.y2 - region-&gt;extents.y1; GdkRectangle rect; rect.x = rectangle-&gt;x; rect.y = rectangle-&gt;y; rect.width = 0; rect.height = rectangle-&gt;height; //The caret width is 2 in sublime text 2 //And is 1 in sublime text 3. //Maybe sometimes we will make a mistake, but for most of the time, it should be the caret. if((rectangle-&gt;width == 2 || rectangle-&gt;width == 1) &amp;&amp; GTK_IS_IM_CONTEXT(local_context)) &#123; gtk_im_context_set_cursor_location(local_context, rectangle); &#125;&#125; //this is needed, for example, if you input something in file dialog and return back the edit area//context will lost, so here we set it again.static GdkFilterReturn event_filter (GdkXEvent *xevent, GdkEvent *event, gpointer im_context)&#123; XEvent *xev = (XEvent *)xevent; if(xev-&gt;type == KeyRelease &amp;&amp; GTK_IS_IM_CONTEXT(im_context)) &#123; GdkWindow * win = g_object_get_data(G_OBJECT(im_context),\"window\"); if(GDK_IS_WINDOW(win)) gtk_im_context_set_client_window(im_context, win); &#125; return GDK_FILTER_CONTINUE;&#125; void gtk_im_context_set_client_window (GtkIMContext *context, GdkWindow *window)&#123; GtkIMContextClass *klass; g_return_if_fail (GTK_IS_IM_CONTEXT (context)); klass = GTK_IM_CONTEXT_GET_CLASS (context); if (klass-&gt;set_client_window) klass-&gt;set_client_window (context, window); //below is our interposed codes to save the context to local_context. if(!GDK_IS_WINDOW (window)) return; g_object_set_data(G_OBJECT(context),\"window\",window); int width = gdk_window_get_width(window); int height = gdk_window_get_height(window); if(width != 0 &amp;&amp; height !=0) &#123; gtk_im_context_focus_in(context); local_context = context; &#125; //only add this event_filter when using 'fcitx' immodule. //for xim immodule, this function is as same as original from gtk2. const gchar * immodule = g_getenv(\"GTK_IM_MODULE\"); if(immodule &amp;&amp; !strcmp(immodule, \"fcitx\")) &#123; gdk_window_add_filter (window, event_filter, context); &#125;&#125; /*below codes is from whitequark, fix for xim immodule*/ /* See gtkimcontextxim.c */GType gtk_type_im_context_xim = 0; #define GTK_TYPE_IM_CONTEXT_XIM (gtk_type_im_context_xim)#define GTK_IM_CONTEXT_XIM(obj) (G_TYPE_CHECK_INSTANCE_CAST ((obj), GTK_TYPE_IM_CONTEXT_XIM, GtkIMContextXIM))#define GTK_IM_CONTEXT_XIM_CLASS(klass) (G_TYPE_CHECK_CLASS_CAST ((klass), GTK_TYPE_IM_CONTEXT_XIM, GtkIMContextXIMClass))#define GTK_IS_IM_CONTEXT_XIM(obj) (G_TYPE_CHECK_INSTANCE_TYPE ((obj), GTK_TYPE_IM_CONTEXT_XIM))#define GTK_IS_IM_CONTEXT_XIM_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE ((klass), GTK_TYPE_IM_CONTEXT_XIM))#define GTK_IM_CONTEXT_XIM_GET_CLASS(obj) (G_TYPE_INSTANCE_GET_CLASS ((obj), GTK_TYPE_IM_CONTEXT_XIM, GtkIMContextXIMClass)) typedef struct _GtkIMContextXIM GtkIMContextXIM;typedef struct _GtkIMContextXIMClass GtkIMContextXIMClass; struct _GtkIMContextXIMClass&#123; GtkIMContextClass parent_class;&#125;; typedef struct _StatusWindow StatusWindow;typedef struct _GtkXIMInfo GtkXIMInfo; struct _GtkIMContextXIM&#123; GtkIMContext object; GtkXIMInfo *im_info; gchar *locale; gchar *mb_charset; GdkWindow *client_window; GtkWidget *client_widget; /* The status window for this input context; we claim the* * status window when we are focused and have created an XIC* */ StatusWindow *status_window; gint preedit_size; gint preedit_length; gunichar *preedit_chars; XIMFeedback *feedbacks; gint preedit_cursor; XIMCallback preedit_start_callback; XIMCallback preedit_done_callback; XIMCallback preedit_draw_callback; XIMCallback preedit_caret_callback; XIMCallback status_start_callback; XIMCallback status_done_callback; XIMCallback status_draw_callback; XIMCallback string_conversion_callback; XIC ic; guint filter_key_release : 1; guint use_preedit : 1; guint finalizing : 1; guint in_toplevel : 1; guint has_focus : 1;&#125;; static GClassInitFunc orig_gtk_im_context_xim_class_init;static GType (*orig_g_type_module_register_type)(GTypeModule *, GType, const gchar *, const GTypeInfo *, GTypeFlags);static gboolean (*orig_gtk_im_context_xim_filter_keypress)(GtkIMContext *context, GdkEventKey *event); static gbooleanhook_gtk_im_context_xim_filter_keypress(GtkIMContext *context, GdkEventKey *event) &#123; GtkIMContextXIM *im_context_xim = GTK_IM_CONTEXT_XIM(context); if (!im_context_xim-&gt;client_window) &#123; DEBUG(\"im_context_xim == %p\\n\", im_context_xim); DEBUG(\"event-&gt;window == %p\\n\", event-&gt;window); gtk_im_context_set_client_window(context, event-&gt;window); &#125; return orig_gtk_im_context_xim_filter_keypress(context, event);&#125; static voidhook_gtk_im_context_xim_class_init (GtkIMContextXIMClass *class) &#123; orig_gtk_im_context_xim_class_init(class, NULL); /* wat? */ GtkIMContextClass *im_context_class = GTK_IM_CONTEXT_CLASS (class); assert(!orig_gtk_im_context_xim_filter_keypress); orig_gtk_im_context_xim_filter_keypress = im_context_class-&gt;filter_keypress; im_context_class-&gt;filter_keypress = hook_gtk_im_context_xim_filter_keypress; DEBUG(\"orig_gtk_im_context_xim_filter_keypress: %p\\n\", orig_gtk_im_context_xim_filter_keypress);&#125; GTypeg_type_module_register_type (GTypeModule *module, GType parent_type, const gchar *type_name, const GTypeInfo *type_info, GTypeFlags flags) &#123; if (!orig_g_type_module_register_type) &#123; orig_g_type_module_register_type = dlsym(RTLD_NEXT, \"g_type_module_register_type\"); assert(orig_g_type_module_register_type); &#125; if (type_name &amp;&amp; !strcmp(type_name, \"GtkIMContextXIM\")) &#123; assert(!orig_gtk_im_context_xim_class_init); orig_gtk_im_context_xim_class_init = type_info-&gt;class_init; assert(sizeof(GtkIMContextXIM) == type_info-&gt;instance_size); const GTypeInfo hook_im_context_xim_info = &#123; type_info-&gt;class_size, type_info-&gt;base_init, type_info-&gt;base_finalize, (GClassInitFunc) hook_gtk_im_context_xim_class_init, type_info-&gt;class_finalize, type_info-&gt;class_data, type_info-&gt;instance_size, type_info-&gt;n_preallocs, type_info-&gt;instance_init, &#125;; DEBUG(\"orig_gtk_im_context_xim_class_init: %p\\n\", orig_gtk_im_context_xim_class_init); gtk_type_im_context_xim = orig_g_type_module_register_type(module, parent_type, type_name, &amp;hook_im_context_xim_info, flags); return gtk_type_im_context_xim; &#125; return orig_g_type_module_register_type(module, parent_type, type_name, type_info, flags);&#125; Then compile it. 1gcc -shared -o libsublime-imfix.so sublime_imfix.c `pkg-config --libs --cflags gtk+-2.0` -fPIC You will get a file called libsublime-imfix.so, put it in $HOME/.config/sublime-text-3/Packages/. In fact, it doesn’t matter where you put it, as long as you specify the right location of it in the following code. Put the following code in your ~/.bashrc file. 12# sublime fcitx fixalias sublime='LD_PRELOAD=$HOME/.config/sublime-text-3/Packages/libsublime-imfix.so /usr/bin/subl &gt; /dev/null 2&gt;&amp;1 &amp;' Save, re-source it. 1. ~/.bashrc Type in sublime in your terminal and you are good to go! Showcase","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://searene.me/tags/linux/"},{"name":"fcitx","slug":"fcitx","permalink":"http://searene.me/tags/fcitx/"},{"name":"sublime","slug":"sublime","permalink":"http://searene.me/tags/sublime/"}]},{"title":"GoldenDictMedia","slug":"GoldenDictMedia","date":"2016-02-14T03:19:57.000Z","updated":"2017-05-17T12:41:19.423Z","comments":true,"path":"2016/02/14/GoldenDictMedia/","link":"","permalink":"http://searene.me/2016/02/14/GoldenDictMedia/","excerpt":"","text":"IntroductionGoldenDict is an excellent dictionary management software. It can handle most dictionary formats, some of these dictionaries contain audios and/or images. This addon can import the images and audios pasted from Goldendict when adding new cards in Anki Usage1. Unzip the media fileEvery dictionary containing audios or images in goldendict comes with a media folder, the filename of the media file often ends with .files.zip. The size of the file is usually huge, 100MB+ or even 1GB+. Unzip the file, and you will get a directory containing all the audios and images a dictionary need. You have to do this for every dictionary you need. 2. Turn off Strip-HTMLThe addon cannot paste images from goldendict if you turn on Strip-HTML. If you only want to import audios from goldendict, then you can skip this step. Open Anki, go to Tools --&gt; Preferences and uncheck Strip HTML when pasting text to turn it off. 3. Copy and pasteGo to goldendict, copy something containing audios / images in a dictionary. Go to Anki, adding new cards, then paste it. GoldenDictMedia will notice that the text is pasted from a GoldenDict dictionary, and it will ask you for the media path of it, like this: 4. Specify the location of the media directoryClick on the ... button, find the media directory you unzipped earlier from the zip file, and select it. Notice that selecting the directory is fine, you don’t need go in the directory. Click on OK, and GoldenDictMedia will import the dictionary media for you. You only need to do this once for each dictionary. Copy another audios / images from this dictionary, GoldenDictMedia will import the media automatically. ConfigurationsIgnore the dictionaryIf there are any of the dictionaries you don’t want the addon to process, check ignore the dictionary and never prompt for it again, GoldenDictMedia will not process it. If you only want to ignore it once, just click on Cancel will do the trick. Check GoldenDict MediaBy default GoldenDictMedia will check if there’s any new dictionary added when pasting, if you have added enough dictionaries and you don’t want GoldenDictMedia to detect it again, you can turn it off by uncheck Check goldendict media everytime it pastes in Tools --&gt; GoldenDictMedia. Usually you don’t have to turn it off unless there’s something wrong with it. ResetReset will delete all the dictionary data and configurations in GoldenDictMedia, it will make the addon just as the when you install it the first time. You can do a reset by clicking on Reset in Tools --&gt; GoldenDictMedia. Known Issues Images cannot imported when Strip-HTML is on. I didn’t look through the source code of GoldenDict. But I think that this process should be totally automatic. The file path used in GoldenDict should be reversible, the addon should be able to reverse GoldenDict file path to the real file path in system and get the media from the zip file. So anyone with a good knowledge of how GoldenDict media works is welcomed to improve the addon to make it automatic. Bug ReportThere are two ways to report a bug or offering a suggestion. Open an issue on my github repository Leave a comment below my blog","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"python","slug":"python","permalink":"http://searene.me/tags/python/"},{"name":"anki","slug":"anki","permalink":"http://searene.me/tags/anki/"}]},{"title":"PurgeAttributes, an Anki addon to purge unnecessary attributes","slug":"PurgeAttributes-an-Anki-addon-to-purge-unnecessary-attributes","date":"2016-02-14T03:14:36.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/02/14/PurgeAttributes-an-Anki-addon-to-purge-unnecessary-attributes/","link":"","permalink":"http://searene.me/2016/02/14/PurgeAttributes-an-Anki-addon-to-purge-unnecessary-attributes/","excerpt":"","text":"IntroductionPurgeAttributes is used to purge the font-size attribute originally. But you can purge any attribute defined in something like style=&#39;font-size: 100px; color: red&#39;. InstallPut PurgeAttributes.py in your anki addon directory and restart. UsagePut all the files under PurgeAttributes(including PurgeAttributes.py and PurgeAttribues folder which contains bs4) into your Anki add-ons folder. EffectsIt will purge the four attributes by default: font-family font-size background-color line-height If you are running Anki with a high-resolution like me, and you didn’t strip the html when pasting like me, you may encounter something like this: If you use the addon, it will remove the yellow background and remove the font-size attribute, because the font size here is small. The result is like this: Now it’s not hard to see, right? ConfigurationTo choose which attribute you need to remove, edit the purgeAttributes.py file from menu Tools --&gt; Add-ons --&gt; PurgeAttributes --&gt; Edit, and modify the variable REMOVE_ATTRIBUTES at will.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"python","slug":"python","permalink":"http://searene.me/tags/python/"},{"name":"anki","slug":"anki","permalink":"http://searene.me/tags/anki/"}]},{"title":"ImageResizer, an anki addon to resize images","slug":"ImageResizer-an-anki-addon-to-resize-images","date":"2016-02-14T03:09:32.000Z","updated":"2017-05-21T10:06:38.153Z","comments":true,"path":"2016/02/14/ImageResizer-an-anki-addon-to-resize-images/","link":"","permalink":"http://searene.me/2016/02/14/ImageResizer-an-anki-addon-to-resize-images/","excerpt":"","text":"IntroductionImageResizer is a simple anki addon used to resize the image stored in the clipboard. So images that are too big or too small to be used in reviewing are not a problem any more. Before resizing After resizing InstallThere’s two ways of installing the addon, both require to restart anki after installation Install it from ankiweb. Put ImageResizer.py in your anki addon directory UsageNormally after you install this addon, Images will be automatically resized if you paste images when adding new cards, either by hitting Ctrl + V or Ctrl + Shift + V or click on the button on the toolbar. SettingsYou can change the shortcut and the size of the image etc. from Tools --&gt; Image Resizer The Settings window will pop up. Check Automatically resize the image when pasting if you want to paste the resized image when using Ctrl+V. Anki will paste the original-sized image if you uncheck it. The Key Combination is the shortcut to paste the resized image. It’s just like Ctrl+V, the only difference is that you will always get the resized the image if you use the shortcut to paste. You can modify the shortcut by hitting the button Grab the Key combination on the right. Notice that the shortcut you specified may not work, try and find a workable one. You can also set the width or height of the resized image. Select scale to width and keep ratio, it will resize the image according to the width you specified, and the height value here will be ignored. The same goes to scale to height and keep ratio. Notice that it will always keep the original image’s ratio, either by width or height. Bug ReportThere are two ways to report a bug or offering a suggestion. Open an issue on my github repository Leave a comment below my blog","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"python","slug":"python","permalink":"http://searene.me/tags/python/"},{"name":"anki","slug":"anki","permalink":"http://searene.me/tags/anki/"}]},{"title":"django.db.utils.IntegrityError: duplicate key value violates unique constraint","slug":"django-db-utils-IntegrityError-duplicate-key-value-violates-unique-constraint","date":"2016-01-10T05:23:57.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2016/01/10/django-db-utils-IntegrityError-duplicate-key-value-violates-unique-constraint/","link":"","permalink":"http://searene.me/2016/01/10/django-db-utils-IntegrityError-duplicate-key-value-violates-unique-constraint/","excerpt":"","text":"ErrorRecently I ran into a problem, which bugged me for days. I’m using django and spirit to build a website, there’s a model called category in spirit, which is like this 12345class Category(models.Model): ... title = models.CharField(_(\"title\"), max_length=75) description = models.CharField(_(\"description\"), max_length=255, blank=True) ... The only thing you need to know is that, there’s no such thing as an id in the model, which means django and postgresql will take care of the primary key. It seems fine, right? Until I ran a test, which created a category: 12345678class UserViewTest(TestCase): def setUp(self): cache.clear() self.category = utils.create_category() def simple_test(self): self.assertEqual(1, 1) This is a very simple test, create_category is only responsible for creating a brand new category. Everything should work fine. Then I got an error: 12django.db.utils.IntegrityError: duplicate key value violates unique constraint &quot;spirit_category_category_pkey&quot;DETAIL: Key (id)=(1) already exists. Try to find the reasonIs there an already existing Key (id)=(1)? I leafed through the migration file, and found this: 1234567891011121314if not Category.objects.filter(pk=settings.ST_TOPIC_PRIVATE_CATEGORY_PK).exists(): Category.objects.create( pk=settings.ST_TOPIC_PRIVATE_CATEGORY_PK, title=\"Private\", slug=\"private\", is_private=True )if not Category.objects.filter(pk=settings.ST_UNCATEGORIZED_CATEGORY_PK).exists(): Category.objects.create( pk=settings.ST_UNCATEGORIZED_CATEGORY_PK, title=\"Uncategorized\", slug=\"uncategorized\" ) So django will create two default categories due to the migration file. OK, that’s fine. But why did postgresql insert a record with a Key (id)=(1) instead of Key (id)=(3)? Maybe it’s django’s fault? Maybe django was trying to insert a specified record with Key (id)=(1)? To find out the reason, I debugged all the way to this part: 1234567def execute(self, sql, params=None): self.db.validate_no_broken_transaction() with self.db.wrap_database_errors: if params is None: return self.cursor.execute(sql) else: return self.cursor.execute(sql, params) This was where the insert happened. I checked the sql and params, which was: 12sql = 'INSERT INTO \"spirit_category_category\" (\"parent_id\", \"title\", \"slug\", \"description\", \"is_global\", \"is_closed\", \"is_removed\", \"is_private\") VALUES (%s, %s, %s, %s, %s, %s, %s, %s) RETURNING \"spirit_category_category\".\"id\"'params = (None, 'category_foo2', 'categoryfoo2', '', True, False, False, False) So django didn’t include the id part, but why didn’t postgresql auto increment the id? After searching online for a long time, I found this website. I followed its process and ran the following code to find out the last_value of the id sequence(the primary key is usually a sequence in postgresql if you use django to generate the tables automatically) 1SELECT last_value from spirit_category_category_id_seq; And the answer I got was 1. It’s ONE! What does it mean? It means the next id to be generated will be 1. This is so not what we want. This is why the error happened. Fix the problemLet’s alter it to 3. 1alter sequence spirit_category_category_id_seq restart with 3 Continue the test, and you will pass it. Wait, this is a test, right? So the next time you run the test, it will create all kinds of brand new tables again in order to start a fresh test. So it’s meaningless to alter the sequence, because it would be flushed. Don’t believe it? Run the test again, and it will fail. Fix it for a testSo how to fix this? Just remove the line which id was specified in the migration file, i.e. let postgresql handle the primary key for us. Don’t insert the primary key manually, don’t try to calculate the next avaible id number, you will mess it up. In my case, I just need to remove the following two lines in file 0002_auto_20150728_0442.py 12pk=settings.ST_TOPIC_PRIVATE_CATEGORY_PK,pk=settings.ST_UNCATEGORIZED_CATEGORY_PK, Run the test again, it will pass. ConclusionIt’s a long story, I’ve debugged for days to find out the reason, but it’s totally fine. Though the solution is quite simple, I have to fight all the way to find. During the process, I read a lot of django source code, I learned a lot of python features. I learned how postgresql’s sequence worked. It’s very helpful to me.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"python","slug":"python","permalink":"http://searene.me/tags/python/"},{"name":"django","slug":"django","permalink":"http://searene.me/tags/django/"}]},{"title":"backup script","slug":"backup-script","date":"2015-12-27T14:50:08.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2015/12/27/backup-script/","link":"","permalink":"http://searene.me/2015/12/27/backup-script/","excerpt":"","text":"Recently I made a backup script with python2.7, and it worked fine by now. So I think it might be a good idea to share it here. Install megaFuseThe first thing you need to do is to install megaFuse Install additional packages:1sudo apt-get install libcrypto++-dev libcurl4-openssl-dev libdb5.1++-dev libfreeimage-dev libreadline-dev libfuse-dev Compile megaFuse12cd MegaFusemake Fill in your mega username, password and mountpoint in megafuse.conf, just as follows:123USERNAME = username@email.comPASSWORD = your_passwordMOUNTPOINT = /media/mega Enable MegaFuse1sudo ./MegaFuse -f -o allow_other -o uid=1000 Run MegaFuse at system bootSave the following code as a bash file, e.g. start_mega.sh. Then run the file automatically every time the OS boots by using Startup Applications on ubuntu, note that you should modify /path/to/MegaFuse to the correct one 1234#!/bin/bashsleep 100echo \"yourpassword\" | sudo -S /path/to/MegaFuse/MegaFuse -c /path/to/MegaFuse/megafuse.conf -f -o allow_other -o uid=1000 Why do you need sleep 100? I don’t know either. I tried to add the line /path/to/MegaFuse -c /path/to/megafuse.conf -f -o allow_other -o uid=1000 in the file /etc/rc.local before, but it failed. I don’t know why. And it almost caused my PC fail to boot because it output way too many errors in /var/log/syslog file. Finally I decided to put it in Startup Applications. Notice that I used sudo here, and you have to put your password in plaintext. This is a security risk. But I don’t know to make it work without it, because you need to have root permission to mount it. If you know how to work without sudo, I’d like to hear your opinion. MegaToolsYou also need MegaTools to run this script, I put the tools in /usr/local/bin/ to make it work. 12345678910~/Development/demos$ ls /usr/local/bin|grep megamegacopymegadfmegadlmegagetmegalsmegamkdirmegaputmegaregmegarm my python backup scriptMy backup script was written with python. But I think maybe bash script would be easier. Anyway, this is my backup file 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#!/usr/bin/env pythonimport subprocessimport osimport datetimeimport reimport loggingif __name__ == \"__main__\": # the location in mega where you want to put your files BACKUP_DIRECOTORY = \"Backups\" # local location in which mega was mounted using MegaFuse MOUNTED_LOCATION = \"/media/mega\" # BACKUP_LIST: files you want to back up # file: the file that you want to backup # count: how many versions you want to keep # name: backup basename BACKUP_LIST = [ &#123;'file': '/var/www/html', 'count': 3, 'name': 'html'&#125;, &#123;'file': '/home/searene/Documents/blog/source/_posts', 'count': 3, 'name' : 'blog'&#125; ] devnull = open(os.devnull, 'w') if not os.path.exists(os.path.join(MOUNTED_LOCATION, BACKUP_DIRECOTORY)): os.makedirs(os.path.join(MOUNTED_LOCATION, BACKUP_DIRECOTORY)) for f in BACKUP_LIST: today = datetime.datetime.today() backup_path = os.path.join(MOUNTED_LOCATION, BACKUP_DIRECOTORY, f['name']) if not os.path.exists(backup_path): os.makedirs(backup_path) backup_name = '&#123;&#125;-TIME-&#123;&#125;.tar.gz'.format(os.path.join(backup_path, f['name']), today.strftime(\"%Y-%m-%d-%H-%M-%S\")) logging.info('tar...') subprocess.call(['tar', '-zcvf', backup_name, f['file']], stdout=devnull) file_list = subprocess.check_output(['/usr/local/bin/megals', backup_path]).split('\\n') file_list = [x for x in file_list if re.match(r'&#123;&#125;-TIME-.*'.format(f['name']), x)] if len(file_list) &gt; f['count']: redundant_files = sorted(file_list, reverse=True)[f['count']:] for f in redundant_files: logging.info('&#123;&#125; is deprecated, removing'.format(redundant_files)) subprocess.call(['rm', os.path.join(backup_path, f)]) run the backup script every day at 5:00pmrun crontab -e, add the following line 10 17 * * * python /home/searene/Tools/backupMega.py","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://searene.me/tags/linux/"},{"name":"python","slug":"python","permalink":"http://searene.me/tags/python/"}]},{"title":"auto save in vim","slug":"auto-save-in-vim","date":"2015-12-26T06:49:31.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2015/12/26/auto-save-in-vim/","link":"","permalink":"http://searene.me/2015/12/26/auto-save-in-vim/","excerpt":"","text":"I’d been using vim-auto-save for a long time, but I also found that it often messed up with my buffer order because it used silent wa to save all buffers. And sometimes undo didn’t work, I suspected that it had something to do with silent wa. After searching online for a while, I found out a way to make vim automatically save files without an extra plugin installed, just add the following lines to your .vimrc: 123&quot; save automatically when text is changedset updatetime=200au CursorHold * silent! update It will save the current file whenever text is changed in normal mode or you leave the insert mode. It works pretty well for me. Note that it only works in vim 7.4 or above. Check out your vim version first.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"vim","slug":"vim","permalink":"http://searene.me/tags/vim/"}]},{"title":"map Ctrl-V as Ctrl-Q in vim","slug":"map-Ctrl-V-as-Ctrl-Q-in-vim","date":"2015-12-25T15:40:23.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2015/12/25/map-Ctrl-V-as-Ctrl-Q-in-vim/","link":"","permalink":"http://searene.me/2015/12/25/map-Ctrl-V-as-Ctrl-Q-in-vim/","excerpt":"","text":"If you want to map Ctrl-V as Ctrl-Q, you can add the following line in your .vimrc file 1nnoremap &lt;C-V&gt; &lt;C-Q&gt; It works in gvim, but it wouldn’t work in terminal-vim. Why? I’d been confused about it for a long time until I saw this: If you want to make &lt;c-q&gt; work in your terminal vim, you need to understand the default &lt;C-q&gt; has special meaning in your terminal settings. In your terminal, pressing &lt;c-q&gt; will sent stty start signal. This is important when you first stop your terminal output scrolling(by ctrl-s), and then you want to resume. That is, in terminal vim, if you pressed C-q, it will be captured first by terminal. You can of course change that rule, by disable the stty start definition. like: stty start undef you could add this to your .bashrc file (I assume you were using bash) if you want to make it as default. with this line executed, you can create the same mapping nnoremap &lt;c-q&gt; &lt;c-v&gt; in your vim, and pressing &lt;c-q&gt; in normal mode, vim is gonna enter block-wise selection mode. After all, again, I suggest you forget the windows mapping if you work on linux box. In short, add the following line in your .bashrc file, and the map will work after that. 1stty start undef","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://searene.me/tags/linux/"},{"name":"vim","slug":"vim","permalink":"http://searene.me/tags/vim/"}]},{"title":"Fix The Font Rendering Problem On Pycharm","slug":"Fix-The-Font-Rendering-Problem-In-Pycharm","date":"2015-12-21T13:39:27.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2015/12/21/Fix-The-Font-Rendering-Problem-In-Pycharm/","link":"","permalink":"http://searene.me/2015/12/21/Fix-The-Font-Rendering-Problem-In-Pycharm/","excerpt":"","text":"Almost all the java desktop apps running on PC/Mac have a common problem: font rendering. The font rendering in pycharm was so crappy that I couldn’t live with it any more. So I began to search for a way to fix it. Luckily I found a solution here I added these lines to my ../pycharm/bin/pycharm64.vmoptions file: -Dawt.useSystemAAFontSettings=on-Dswing.aatext=true-Dswing.defaultlaf=com.sun.java.swing.plaf.gtk.GTKLookAndFeel To make it even more clear, this is my complete pycharm64.vmoptions file: -Xms128m-Xmx750m-XX:MaxPermSize=350m-XX:ReservedCodeCacheSize=225m-XX:+UseConcMarkSweepGC-XX:SoftRefLRUPolicyMSPerMB=50-ea-Dsun.io.useCanonCaches=false-Djava.net.preferIPv4Stack=true-Dawt.useSystemAAFontSettings=on-Dswing.aatext=true-Dswing.defaultlaf=com.sun.java.swing.plaf.gtk.GTKLookAndFeel Now the font rendering is much better now. Great! By the way, I love the default font-rendering method on ubuntu, it is much better than that on Windows.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"pycharm","slug":"pycharm","permalink":"http://searene.me/tags/pycharm/"},{"name":"java","slug":"java","permalink":"http://searene.me/tags/java/"}]},{"title":"Specify Port For Hexo Git Deployment","slug":"Specify-Port-For-Hexo-Git-Deployment","date":"2015-12-17T13:11:12.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2015/12/17/Specify-Port-For-Hexo-Git-Deployment/","link":"","permalink":"http://searene.me/2015/12/17/Specify-Port-For-Hexo-Git-Deployment/","excerpt":"","text":"Usually if you want to deploy your hexo posts with git, you can add the following lines to your _config.yml file: 1234567# Deployment## Docs: http://hexo.io/docs/deployment.htmldeploy: type: git repo: git@example.com:blog.git branch: master message: And hexo would deploy your posts if you run hexo deploy, and it will use port 22 (because git uses ssh or https protocal to access server, and hexo will use git under ssh by default). What if the ssh port of your server is not 22? Say it’s port 20000, what can you do? You can change the contents to the following lines: 1234567# Deployment## Docs: http://hexo.io/docs/deployment.htmldeploy: type: git repo: ssh://git@example.com:20000/home/git/blog.git branch: master message: Run hexo deploy, and it works too. Hooray!","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://searene.me/tags/hexo/"},{"name":"git","slug":"git","permalink":"http://searene.me/tags/git/"}]},{"title":"Something About Dnsmasq On Ubuntu 15.10","slug":"Something-About-Dnsmasq-On-Ubuntu-15-10","date":"2015-12-17T11:37:39.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2015/12/17/Something-About-Dnsmasq-On-Ubuntu-15-10/","link":"","permalink":"http://searene.me/2015/12/17/Something-About-Dnsmasq-On-Ubuntu-15-10/","excerpt":"","text":"PrefaceThere are something confusing about dnsmasq on ubuntu 15.10. I would like to write them down here, in case I might forget down the road. How Dnsmasq Starts On Ubuntu 15.10You can find the answer in the file /etc/NetworkManager/NetworkManager.conf: 123456[main]plugins=ifupdown,keyfile,ofonodns=dnsmasq[ifupdown]managed=false If you notice the line dns=dnsmasq, you may figure out that it is network-manager that starts dnsmasq. So if you run sudo service network-manager restart, dnsmasq will get retarted too. Configure Network-Manager Not To Use DnsmasqHow to let network-manager not use dnsmasq, but use the dns servers specified in the file /etc/resolv.conf instead? Just comment the line dns=dnsmasq in /etc/NetworkManager/NetworkManager.conf would be fine, as follows: 123456[main]plugins=ifupdown,keyfile,ofono#dns=dnsmasq[ifupdown]managed=false Then edit /etc/resolv.conf, add your dns server: 1namesever 8.8.8.8 Finally restart network-manager, you will find out the dns server has changed. 1sudo service network-manager restart","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://searene.me/tags/linux/"},{"name":"dnsmasq","slug":"dnsmasq","permalink":"http://searene.me/tags/dnsmasq/"}]},{"title":"Switch CapsLock And Esc And Take CapsLock As Control When It Is Pressed","slug":"Switch-CapsLock-And-Esc-And-Take-CapsLock-As-Control-When-It-Is-Pressed","date":"2015-12-16T15:10:56.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2015/12/16/Switch-CapsLock-And-Esc-And-Take-CapsLock-As-Control-When-It-Is-Pressed/","link":"","permalink":"http://searene.me/2015/12/16/Switch-CapsLock-And-Esc-And-Take-CapsLock-As-Control-When-It-Is-Pressed/","excerpt":"","text":"Edit 1Sometimes the method mentioned below just stops working, and I don’t know why. For now I just switch Esc and CapsLock, and leave Control part behind. It’s quite easy if you just want to switch Esc and CapsLock, all you need to do is install gnome-tweak-tool and find CapsLock key behavior under Typing, and choose Swap Esc and Caps Lock, just as shown below: Edit 2I found a way to make it work. First, open gnome-tweak-tool and find CapsLock key behavior under Typing, and choose Make Caps Lock an additional Ctrl Then add the following line in your ~/.bashrc file: 1xcape -e 'Caps_Lock=Escape' It works for me. The only problem is that you don’t have a CapsLock key anymore. But I guess you can map another key with gnome-tweak-tool. I don’t use that key a lot, so I haven’t done that yet. By the way, you don’t have to see the method below, it doesn’t work properly, at least for me. PrefaceI’ve been using vim for years, and I’ve been using Esc for years. A few days before, I heard about an idea that I could switch Caps Lock and Esc to make vim more convenient, because you know, Caps Lock is nearer than Esc. This is interesting, but lately I heard about a even more convenient idea, which not only includes switching Caps Lock and Esc, but also taking Caps Lock as Control when it’s pressed. So in this way, Caps Lock has two distinct functionalities, one is to be used as Esc when punched, the other is to be used as Control when pressed, what a great idea! Let’s get started to make it real. InstallationI’m using ubuntu 15.10, so I can only guarantee it works in linux. First thing you need to do is to install xcape. 1sudo apt-get install xcape ScriptAfter that, create a new file called xmodmaprc, let’s put it under ~/Tools (or wherever you want, ~ denotes your home folder). The contents of xmodmaprc are as follows: 123456789101112131415!! make caps_lock an additional controlclear Lock! NOTE: this keycode may need to be changed for your controlkeycode 66 = Control_Ladd Control = Control_L!! make escape be caps_lockkeysym Escape = Caps_Lockadd Lock = Caps_Lock!! make a fake escape key (so we can map it with xcape)keycode 999 = Escape Create another file called switch.sh, put it under ~/Tools too. 123456#!/bin/sh# keyboard settings need the desktop to be fully loaded, so we let it sleep for 15s to wait for it.sleep 15xmodmap $HOME/Tools/xmodmaprcxcape -e 'Control_L=Escape' Add permission to make it executable 1chmod +x ~/Tools/switch.sh Now if you run ~/Tools/switch.sh, you will find that it’s already working StartupOf course you don’t want to run ~/Tools/switch.sh manually every time a session starts. Open Startup Applications in unity dash and add a new entry: Now reboot, and you will find that you don’t have to run the command manually any more. Startup Applications does this for you automatically. Enjoy. Referencesuper-caps","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://searene.me/tags/linux/"},{"name":"vim","slug":"vim","permalink":"http://searene.me/tags/vim/"}]},{"title":"get selected text in chrome","slug":"get-selected-text-in-chrome","date":"2015-12-09T14:32:06.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2015/12/09/get-selected-text-in-chrome/","link":"","permalink":"http://searene.me/2015/12/09/get-selected-text-in-chrome/","excerpt":"","text":"EDITThe method mentioned here is overcomplicated. To see a simple method, please refer to my answer at stackoverflow.com prefaceI want to get the selected text in chrome. After hours of searching and trying, I finally figured it out. It’s not as simple as putting the javascript in a file and invoking the script. content.jsYou need this file to inject your script into the target webpage. Without this file, it’s impossible to get the selected text. 12345chrome.runtime.sendMessage(&#123; 'title': document.title, 'url': window.location.href, 'summary': window.getSelection().toString()&#125;); Notice that if you want to get the HTML source code of the selected text, you can use the following content.js content.js to get the HTML source code instead of plain text123456789101112131415// http://groups.google.com/group/mozilla.dev.tech.dom/browse_thread/thread/7ecbbb066ff2027f// Martin Honnen// http://JavaScript.FAQTs.com/ var selection = window.getSelection();var range = selection.getRangeAt(0);if (range) &#123; var div = document.createElement('div'); div.appendChild(range.cloneContents()); vs=div.innerHTML;&#125; chrome.runtime.sendMessage(&#123; 'title': document.title, 'url': window.location.href, 'summary': vs&#125;); Here you can see, content.js sent a message including the selected text. So how we get the message? To achieve this, we need something called background page, which is running in the background. It’s usually called event.js event.js12345678910// This function is called onload in the popup codefunction getPageDetails(callback) &#123; // Inject the content script into the current page chrome.tabs.executeScript(null, &#123; file: 'content.js' &#125;); // Perform the callback when a message is received from the content script chrome.runtime.onMessage.addListener(function(message) &#123; // Call the callback function callback(message); &#125;); &#125;; event.js is not always running, but it will wake up when another view in the extension (for example, a popup) calls runtime.getBackgroundPage., just like the code in popup.js popup.js12345678910111213function onPageDetailsReceived(details) &#123; document.getElementById('output').innerText = details.summary;&#125;// When the popup HTML has loadedwindow.addEventListener('load', function(evt) &#123; // Get the event page chrome.runtime.getBackgroundPage(function(eventPage) &#123; // Call the getPageInfo function in the event page, passing in // our onPageDetailsReceived function as the callback. This injects // content.js into the current tab's HTML eventPage.getPageDetails(onPageDetailsReceived); &#125;); &#125;); You have to declare your background page (event.js) and relative permissions in manifest.json, the sample file is as follows: manifest.json12345678910111213141516171819202122232425262728293031323334&#123; \"manifest_version\": 2, \"name\": \"sample\", \"description\": \"a sample manifest.json\", \"version\": \"1.0\", \"permissions\": [ \"storage\" ], \"icons\": &#123; \"16\": \"img/icon16.png\", \"48\": \"img/icon48.png\", \"128\": \"img/icon128.png\" &#125;, \"background\": &#123; \"scripts\": [\"event.js\"], \"persistent\": false &#125;, \"browser_action\": &#123; \"default_icon\": &#123; \"19\": \"img/icon48.png\", \"38\": \"img/icon48.png\" &#125;, \"default_popup\": \"popup.html\" &#125;, \"content_security_policy\": \"script-src 'self' https://ssl.google-analytics.com; object-src 'self'\", \"web_accessible_resources\": [ \"img/icon128.png\" ], \"permissions\": [ \"tabs\", \"http://*/*\", \"https://*/*\" ]&#125; Finally, this is what popup.html looks like popup.html123456789101112&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;meta charset=\"UTF-8\"&gt;&lt;script src=\"popup.js\"&gt;&lt;/script&gt;&lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=\"output\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; You can find the demo source code here This is the whole picture: ReferenceBuilding a simple Google Chrome extension","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://searene.me/tags/javascript/"},{"name":"chrome","slug":"chrome","permalink":"http://searene.me/tags/chrome/"}]},{"title":"Batch Insert Into MySQL With Python","slug":"Batch-Insert-Into-MySQL-With-Python","date":"2015-12-07T11:50:29.000Z","updated":"2018-07-04T14:49:02.883Z","comments":true,"path":"2015/12/07/Batch-Insert-Into-MySQL-With-Python/","link":"","permalink":"http://searene.me/2015/12/07/Batch-Insert-Into-MySQL-With-Python/","excerpt":"","text":"In Python, you can use MySQLdb‘s executemany to insert multiple records into MySQL at once. First, let’s install MySQLdb. The command used to install it depends on your OS: easy_install mysql-python (mix os) pip install mysql-python (mix os/ python 2) pip install mysqlclient (mix os/ python 3) apt-get install python-mysqldb (Linux Ubuntu, …) cd /usr/ports/databases/py-MySQLdb &amp;&amp; make install clean (FreeBSD) yum install MySQL-python (Linux Fedora, CentOS …) (Source: Stackoverflow) Then use executemany to insert multiple records at once. 123456789101112131415import MySQLdbdb=MySQLdb.connect(user=\"searene\",passwd=\"123\",db=\"test\")c=db.cursor()c.executemany( \"\"\"INSERT INTO breakfast (name, spam, eggs, sausage, price) VALUES (%s, %s, %s, %s, %s)\"\"\", [ (\"Spam and Sausage Lover's Plate\", 5, 1, 8, 7.95 ), (\"Not So Much Spam Plate\", 3, 2, 0, 3.95 ), (\"Don't Wany ANY SPAM! Plate\", 0, 4, 3, 5.95 ) ] )db.commit()# close db if you don't need to execute other SQLs.db.close() (Source: MySQLdb documentation)","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://searene.me/tags/mysql/"},{"name":"python","slug":"python","permalink":"http://searene.me/tags/python/"},{"name":"mysqldb","slug":"mysqldb","permalink":"http://searene.me/tags/mysqldb/"}]},{"title":"Configure Win7 Support For UTC","slug":"Configure-Win7-Support-For-UTC","date":"2015-12-06T09:46:08.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2015/12/06/Configure-Win7-Support-For-UTC/","link":"","permalink":"http://searene.me/2015/12/06/Configure-Win7-Support-For-UTC/","excerpt":"","text":"I have a virtual machine installed on ubuntu, the virtual machine contains an operation system of Win7. Win7 uses localtime, but ubuntu uses UTC, so the time they display is different. To fix this, I decided to set Win7 to use UTC. Here is the solution. Win + S, register, enter Navigate to the key HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation Create new DWORD (32-bit) Value, name it RealTimeIsUniversal. Set its value to 1. Reboot to BIOS settings, set the hardware clock to the correct time in UTC.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://searene.me/tags/linux/"},{"name":"win7","slug":"win7","permalink":"http://searene.me/tags/win7/"}]},{"title":"set up a git server to deploy with hexo","slug":"set-up-a-git-server-to-deploy-with-hexo","date":"2015-12-05T01:52:25.000Z","updated":"2017-12-02T15:34:56.129Z","comments":true,"path":"2015/12/05/set-up-a-git-server-to-deploy-with-hexo/","link":"","permalink":"http://searene.me/2015/12/05/set-up-a-git-server-to-deploy-with-hexo/","excerpt":"","text":"PrefaceI used rsync to deploy my website for the past few days, but it seemed that there were some bugs with hexo rsync deployment, I could only use rsync by running rsync -a localfiles username@server:/remote/path manually instead of simply hexo deploy. Instead of looking for the reason why rsync doesn’t work in hexo, I decided to set up a git server for deployment, because git provides an extra version control feature, which might come in handy sometime in the future. It actually took me a lot of time to do this because there were little information on the Internet regarding it, so writing a blog to record this process is important, I think. NginxFirst we need to set up an nginx on the server, I use centos, so the command works for me 1sudo yum install nginx If you are using ubuntu, the following command would work for you 1sudo apt-get install nginx When the installation finishes, start your nginx 1sudo service nginx start You can test whether nginx works or not by typing in your server’s IP address on your client. Git ServerCreate A User Name On The Server For Git SyncTo set up a git server, the first thing we need to do is to create a username for it, let’s call it git, you should run this command on your server. 1useradd git It will prompt you for a password. Create A SSH Key Pair To Avoid Typing In Password Every TimeTo avoid typing in the password every time we use git, we need to set up a ssh key pair. Run the command on your client. 1ssh-keygen -t rsa Just punch enter when a prompt shows up. Then you will find a file called id_rsa.pub in .ssh folder of your home directory, this is the public key. Now turn to the server, switch your username to git. 1su git create a .ssh foler in your git home directory 1mkdir ~/.ssh create a file named authorized_keys to save the accepted public keys 1touch ~/.ssh/authorized_keys Now turn to your client side, run the following command to add your client’s public key to your server, notice that you should replace the IP address with yours. 1cat .ssh/id_rsa.pub | ssh user@123.45.56.78 \"cat &gt;&gt; ~/.ssh/authorized_keys\" Change the permissions to avoid others modifying your ssh key pair 1chmod 700 ~/.ssh &amp;&amp; chmod 400 ~/.ssh/authorized_keys Set Up A Bare Local Repository On The ServerOK, the next time you log on to your server with the user name git, you won’t need the password anymore. Now Let’s turn to the server side and set up a bare local repository 1git init --bare website.git Use The Remote Repository On The ClientNow turn to your client, go to the hexo directory, install hexo-deployer-git 1npm install hexo-deployer-git --save Then find the _config.yml file and open it. Add the following lines at the end of the file. Notice that you should replace the IP address with your server’s. If there is other deployment setting in your file like this, please remove it. 12345deploy: type: git repo: git@123.456.78.90:website.git branch: master message: Let’s use git to sync our website to the server 1hexo generate &amp;&amp; hexo deploy If nothing error occurs, you’re successful till now. Use Git Hook To Deploy Your Website Automatically On Your ServerNow that you’ve synced your website to the server, but you cannot find these files on your server, why? In fact, it took me a lot of time to search for my website in the website.git folder, but I just couldn’t find it. After gleaning information on the Internet, I realized that my website is still on my server, but not in the way it is stored on my client. Those website files are stored as the object in the git bare repository, you cannot see those files, but you can pull or clone them. So what we need do is deploy these synced files to our web server’s root directory. Go to your nginx’s root directory (it’s usually /usr/share/nginx/html, but I noticed that it’s /var/www/html on ubuntu 15.10), set up a git repository and add the remote server(localhost, actually) 1git init /usr/share/nginx/html &amp;&amp; git remote add origin git@localhost:website.git To enable git user the permission to modify our website, we need to change the ownership of those files to git 1chown git:git /usr/share/nginx/html -R Set up the git hook for deployment, it will automatically sync your files from website.git to /usr/share/nginx/html every time it receives a push operation. 12345678910su gitcd ~/website.git/hooks/cat &lt;&lt;EOT &gt; post-receive#!/bin/shunset $(git rev-parse --local-env-vars)cd /usr/share/nginx/htmlgit fetch origingit reset --hard origin/masterEOT Then set the permission to make the git hook work. 1chmod ug+x ~/website.git/hooks/post-receive To avoid the authorization issue, add the public key of root to the authorized_keys of user git 12su # switch to user rootcat ~/.ssh/id_rsa.pub &gt;&gt; /home/git/.ssh/authorized_keys Test The ResultOK, now we are ready to go. Turn to the client side and deploy your files with hexo-git-deployer 123cd /path/to/your/hexo/root/directoryrm .deploy_git #remove the previous deployment infohexo generate &amp;&amp; hexo deploy Then check your website on your server. ConclusionThis is a long story for me. So there might be something that I didn’t mention, or you get confused about something in the post. If so, please leave a comment below to let me know, I’d like to help you.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"git","slug":"git","permalink":"http://searene.me/tags/git/"}]},{"title":"Ubuntu crashes when entering or exiting fullscreen while watching youtube videos","slug":"Ubuntu-crashes-when-entering-or-exiting-fullscreen-while-watching-youtube-videos","date":"2015-12-04T07:48:31.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2015/12/04/Ubuntu-crashes-when-entering-or-exiting-fullscreen-while-watching-youtube-videos/","link":"","permalink":"http://searene.me/2015/12/04/Ubuntu-crashes-when-entering-or-exiting-fullscreen-while-watching-youtube-videos/","excerpt":"","text":"PrefaceAfter I installed ubuntu 15.10, something weird happened from time to time. Ubuntu often crashed when I entered or exited fullscreen mode while watching youtube videos. Sometimes I could get away with it by punching the Super button to bring up another app, in which I could run some commands to terminate google-chrome. Or I could jumped to tty1 to pkill chrome or sudo pkill Xorg. But sometimes nothing worked. And the most important thing is, it’s extremely annoying, so I decided to solve the problem. SolutionAfter searching for the solution online for a while, I found an answer, it’s pretty simple, just disable hardware accelerator in chrome, as followed. ResultI haven’t encountered the crash phenomenon since I disabled hardware accelerator. So I guess it worked. Whether it’s a bug of google-chrome or ubuntu, I don’t know. But now I can safely enter or exit fullscreen mode without worrying a crash might happen. Hooray!","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://searene.me/tags/linux/"}]},{"title":"enlarge the size of a vdi of virtualbox","slug":"enlarge-the-size-of-a-vdi-of-virtualbox","date":"2015-12-03T10:45:54.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2015/12/03/enlarge-the-size-of-a-vdi-of-virtualbox/","link":"","permalink":"http://searene.me/2015/12/03/enlarge-the-size-of-a-vdi-of-virtualbox/","excerpt":"","text":"I’m more accustomed to Linux compared with Windows, but some apps are not accessible in Linux, e.g. QQ. And sometimes I have to use Visual Studio, which is a cumbersome, slow developing tool. I don’t like that. But I have to use that sometimes. So I use a virtual machine to access Windows, which could help to access those windows apps. For example, today my classmate asked for help, which was about building a client-server app with windows socket. But I didn’t install C++ development environment in my Visual Studio, so I have to install them. But one afternoon passed, and I found that I’ve got no place to install any extra packages any more, since Visual Studio installed a lot of tools on my virtual machine before C++ development tools were installed. Anyway, this is just some bullshit. I know this paragraph has little to do with the title, you can skip the paragraph if you want. But I guess you’ve finished reading it, so, anyway. :) The way to enlarge a vdi is unbelievably simple, it’s just like this: 1VBoxManage modifyhd ~/VirtualBox\\ VMs/win7/win7.vdi --resize 61440 #61440MB = 60GB Then you will find the output like this: 10%...10%...20%...30%...40%...50%...60%...70%...80%...90%...100% It’s very fast, no more than 1 second. Then you can find that the size of the disk has been enlarged to 60GB But when you start Virtual Machine, you will find that the size of the disk doesn’t change in the system, This is because you haven’t extended the volume in the System. Open Control Panel, and search disk in it. Click on Create and format hard disk partiton to open Disk Management. You will find 10GB or whatever the size is that is not allocated yet. Click on the disk that you want to extend, click on extend volume. Then next, next… All done!","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"virtualbox","slug":"virtualbox","permalink":"http://searene.me/tags/virtualbox/"}]},{"title":"rc.local stopped running when an error occurred","slug":"rc-local-stopped-running-when-an-error-occurred","date":"2015-12-03T07:07:46.000Z","updated":"2016-12-06T14:08:49.749Z","comments":true,"path":"2015/12/03/rc-local-stopped-running-when-an-error-occurred/","link":"","permalink":"http://searene.me/2015/12/03/rc-local-stopped-running-when-an-error-occurred/","excerpt":"","text":"Today I found out that /etc/rc.local didn’t execute all of my commands that were written in the file. The content of the /etc/rc.local is like this: 123456#!/bin/bash -ecommand1command2command3exit 0 I tried to execute /etc/rc.local manually, then I found that command1 failed in the middle of running and /etc/rc.local detected this phenomenon and it stopped running too, without considering the feelings of command2 and command3. This is weird, because normally a bash file will execute every command in its file no matter one of the command fails or not. After searching for a while on the Internet. I found that it was -e option that made this happen. -e will make sure the script stop running when an error occurrs. It is essential for PC booting, because if a command fails, there’s no guarantee that other commands will be running normally. But I don’t need this, I just want every command to be executed no matter what happens. so I removed the -e option. Then Everything is fine. Now even when command1 fails, command2 and command3 will still get to be executed.","categories":[{"name":"Coding","slug":"Coding","permalink":"http://searene.me/categories/Coding/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://searene.me/tags/linux/"},{"name":"shell","slug":"shell","permalink":"http://searene.me/tags/shell/"}]}]}